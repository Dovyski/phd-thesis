\chapter{Non-obtrusive detection of emotions}
\label{ch:discussion}

The initial chapters of this thesis present the theoretical foundations and the work needed to create a novel method for the remote detection of users' emotions during their interaction with games. As highlighted by previous research, the understanding of human emotions, as well as the process of automatically detecting them, is the aim of a number of researchers in many different fields. As detailed in Chapter \ref{ch:literature-games}, different theories for modeling and studying emotions in a variety of contexts, including those related to games, have been proposed. A considerable number of those theories are based on the human physiology, connecting emotional reactions to psychophysiological signals, e.g. HR and facial activity. Several approaches to putting such models and theories into practice, to achieve the ultimate goal of detecting what a person is feeling, have been proposed. Chapters \ref{ch:literature-face} and \ref{ch:literature-physiological}, for instance, describe the connection between emotions and their manifestations in the body, particularly the process of mapping measurable psychophysiological signals into an emotional state.

Emotion detection is a complex and multidisciplinary problem that demands knowledge from many different areas. In this thesis, focus is given to the field of games research. This chapter presents and discusses the outcomes of this research, which is focused on creating a non-obtrusive method for emotion detection, particularly in the context of games. The results and contributions of this research are aimed at and discussed in the light of games research; however, they may be useful for scholars in other fields as well. The following sections also present insights obtained during the systematic investigation and development of the proposed method, including a discussion on how they relate to games research and other areas.

\section{\nohyphens{Game-based model for emotion detection}}

Generally, the process of detecting emotions using psychophysiological signals relies on mapping the patterns of such signals into an emotional state. As indicated by the literature review conducted in this thesis, a validated way of achieving this is by measuring the changes of psychophysiological signals caused by the interaction between users and emotion elicitation materials. The process typically involves three main parts: emotion elicitation, signal acquisition and the mapping of such signals into an emotional state. Simply put, subjects are exposed to materials that are likely to produce certain emotional reactions, e.g. video and images depicting sad events. This is then followed by observations of how the signals of interest, e.g. HR, change in accordance. Finally, the emotion detection is conducted by a technique that aims to produce a model to map the changes of those signals into emotional states, e.g. machine learning model like neural networks. The literature review presented in this thesis reveals a myriad of different approaches that have been used in each of the previously mentioned parts.

Most previous research focuses on producing a group model, where data from several individuals are used to create a trained machine capable of detecting the emotions of any other subject outside the training population. Contrary to the established notion that a group model is better, this research investigated the venue of a user-tailored approach. As indicated by previous findings \parencite{bailenson2008real}, a model trained on the data of a given person might be better at predicting the emotional state of that person. This is motivated by the fact that people are different in many aspects, including cultural and personal expectations \parencite{goldberg1993structure}. Furthermore, it is reasonable to believe that these individual characteristics might be preserved and better accounted for in a method that applies a user-tailored model, instead of a group model, to detect emotions. In this thesis, both the emotion elicitation process and the mapping of psychophysiological signals into emotional states were focused on the notion of the individual instead of the group.

\subsection{Calibration games as emotion elicitation}

%When games are used, they are usually gamified version of cognitive tests, or games featuring a well defined difficulty curve, e.g. easy/hard levels. Users have different gaming skills and expectations, so a game designed to be elicitate stresss might not be perceived as such by some users.

%, while previous work explored the use of games as elicitation sources for recognizing user emotions, relying on the emotional states a person can experience \citep{mandryk2006continuous} and which physiological signals are better predictors of such states \citep{jerritta2011physiological},

Previous works have used several different emotion elicitation materials, mainly images and videos, and less often game-related elements. These materials, however, lack a more user-tailored approach for studying the variations of signals. When games are used, emotional states, such as stress and boredom, are often inducted by administering a game with the same particular setup, e.g. high/low difficulty, to all subjects. People respond differently to media according to their personality \parencite{ravaja2004effects}, and differ in social, learning and play styles \parencite{goldberg1993structure}. A game session labeled as stressful, for instance, assumes that all the subjects have the same expectations and behave similarly, which dilutes the individuality of each person, since some might experience the interaction as not being stressful as intended. Additionally, the analysis usually involves the interaction of subjects with some game levels (from the same game) that feature a constant difficulty scale, which does not contemplate the variations of signals in a context where the difficulty of the game constantly increases in the same game level/session.

The investigation of better game-based emotion elicitation materials was one of the main aspects of this research. In the aim to properly elicit particular emotional states in each user, this research introduced the novel idea of calibration games. As detailed in Section \ref{sec:experiment1-games-elicitation} (page \pageref{sec:experiment1-games-elicitation}), calibration games are carefully designed to have a difficulty level that constantly and linearly progresses over time without a pre-defined stopping point. At the beginning, the games are highly predictive, without novelties, changes or surprises and with an emphasis on the passage of time during a wait, which leads to an emotional state of boredom \parencite{van2010behave,koster2013theory,schell2014art}. The game difficulty is then periodically increased until the subject is not able to cope with the challenges at hand, which happens at different times for different users. The ever-increasing game difficulty leads to an emotional state of stress towards the end of the interaction, accounting for the different expectations and gaming skill of a wide range of users.

Sections \ref{sec:experiment1-study1} and \ref{sec:experiment1-study2} present a detailed analysis of how the responses to psychophysiological activity, i.e. HR and facial actions (FA), relate to emotional states in a context featuring calibration games. The results show that a calibration game is a valid emotion elicitation material which accounts for personal differences among subjects when it induces the emotional states of stress and boredom. Using the proposed calibration games, made it possible to observe and confirm, with statistical significance, the variations of HR and naked-eye recognizable FA that happened during the interactions with the games, especially during situations that were designed to provoke boredom and stress. These findings were an essential part of the user-tailored method proposed in this thesis, since they proved that calibration games can be used as emotion elicitation material. Another important factor is the nature of the calibration games compared to other emotional stimuli, e.g. images or videos. The use of images, videos or text as content to produce the emotional stimuli is less likely to produce the reactions of a real gaming session. In a game, users are in charge of actions, which are bound to have consequences. A bad judgment might cause the main character to be hurt, or a correct movement might produce a reward. This feedback loop happen constantly in a game, likely producing emotional reactions in the user. It is plausible to believe that the calibration games present a more sophisticated interaction through their game mechanics, as opposed to the simplistic, one-way interaction between users and images/videos, for instance. Consequentially the use of calibration games is likely to create a deeper emotional connection between users and the emotion elicitation material, resulting in clear and observable changes in psychophysiological signals.

\subsection{Remote readings of psychophysiological signals}

Several works found in the literature rely on physical sensors to acquire the signals used in the emotion detection model. Physical sensors are not convenient since they require a cumbersome setup and might disturb the user experience, i.e. invalidate the use of a finger or hand. The use of remote sensing to acquire psychophysiological signals, a non-obtrusive data collection approach, is mentioned in the literature as a promising solution for this problem. The remote sensing of psychophysiological signals is an essential part of this research, since its objective is to create a method that is able to non-obtrusively detect user emotions. A complete non-obtrusive method for signal acquisition, however, is a complex and challenging problem, particularly in a context involving games. The literature review conducted for this thesis found the main psychophysiological signals that can be remotely acquired and whose data can be used to detect emotional states.

One of the signals that can be generally acquired using remote and non-obtrusive approaches is facial activity. Chapter \ref{ch:literature-face} describes in detail the techniques for facial analysis and the approaches that use them for emotion detection. As mentioned in the chapter, the results indicate that facial analysis is a promising source of information for use in the process of emotion detection. Additionally, the combined use of facial and body features (multimodal emotion recognition) is known to perform better than using either one alone \parencite{zacharatos2014automatic}. Following the findings of previous work, the present thesis used facial activity as an important signal in the emotion detection process. A novel method for the automated analysis of facial cues from videos was developed, as explained in Section \ref{sec:experiment1-study4} (page \pageref{sec:experiment1-study4}). Empirical results of this method show its potential for detecting stress and boredom in players of games. The method is based on Euclidean distances between automatically detected facial points, designed to be robust enough to correctly perform facial analysis even when users naturally interact with games. In such a case, players behave naturally as they play, e.g. moving, laughing and speaking. Evaluations of the method were conducted experimentally using game-based emotion elicitation, which properly contextualized the efficiency of the method in the field of games research. The results, detailed in Section \ref{sec:experiment1-study4}, confirm the method has the potential to differentiate the emotional states of boredom and stress in players. However, the natural behavior of users during the interaction with the games is a significant factor impacting the process.

%. Secondly we present the results of an automated facial analysis performed on subjects of our experiment, who interacted with different games under boring and stressful gameplay conditions. Our results show that values of facial features detected during boring periods of gameplay are different from values of the same facial features detected during stressful periods of gameplay. Even though the nature of our games, i.e. 2D and casual, and the sample size (N=20) could be limiting factors for the generality of the evaluation of our method, we believe our population of experimental subjects is diverse and our results are still promising. Our study contributes with results that can guide further investigation regarding emotions and facial analysis in gaming contexts. .

Another signal acquired using remote and non-obtrusive approaches is HR and its derivatives. Chapter \ref{ch:literature-rppg} details the progress that has been made in the remote estimation of physiological signals, particularly the use of rPPG to estimate HR. Despite the potential rPPG has to eliminate physical sensors completely, its use is considerably impacted by the natural behavior of users. As presented in Section \ref{sec:experiment1-study3} (page \pageref{sec:experiment1-study3}), rPPG estimations of HR are sensitive to noise caused by movement, facial expressions or changes in illumination (e.g. screen activity reflected on user's face), which are all likely to happen in gaming sessions. These interferences can produce unreliable measurements of the HR signal, resulting in misleading data. Although these challenges are limiting factors, the use of the remote measurement of physiological signals, such as rPPG, has already been applied to emotion detection. Signals, such as HR and HRV, were used to remotely detect stress \parencite{mcduffcogcam, mcduff2014improvements, bousefsaf2013remote}, for instance. In the majority of the cases, the subjects are typically instructed to stay still \parencite{rouast2016remote}, which improves the accuracy of the rPPG technique. In some other cases, however, authors evaluate the accuracy of the HR estimation in scenarios where subjects are instructed to act naturally. Despite the fact that such works present experiments where subjects are told to behave naturally, their accuracy evaluation is based on artificial or simple human-computer interactions. Subjects stare idly at the camera \parencite{zhao2013remote,hsu2014learning}, faking an interaction with a computer \parencite{poh2010non}, working on a task, i.e. creating a website \parencite{monkaresi2014machine}, mentally subtracting numbers \parencite{mcduff2014remote}, or performing arbitrary movements \parencite{tran2015robust}, e.g. head rotation in different degrees. In contrast to previous works, this thesis employed rPPG in a context that enabled users to naturally interact with games. Information related to HR is an important physiological indication of the emotional state of users, therefore, the use of rPPG in this thesis to remotely acquire HR data was essential. Extensive evaluations were conducted to establish the reliability of remote HR measurements acquired in situations where users behaved naturally, rather than differently to their usual behavior. The analysis of the accuracy of remote HR estimations clearly established the limitations of the rPPG technique, showing how it is affected by user behavior. One of these identified limitations is the effect of facial occlusion on the rPPG estimations of the HR. The act of resting the chin on the palm of the hand, for instance, a common trait of bored users, significantly affects the process of detecting a face in the videos, thus directly affecting the estimations of HR. Evaluation results of the rPPG technique, as detailed in Section \ref{sec:experiment1-study3}, have shown an average estimation error within the range that still allows the identification of HR variations caused by emotion elicitation materials, as detailed in Section \ref{sec:experiment1-study2}. It shows that it is feasible to remotely extract HR and facial data from video recordings of users interacting with games. As a consequence, those signals can be acquired non-obtrusively and used to detect the emotional state of users playing games.

%are presented and discussed. The main contribution of this paper is the accuracy evaluation of an established rPPG technique within the context of gaming sessions where users behave naturally instead of following movement constraint rules, e.g. remain still. Our results provide researchers with information related to the reliability of a remote HR measurement technique when applied to contexts where users behave more naturally

%is drastically impacted by noise introduced by the movement of users. Previous research countered this problem by instructing users to stand still during any interaction, or by limiting the complexity of such interactions, e.g. using images/videos as emotion elicitation materials, not games. In the present research, effort has been put to apply rPPG in a context involving users behaving naturally while interacting with games. Results

\subsection{Multifactorial emotion detection}

The literature review supporting this thesis suggests that the mapping of psychophysiological signals into emotional states based on a multifactorial analysis, when more than one signal is used, is more likely to produce accurate results \parencite{kukolja2014comparative}. As detailed in Chapter \ref{ch:literature-multifactorial}, a combination of signals can reduce the interference and noise caused by signal manipulation, enhancing the accuracy of an emotion detector. Early studies mapping psychophysiological signals into emotional states focused on a multimodal analysis, when more than one modality, e.g. ECG and skin conductivity, are used in conjunction. Such approaches use a wide variety of physical sensors to acquire signal data. As previously mentioned, physical sensors are not ideal, so a completely remote-based approach for data acquisition would be of interest.

As mentioned in Chapter \ref{ch:literature-multifactorial}, a few studies focus on the remote extraction of different user signals, i.e. HR and blinking rate, from a single source, i.e. video recording. In such a case, a single modality is used, i.e. video, however a set of different signals (factors) is extracted and used in the emotion detection process, i.e. multifactorial analysis. Despite the fact that those studies use non-obtrusive extraction of user signals for emotion detection, they do not use game-focused elicitation materials. The research presented in this thesis used a novel approach to produce a multifactorial analysis, which is non-obtrusive, user-tailored and game-focused. The overall idea, presented in Section \ref{sec:research-aim} (page \pageref{sec:research-aim}), is to remotely extract signals from a given user playing calibration games, then use that data to train a user-tailored neural network, i.e. data from a given user are employed to train a single neural network tailored to that given user. Finally, the signals that a given user exhibits during the interaction with a particular, but ordinary, non-calibration game are remotely extracted and fed into the previously trained neural network. The neural network then outputs the emotional state of that given user in that particular game.

It is important to highlight that this method for emotion detection based on calibration games, remote sensing and a user-tailored multifactorial analysis has not been found in the literature. Furthermore, its feasibility was unknown and the research conducted and reported in this thesis reflects the steps taken to conceive and validate this method for emotion detection. In that light, studies 1 to 4, detailed in Sections \ref{sec:experiment1-study1} to \ref{sec:experiment1-study4}, were conducted to evaluate each component of this novel emotion detection method. They focused on understanding the capabilities and limitations of each component, including their validity in the process, e.g. use of calibration games as emotion elicitation material. Each of the studies contributed to the final assembling of the novel architecture for emotion detection proposed in this thesis. Finally, study 5, detailed in Section \ref{sec:experiment1-study5} (page \pageref{sec:experiment1-study5}), has shown a systematic evaluation of the feasibility of the proposed method in detecting the emotions of users actually playing games. That study was based on the first experiment conducted. It tested a user-tailored neural network trained on data samples from two calibration games of a given subject, which was then used to classify samples from a third calibration game of that same subject. The evaluation included the testing of different user signals, such as HR and facial data combined or used separately. The intent of such an evaluation was to better understand the benefits of a multifactorial analysis, confirming that it indeed produces better estimations of the emotional state of users. The results suggest that the proposed method is feasible and has the potential to non-obtrusively detect the emotional state of users, in a user-tailored fashion during their interaction with games.

\subsection{Usage and validation}

The initial feasibility evaluation of the proposed method, conducted in study 5 (Section \ref{sec:experiment1-study5}, page \pageref{sec:experiment1-study5}) was limited by the number of games available for analysis, i.e. three, and the reduced number of subjects. Despite these constraints, the results suggest the feasibility of a non-obtrusive, game-based and user-tailored emotion detector. In order to further test such suggestions, a final validation of the proposed method was conducted in a second experiment with a larger sample size, as detailed in Chapter \ref{ch:experiment2}. In the experiment, the previously mentioned calibration games, i.e. Mushroom, Platformer and Tetris, were used as emotion elicitation materials to train a user-tailored model, i.e. neural network. This model was then used to detect the emotional state of each user during the interaction with a fourth game, i.e. Infinite Mario. Following the expectations inferred by study 5, the proposed method was able to identify the emotional state of subjects with a mean accuracy of 61.6\%. The results confirm with statistical significance that the proposed method indeed classifies emotional states, achieving an accuracy rate better than chance-level classification.

However, compared to existing works in the literature, the mean classification accuracy of 61.6\% achieved by the proposed method is still below the mean classification accuracy achieved by other affective computing studies, i.e. 77.91\%. A fair comparison of these numbers, however, is not possible. Each study is conducted in particular situations, using different emotion elicitation materials and different training/testing models. As previously mentioned, the method proposed in this thesis focuses on the individual, not the group, which is a common factor found in the literature. Another important and highly distinctive difference between the present work and existing ones is how data is obtained to train and evaluate the emotion detection model. The method proposed in this thesis uses a completely independent dataset to train the model, which is obtained from the natural interactions of users with game-focused elicitation materials, i.e. calibration games. These games are similar to COTS games, which portray a more real gaming experience. The evaluation of the method was conducted on the Infinite Mario game, which mimics the commercial Super Mario game. Data from this game were never used in the trained model, yet it was able to classify the emotional state of users. As mentioned previously, the evaluation of classification performance on fresh data is a better measure of how well classifiers generalize \parencite[Chapter 5]{james2013introduction}. Several works focused on emotion detection do not use game-focused materials for training of a model. Commonly they evaluate accuracy by testings samples that are considerably similar to those found in the training dataset, e.g. splitting available data into training and evaluation datasets, which is different from what is presented in this thesis.

Finally, it is relevant to mention that the method for emotion detection proposed by this research had to deal with significant challenges not faced by previous works. It aims to remotely detect the emotions of players without instructing them how to behave during their interaction with games, i.e. natural behavior. Such a configuration presents a set of unique challenges that inherently affect the results of an emotion detection procedure. The remote acquisition of signals, for instance, is considerably influenced by a subject's movements, which are themselves directly affected by the interaction between the subjects and the games being played. Previous studies that use physical sensors, non-interactive emotion elicitation materials, e.g. images, instructions for subjects to keep still, and highly correlated samples for training and testing any emotion classification model faced less challenging conditions than the method presented in this thesis. Therefore, they were able to obtain data with less noise and ambiguity which is more likely to lead to better results for emotion detection. The research presented in this thesis features unique elements, e.g. calibration games, the natural behavior of subjects and the remote acquisition of signals, which were employed under significantly challenging circumstances. The proposed method is less likely to outperform the accuracy achieved by previous affective computing studies that were more established and were conducted in more controlled contexts, e.g. studies reported by \textcite{moghimi2017affective}. However, it is important to emphasize that the systematic evaluation of the method proposed in this thesis during various studies and experiments, repeatedly indicated its feasibility and potential in different statistical analyses.

As a final and less significant note, it can be mentioned that the design of the method for emotion detection proposed in this thesis allows classifications of emotions in real-time, in contrast to some existing approaches that require offline analysis of all available data. Assuming that a user-tailored model has already been trained, the proposed method only needs an initial amount of data points to detect emotional states, i.e. enough data to fill the moving window used for the analysis. After the minimum amount of data has been collected, e.g. 15 seconds of video data, the method can continuously estimate the emotional state of a user. The estimation can be performed with an arbitrary time interval, including for each new frame of the input video feed. The majority of cases, however, are more likely to employ a longer interval between classifications, e.g. 1 second, which was the value (of the window step) used in the evaluations presented in Section \ref{sec:experiment1-study5} and Chapter \ref{ch:experiment2}. Nevertheless, the proposed method is able to detect emotions off-line, i.e. analyze a previously recorded video, or on-line, i.e. real-time analysis of a live video streaming session.

 %a larger sample size and a non-calibration game.a more challenging setup  able to detect emotional states of stress and boredom in a larger scequally Following the analysis conducted in study 5, it was expected that

 %that the proposed method would still be feasible when used to detect the emotional state of users in a non-calibration.

 %Finally results suggest that a multifactorial, user-tailored model trained on data samples extracted from calibration games is a feasible method to classify emotional states of user during the interaction with games.

%Physiological signals, e.g. HR, are considered reliable sources since they are hard to fake (because of their link to the ANS), differently from facial expressions \parencite{Landowska}, for instance. When combined in the same analysis, however, those signals can complement each other and provide more information about emotional states.

\section{Insights outside games research}

The contributions of this thesis are aimed at the field of games research, however, techniques and theories from a variety of fields, e.g. computer vision and psychology, were used in the investigation process. Several of the components that constitute the proposed method for emotion detection were studied and evaluated separately, which in themselves produced insights that could be used outside the field of games research.

\subsection{Facial behavior and emotions}

One insight that this thesis presents is related to the exploration of facial activity under stressful and boring situations. As detailed in Section \ref{sec:experiment1-study1} (page \pageref{sec:experiment1-study1}), observations of facial actions during the interaction with games indicate that a neutral face remains for longer periods of time during boring segments of play. Additionally, in the context of the experiment presented in this thesis, the facial analysis at an individual level, as opposed to a group level, produced more information to connect facial activity to stress/boredom. This analysis was based on an experiment with a particular configuration that allowed a better exploration of how facial activity relates to the emotional states of stress and boredom. The results obtained could be used by other scholars or practitioners interested in understanding or exploring the relationship between facial activity and emotions. In that light, the present research also introduces a novel method for the automated analysis of facial behavior, which has been proven to have the potential to differentiate, in real-time, the emotional states of boredom and stress in users. The evaluations of such an automated facial analysis show that the values of facial features detected during boring periods are different from values of the same facial features detected during stressful periods. These results can contribute to further investigations regarding emotions and automated facial analysis. They could also be used as indicators of the emotional state of users in human-computer or human-robot interactions, for instance.

%This paper presented the description and results of an experiment aimed at exploring the variations of heart rate (HR) and facial actions (FA) during gaming sessions with induced boredom and stress. In total twenty adults of different ages and gaming experiences participated in the experiment, where they played three different games while being recorded by a video camera and monitored by a HR sensor. The games used in the experiment were carefully designed and implemented to have a difficulty level that linearly increases over time, from a boring to a stressful point. According to self-reported answers in post-games questionnaires, participants perceived the games as being boring at the beginning and stressful at the end.

%In the context where the measurement of physiological signals by physical and contact-based sensors is intrusive or not desired, e.g. remote estimation of HR, information from different channels is required. One of such additional channels of information might be facial expressions, such as the FA analysis performed in this paper.  We believe that this paper contributes with information regarding HR and FA in the context of games, which can be combined to create user-tailored models for emotion detection based on different data sources.

\subsection{Physiological activity and emotions}

Another insight that this thesis presents is related to the remote estimations of HR using rPPG in a context involving natural behavior. The use of rPPG is a promising technique to obtain physiological signals from users/subjects non-obtrusively. Such information has applications in research and industry. As detailed in Section \ref{sec:experiment1-study3} (page \pageref{sec:experiment1-study3}), the evaluation conducted in this thesis regarding rPPG and natural behavior contributes more information related to the reliability of remote HR measurements. Even though the evaluation was performed in a context involving games, the analysis still indicates the limitations of the rPPG technique when applied on users interacting with a computer. As demonstrated, a user's natural behavior, e.g. movement, affects rPPG estimations to different extents. Such information can guide the use of rPPG in contexts where the mentioned natural behavior is an inherent factor.

Finally, this thesis presents an extensive analysis of how physiological signals, particularly HR, relate to emotional states of boredom and stress. As detailed in Section \ref{sec:experiment1-study2} (page \pageref{sec:experiment1-study2}), this research presents indications that the average HR mean during periods of stress is greater than the average HR mean during periods of boredom in the interaction with games. Similar to the facial exploration mentioned previously, the analysis of the HR activity was performed in an experiment that permitted a more elaborate observation of such activity in boring and stressful interactions. The results of this analysis suggest that changes in HR are a promising indicator of stress, which contributes information to the body of knowledge of physiological reactions and emotions.

%\begin{figure}[h]
%    \centering
%    \includegraphics[width=0.6\textwidth]{Content/figures/model-inputs-set.png}
%    \caption{Overall structure of the user-tailored emotion detection model regarding input (user signals) and output (stress/boredom levels).}
%    \label{fig:model-inputs-set}
%\end{figure}

%The user-tailored model proposed for this research might have $N$ input signals, varying from physiological ones, e.g. HR, to non-physiological ones, e.g. facial actions and head movements. Figure \ref{fig:model-inputs-set} illustrates the overall structure of the model. In order to be used in the model, an input signal needs to be supported by previous work regarding emotion detection, as well as be validated within the process of the proposed game-based calibration phase. Time and scope constraints limit the amount of input signals that can be implemented, evaluated and used in this research. As a consequence, a study will be conducted to investigate, validate and initially implement two of those signals into the proposed model: HR and facial activity (which includes head movement, lips activity, etc).

%The techniques and works presented in chapter \ref{ch:literature-face}, which relate to face detection and emotion estimation, suggest that facial analysis is an important component of a multifactorial emotion detection model. Empirical analysis of the data from the first experiment also suggest that individualities regarding facial activities do exist and could be used to estimate emotional states on a user-tailored basis \parencite{bevilacqua2016variations}. As described in section \ref{ch:literature-face-emotion-detection}, facial actions, head movement, lips/eye/mouth activity and distance measurements of detected facial landmarks are viable and proven sources of information for emotion detection.

%Regarding physiological signals, results indicate that the average HR mean for players during the last minute of gameplay is greater than the average HR mean during the second minute of gameplay (chapter \ref{ch:experiment1}, section \ref{sec:experiment1-study3}). The findings are aligned with and reinforce previous research that indicates higher HR mean during stressful situations in a gaming context. The findings also suggest that changes in the HR during gaming sessions is a promising indicator of stress.

%The study will involve the definition of how those two signals will be used as inputs for the model. Facial actions, for instance, will probably be detected and measured by the euclidian distance of the facial landmarks. A vector containing the distances will be evaluated as the input for the model. Regarding the HR, its mean and standard deviation during a particular analysis window will be evaluated as input for the model. A software for the detection of those two signals will be created and used to analyse the video recordings of the first experiment (chapter \ref{ch:experiment1}). The inclusion or exclusion of a component of a signal, e.g. variations of the distances of the lips landmark points, will be based on the accuracy to detect them and the frequency they appear in boring and stressful part of the calibration games.
