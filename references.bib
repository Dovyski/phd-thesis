% Encoding: UTF-8

@Article{dlib09,
  author        = {Davis E. King},
  title         = {Dlib-ml: A Machine Learning Toolkit},
  journal       = {Journal of Machine Learning Research},
  year          = {2009},
  volume        = {10},
  pages         = {1755-1758},
  __markedentry = {[bevf:6]},
  crossref      = {a},
}
@article{lai2015deep,
  title={Deep Cascaded Regression for Face Alignment},
  author={Lai, Hanjian and Xiao, Shengtao and Cui, Zhen and Pan, Yan and Xu, Chunyan and Yan, Shuicheng},
  journal={arXiv preprint arXiv : 1510 . 09083},
  year={2015}
}

@inproceedings{wu2015robust,
  title={Robust Facial Landmark Detection under Significant Head Poses and Occlusion},
  author={Wu, Yue and Ji, Qiang},
  booktitle={Proc. Int. Conf. Comput. Vision. IEEE},
  volume={1},
  year={2015}
}

@inproceedings{burgos2013robust,
  title={Robust face landmark estimation under occlusion},
  author={Burgos-Artizzu, Xavier P and Perona, Pietro and Doll{\'a}r, Piotr},
  booktitle={Computer Vision (ICCV), 2013 IEEE International Conference on},
  pages={1513--1520},
  year={2013},
  organization={IEEE}
}

@inproceedings{kazemi2014one,
  title={One millisecond face alignment with an ensemble of regression trees},
  author={Kazemi, Vahdat and Sullivan, Josephine},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},
  pages={1867--1874},
  year={2014},
  organization={IEEE}
}

@inproceedings{xiong2013supervised,
  title={Supervised descent method and its applications to face alignment},
  author={Xiong, Xuehan and De la Torre, Fernando},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on},
  pages={532--539},
  year={2013},
  organization={IEEE}
}

@inproceedings{baltruvsaitis20123d,
  title={3D constrained local model for rigid and non-rigid facial tracking},
  author={Baltru{\v{s}}aitis, Tadas and Robinson, Peter and Morency, Louis-Philippe},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on},
  pages={2610--2617},
  year={2012},
  organization={IEEE}
}

@article{cao2014face,
  title={Face alignment by explicit shape regression},
  author={Cao, Xudong and Wei, Yichen and Wen, Fang and Sun, Jian},
  journal={International Journal of Computer Vision},
  volume={107},
  number={2},
  pages={177--190},
  year={2014},
  publisher={Springer}
}

@inproceedings{ren2014face,
  title={Face alignment at 3000 fps via regressing local binary features},
  author={Ren, Shaoqing and Cao, Xudong and Wei, Yichen and Sun, Jian},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},
  pages={1685--1692},
  year={2014},
  organization={IEEE}
}

@article{viola2004robust,
  title={Robust real-time face detection},
  author={Viola, Paul and Jones, Michael J},
  journal={International journal of computer vision},
  volume={57},
  number={2},
  pages={137--154},
  year={2004},
  publisher={Springer}
}

@inproceedings{cristinacce2006feature,
  title={Feature Detection and Tracking with Constrained Local Models.},
  author={Cristinacce, David and Cootes, Timothy F},
  booktitle={BMVC},
  volume={1},
  number={2},
  pages={3},
  year={2006},
  organization={Citeseer}
}

@inproceedings{cheng20143d,
  title={3D facial geometric features for constrained local model},
  author={Cheng, Shiyang and Zafeiriou, Stefanos and Asthana, Akshay and Pantic, Maja},
  booktitle={Image Processing (ICIP), 2014 IEEE International Conference on},
  pages={1425--1429},
  year={2014},
  organization={IEEE}
}

@inproceedings{sagonas2013300,
  title={300 faces in-the-wild challenge: The first facial landmark localization challenge},
  author={Christos Sagonas and Georgios Tzimiropoulos and Stefanos Zafeiriou and Maja Pantic},
  booktitle={Computer Vision Workshops (ICCVW), 2013 IEEE International Conference on},
  pages={397--403},
  year={2013},
  organization={IEEE}
}

@article{belhumeur2013localizing,
  title={Localizing parts of faces using a consensus of exemplars},
  author={Belhumeur, Peter N and Jacobs, David W and Kriegman, David J and Kumar, Narendra},
  journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  volume={35},
  number={12},
  pages={2930--2940},
  year={2013},
  publisher={IEEE}
}

@incollection{le2012interactive,
  title={Interactive facial feature localization},
  author={Le, Vuong and Brandt, Jonathan and Lin, Zhe and Bourdev, Lubomir and Huang, Thomas S},
  booktitle={Computer Vision--ECCV 2012},
  pages={679--692},
  year={2012},
  publisher={Springer}
}

@book{csikszentmihalyi1991flow,
  title={Flow: The psychology of optimal experience},
  author={Csikszentmihalyi, Mihaly and Csikzentmihaly, Mihaly},
  volume={41},
  year={1991},
  publisher={HarperPerennial New York}
}

@phdthesis{yu2010facial,
  title={Facial feature detection and tracking with a 3D constrained local model},
  author={Yu, Meng},
  year={2010},
  school={University of St Andrews}
}

@techreport{maris2015,
  title={Implementation and Study of Cascaded-Regression Methods for Facial Feature Points Detection},
  author={Andrej Maris},
  year={2015},
  school={Imperial College London}
}

@article{bradski2000opencv,
  title={The opencv library},
  author={Bradski, Gary and others},
  journal={Doctor Dobbs Journal},
  volume={25},
  number={11},
  pages={120--126},
  year={2000},
  publisher={M AND T PUBLISHING INC}
}

@InCollection{heylen2005facial,
  author    = {Heylen, Dirk and Ghijsen, Mattijs and Nijholt, Anton and op den Akker, Rieks},
  title     = {Facial signs of affect during tutoring sessions},
  booktitle = {Affective Computing and Intelligent Interaction},
  publisher = {Springer},
  year      = {2005},
  pages     = {24--31},
  file      = {:heylen2005facial - Facial signs of affect during tutoring sessions.pdf:PDF},
}

@inproceedings{jerritta2011physiological,
  title={Physiological signals based human emotion recognition: a review},
  author={Jerritta, S and Murugappan, M and Nagarajan, R and Wan, Khairunizam},
  booktitle={Signal Processing and its Applications (CSPA), 2011 IEEE 7th International Colloquium on},
  pages={410--415},
  year={2011},
  organization={IEEE}
}

@Article{kukolja2014comparative,
  author    = {Davor Kukolja and Sini{\v{s}}a Popovi{\'{c}} and Marko Horvat and Bernard Kova{\v{c}} and Kre{\v{s}}imir {\'{C}}osi{\'{c}}},
  title     = {Comparative analysis of emotion estimation methods based on physiological measurements for real-time applications},
  journal   = {International Journal of Human-Computer Studies},
  year      = {2014},
  volume    = {72},
  number    = {10-11},
  pages     = {717--727},
  month     = {oct},
  abstract  = {In  order to improve intelligent Human-Computer Interaction it  is  important to create a  
personalized
adaptive emotion estimator that  is  able  to  learn  over  time  emotional  response  
idiosyncrasies of individual person and thus  enhance estimation accuracy.  This   paper,  with the 
 aim of  identifying preferable methods  for  such a  concept, presents  an   experiment-based  
comparative study of  seven feature reduction and seven machine learning methods commonly used for  
emotion estimation based on   physiological  signals.  The   analysis was  performed  on   data  
obtained in   an   emotion  elicitation experiment  involving 14  participants. Speciﬁc discrete 
emotions were targeted with stimuli from the International Affective Picture System database. The 
experiment was necessary to achieve the uniformity in   the  various aspects  of   emotion  
elicitation, data  processing, feature  calculation, self-reporting procedures and estimation 
evaluation, in order to avoid inconsistency problems that arise when results from studies that use 
different emotion-related databases are mutually compared. The  results of  the performed 
experiment indicate that the combination of a multilayer perceptron (MLP) with sequential ﬂoating 
forward selection (SFFS) exhibited the highest accuracy in discrete emotion classiﬁcation based on 
physiological features calculated from ECG, respiration, skin conductance and skin temperature. 
Using leave-one-session-out crossvalidation method, 60.3%  accuracy in  classiﬁcation of  5  
discrete emotions (sadness, disgust, fear, happiness and neutral) was obtained. In order to 
identify which methods may be the most suitable for real-time estimator adaptation, execution and 
learning times of emotion estimators were also comparatively analyzed. Based on  this analysis, 
preferred feature reduction method for  real- time estimator adaptation was minimum redundancy – 
maximum relevance (mRMR), which was the fastest approach in  terms of  combined execution and 
learning time, as  well as  the second best in accuracy,  after  SFFS.  In   combination with  
mRMR,   highest  accuracies were  achieved by   k-nearest neighbor (kNN)  and MLP with  negligible 
difference (50.33% versus 50.54%); however,  mRMR þ kNN  is preferable option for real-time 
estimator adaptation due to considerably lower combined execution and
learning time of kNN  versus MLP.},
  doi       = {10.1016/j.ijhcs.2014.05.006},
  file      = {:kukolja2014comparative - Comparative analysis of emotion estimation methods based on physiological measurements for real-time applications.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.ijhcs.2014.05.006},
}

@Article{bailenson2008real,
  author    = {Jeremy N. Bailenson and Emmanuel D. Pontikakis and Iris B. Mauss and James J. Gross and Maria E. Jabon and Cendri A.C. Hutcherson and Clifford Nass and Oliver John},
  title     = {Real-time classification of evoked emotions using facial feature tracking and physiological responses},
  journal   = {International Journal of Human-Computer Studies},
  year      = {2008},
  volume    = {66},
  number    = {5},
  pages     = {303--317},
  month     = {may},
  abstract  = {We present automated, real-time models built with machine learning algorithms which use videotapes of subjects’ faces in conjunction
with physiological measurements to predict rated emotion (trained coders’ second-by-second assessments of sadness or amusement).
Input consisted of videotapes of 41 subjects watching emotionally evocative films along with measures of their cardiovascular activity,
somatic activity, and electrodermal responding. We built algorithms based on extracted points from the subjects’ faces as well as their
physiological responses. Strengths of the current approach are (1) we are assessing real behavior of subjects watching emotional videos
instead of actors making facial poses, (2) the training data allow us to predict both emotion type (amusement versus sadness) as well as
the intensity level of each emotion, (3) we provide a direct comparison between person-specific, gender-specific, and general models.
Results demonstrated good fits for the models overall, with better performance for emotion categories than for emotion intensity, for
amusement ratings than sadness ratings, for a full model using both physiological measures and facial tracking than for either cue alone,
and for person-specific models than for gender-specific or general models.
r 2007 Elsevier Ltd. All rights reserved.},
  doi       = {10.1016/j.ijhcs.2007.10.011},
  file      = {:bailenson2008real - Real-time classification of evoked emotions using facial feature tracking and physiological responses.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.ijhcs.2007.10.011},
}

@inproceedings{grundlehner2009design,
  title={The design and analysis of a real-time, continuous arousal monitor},
  author={Grundlehner, Bernard and Brown, Lindsay and Penders, Julien and Gyselinckx, Bert},
  booktitle={Wearable and Implantable Body Sensor Networks, 2009. BSN 2009. Sixth International Workshop on},
  pages={156--161},
  year={2009},
  organization={IEEE}
}

@InProceedings{grafsgaard2013automatically,
  author    = {Grafsgaard, Joseph F and Wiggins, Joseph B and Boyer, Kristy Elizabeth and Wiebe, Eric N and Lester, James C},
  title     = {Automatically Recognizing Facial Expression: Predicting Engagement and Frustration},
  booktitle = {EDM},
  year      = {2013},
  pages     = {43--50},
  abstract  = {Learning involves a rich array of cognitive and affective states. Recognizing and understanding these cognitive and affective dimensions of learning is key to designing informed interventions. Prior research has highlighted the importance of facial expressions in learning-centered affective states, but tracking facial expression poses significant challenges. This paper presents an automated analysis of fine-grained facial movements that occur during computer-mediated tutoring. We use the Computer Expression Recognition Toolbox (CERT) to track fine-grained facial movements consisting of eyebrow raising (inner and outer), brow lowering, eyelid tightening, and mouth dimpling within a naturalistic video corpus of tutorial dialogue (N=65). Within the dataset, upper face movements were found to be predictive of engagement, frustration, and learning, while mouth dimpling was a positive predictor of learning and self-reported performance. These results highlight how both intensity and frequency of facial expressions predict tutoring outcomes. Additionally, this paper presents a novel validation of an automated tracking tool on a naturalistic tutoring dataset, comparing CERT results with manual annotations across a prior video corpus. With the advent of readily available fine-grained facial expression recognition, the developments introduced here represent a next step toward automatically understanding moment-by-moment affective states during learning.},
  file      = {:grafsgaard2013automatically - Automatically Recognizing Facial Expression Predicting Engagement and Frustration.pdf:PDF},
}

@inproceedings{mandryk2006continuous,
  title={A continuous and objective evaluation of emotional experience with interactive play environments},
  author={Mandryk, Regan L and Atkins, M Stella and Inkpen, Kori M},
  booktitle={Proceedings of the SIGCHI conference on Human Factors in computing systems},
  pages={1027--1036},
  year={2006},
  organization={ACM}
}

@article{garde2002effects,
  title={Effects of mental and physical demands on heart rate variability during computer work},
  author={Garde, Anne and Laursen, Bjarne and J{\o}rgensen, Anker and Jensen, Bente},
  journal={European journal of applied physiology},
  volume={87},
  number={4-5},
  pages={456--461},
  year={2002},
  publisher={Springer}
}

@inproceedings{vandeput2009heart,
  title={Heart rate variability as a tool to distinguish periods of physical and mental stress in a laboratory environment},
  author={Vandeput, Steven and Taelman, Joachim and Spaepen, A and Van Huffel, Sabine},
  booktitle={Proceedings of the 6th international workshop on biosignal interpretation (BSI), New Haven, CT},
  pages={187--190},
  year={2009}
}

@inproceedings{zhang2015noncontact,
  title={Noncontact Extraction of Breathing Waveform},
  author={Zhang, Yuzhe and Shang, Fei},
  booktitle={2015 International Power, Electronics and Materials Engineering Conference},
  year={2015},
  organization={Atlantis Press}
}

@inproceedings{yun2009game,
  title={O'game, can you feel my frustration?: improving user's gaming experience via stresscam},
  author={Yun, Chang and Shastri, Dvijesh and Pavlidis, Ioannis and Deng, Zhigang},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={2195--2204},
  year={2009},
  organization={ACM}
}

@Article{rodriguez2015vr,
  author    = {Alejandro Rodriguez and Beatriz Rey and Ma Dolores Vara and Maja Wrzesien and Mariano Alcaniz and Rosa Ma Banos and David Perez-Lopez},
  title     = {A {VR}-Based Serious Game for Studying Emotional Regulation in Adolescents},
  journal   = {{IEEE} Comput. Grap. Appl.},
  year      = {2015},
  volume    = {35},
  number    = {1},
  pages     = {65--73},
  month     = {jan},
  doi       = {10.1109/mcg.2015.8},
  file      = {:rodriguez2015vr - A VR-Based Serious Game for Studying Emotional Regulation in Adolescents.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/mcg.2015.8},
}

@InProceedings{mcduffcogcam,
  author    = {Daniel J. McDuff and Javier Hernandez and Sarah Gontarek and Rosalind W. Picard},
  title     = {COGCAM: Contact-free Measurement of Cognitive Stress During Computer Tasks with a Digital Camera},
  booktitle = {Proceedings of the 2016 {CHI} Conference on Human Factors in Computing Systems - {CHI} {\textquotesingle}16},
  year      = {2016},
  publisher = {Association for Computing Machinery ({ACM})},
  abstract  = {Contact-free camera-based measurement of cognitive stress opens up new possibilities for human-computer interaction with applications in remote learning, stress monitoring, and optimization of workload for user experience. The autonomic nervous system controls the inter-beat intervals of the heart and breathing patterns, and these signals change under cognitive stress. We built a participant-independent cognitive stress recognition model based on photoplethysmographic signals measured remotely at a distance of 3 meters. We tested the model on naturalistic responses from 10 individuals completing randomized-order computer-based tasks (ball control and card sorting). The system successfully detected increased stress during the tasks, which were consistent with self-report measures. Changes in heart rate variability were more discriminative indicators of cognitive stress than were heart rate and breathing rate.},
  doi       = {10.1145/2858036.2858247},
  file      = {:mcduffcogcam - COGCAM_ Contact-free Measurement of Cognitive Stress During Computer Tasks with a Digital Camera.pdf:PDF},
  url       = {http://dx.doi.org/10.1145/2858036.2858247},
}

@inproceedings{bousefsaf2013remote,
  title={Remote assessment of the heart rate variability to detect mental stress},
  author={Bousefsaf, Fr{\'e}d{\'e}ric and Maaoui, Choubeila and Pruski, Alain},
  booktitle={Pervasive Computing Technologies for Healthcare (PervasiveHealth), 2013 7th International Conference on},
  pages={348--351},
  year={2013},
  organization={IEEE}
}

@inproceedings{xiao2015towards,
  title={Towards Attentive, Bi-directional MOOC Learning on Mobile Devices},
  author={Xiao, Xiang and Wang, Jingtao},
  booktitle={Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},
  pages={163--170},
  year={2015},
  organization={ACM}
}

@incollection{stockhausen2013beats,
  title={Beats down: Using heart rate for game interaction in mobile settings},
  author={Stockhausen, Claudia and Smyzek, Justine and Kr{\"o}mker, Detlef},
  booktitle={Human-Computer Interaction--INTERACT 2013},
  pages={523--530},
  year={2013},
  publisher={Springer}
}

@inproceedings{yun2010pads,
  title={PADS: enhancing gaming experience using profile-based adaptive difficulty system},
  author={Yun, Chang and Trevino, Philip and Holtkamp, William and Deng, Zhigang},
  booktitle={Proceedings of the 5th ACM SIGGRAPH Symposium on Video Games},
  pages={31--36},
  year={2010},
  organization={ACM}
}

@incollection{moussa2009applying,
  title={Applying affect recognition in serious games: The playmancer project},
  author={Moussa, Maher Ben and Magnenat-Thalmann, Nadia},
  booktitle={Motion in Games},
  pages={53--62},
  year={2009},
  publisher={Springer}
}

@inproceedings{yu2014video,
  title={Video based heart rate estimation under different light illumination intensities},
  author={Yu, Yong-Poh and Paramesran, Raveendran and Lim, Chern-Loon},
  booktitle={Intelligent Signal Processing and Communication Systems (ISPACS), 2014 International Symposium on},
  pages={216--221},
  year={2014},
  organization={IEEE}
}

@article{golden1978stroop,
  title={Stroop colour and word test},
  author={Golden, CJ},
  journal={age},
  volume={15},
  pages={90},
  year={1978}
}

@InProceedings{mcduff2015survey,
  author       = {Daniel J. McDuff and Justin R. Estepp and Alyssa M. Piasecki and Ethan B. Blackford},
  title        = {A survey of remote optical photoplethysmographic imaging methods},
  booktitle    = {2015 37th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
  year         = {2015},
  pages        = {6398--6404},
  month        = {aug},
  organization = {IEEE},
  publisher    = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  doi          = {10.1109/embc.2015.7319857},
  file         = {:mcduff2015survey - A survey of remote optical photoplethysmographic imaging methods.pdf:PDF},
  url          = {http://dx.doi.org/10.1109/embc.2015.7319857},
}

@article{berg1948simple,
  title={A simple objective technique for measuring flexibility in thinking},
  author={Berg, Esta A},
  journal={The Journal of general psychology},
  volume={39},
  number={1},
  pages={15--22},
  year={1948},
  publisher={Taylor \& Francis}
}

@article{ekman1977facial,
  title={Facial action coding system},
  author={Ekman, Paul and Friesen, Wallace V},
  year={1977},
  publisher={Consulting Psychologists Press, Stanford University, Palo Alto}
}

@article{unsworth2015playing,
  title={Is playing video games related to cognitive abilities?},
  author={Unsworth, Nash and Redick, Thomas S and McMillan, Brittany D and Hambrick, David Z and Kane, Michael J and Engle, Randall W},
  journal={Psychological science},
  volume={26},
  number={6},
  pages={759--774},
  year={2015},
  publisher={SAGE Publications}
}

@article{terlecki2005important,
  title={How important is the digital divide? The relation of computer and videogame usage to gender differences in mental rotation ability},
  author={Terlecki, Melissa S and Newcombe, Nora S},
  journal={Sex Roles},
  volume={53},
  number={5},
  pages={433--441},
  year={2005},
  publisher={Springer}
}

@article{goodie2000validation,
  title={Validation of Polar heart rate monitor for assessing heart rate during physical and mental stress.},
  author={Goodie, Jeffrey L and Larkin, Kevin T and Schauss, Scott},
  journal={Journal of Psychophysiology},
  volume={14},
  number={3},
  pages={159},
  year={2000},
  publisher={Hogrefe \& Huber Publishers}
}

@InProceedings{bevilacqua2015proposal,
  author       = {Fernando Bevilacqua and Per Backlund and Henrik Engstrom},
  title        = {Proposal for Non-Contact Analysis of Multimodal Inputs to Measure Stress Level in Serious Games},
  booktitle    = {2015 7th International Conference on Games and Virtual Worlds for Serious Applications ({VS}-Games)},
  year         = {2015},
  pages        = {1--4},
  month        = {sep},
  organization = {IEEE},
  publisher    = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  abstract     = {The process of monitoring user emotions in seriousgames  or  human-computer  interaction  is  usually  obtrusive.  Thework-flow   is   typically   based   on   sensors   that   are   physicallyattached to the user. Sometimes those sensors completely disturbthe  user  experience,  such  as  finger  sensors  that  prevent  the  useof  keyboard/mouse.  This  short  paper  presents  techniques  usedto  remotely  measure  different  signals  produced  by  a  person,e.g.  heart  rate,  through  the  use  of  a  camera  and  computervision  techniques.  The  analysis  of  a  combination  of  such  signals(multimodal input) can be used in a variety of applications suchas  emotion  assessment  and  measurement  of  cognitive  stress.  Wepresent  a  research  proposal  for  measurement  of  player’s  stresslevel based on a non-contact analysis of multimodal user inputs.Our main contribution is a survey of commonly used methods toremotely measure user input signals related to stress assessment.},
  doi          = {10.1109/vs-games.2015.7295783},
  file         = {:bevilacqua2015proposal - Proposal for Non-Contact Analysis of Multimodal Inputs to Measure Stress Level in Serious Games.pdf:PDF},
  url          = {http://dx.doi.org/10.1109/vs-games.2015.7295783},
}

@article{cohn2007observer,
  title={Observer-based measurement of facial expression with the Facial Action Coding System},
  author={Cohn, Jeffrey F and Ambadar, Zara and Ekman, Paul},
  journal={The handbook of emotion elicitation and assessment},
  pages={203--221},
  year={2007},
  publisher={Oxford University Press, New York, NY}
}

@Article{Chanel_2011,
  author    = {Guillaume Chanel and Cyril Rebetez and Mireille Bétrancourt and Thierry Pun},
  title     = {Emotion Assessment From Physiological Signals for Adaptation of Game Difficulty},
  journal   = {{IEEE} Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
  year      = {2011},
  volume    = {41},
  number    = {6},
  pages     = {1052--1063},
  month     = {nov},
  abstract  = {This paper proposes to maintain player’s engagement
by adapting game difficulty according to player’s emotions
assessed from physiological signals. The validity of this approach
was first tested by analyzing the questionnaire responses, electroencephalogram
(EEG) signals, and peripheral signals of the
players playing a Tetris game at three difficulty levels. This analysis
confirms that the different difficulty levels correspond to
distinguishable emotions, and that, playing several times at the
same difficulty level gives rise to boredom. The next step was to
train several classifiers to automatically detect the three emotional
classes from EEG and peripheral signals in a player-independent
framework. By using either type of signals, the emotional classes
were successfully recovered, with EEG having a better accuracy
than peripheral signals on short periods of time. After the fusion
of the two signal categories, the accuracy raised up to 63%.},
  doi       = {10.1109/tsmca.2011.2116000},
  file      = {:Chanel_2011 - Emotion Assessment From Physiological Signals for Adaptation of Game Difficulty.pdf:PDF},
  issue     = {6},
  masid     = {51193703},
  publisher = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/TSMCA.2011.2116000},
}

@InProceedings{mcduff2014remote,
  author    = {Daniel McDuff and Sarah Gontarek and Rosalind Picard},
  title     = {Remote measurement of cognitive stress via heart rate variability},
  booktitle = {2014 36th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society},
  year      = {2014},
  pages     = {2957-2960},
  month     = {aug},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  doi       = {10.1109/embc.2014.6944243},
  file      = {:mcduff2014remote - Remote measurement of cognitive stress via heart rate variability.pdf:PDF},
  issn      = {1557-170X},
  url       = {http://dx.doi.org/10.1109/EMBC.2014.6944243},
}


@INPROCEEDINGS{Ubiratan, 
    author={Ubiratan S. Freitas}, 
    booktitle={eTELEMED 2014, The Sixth International Conference on eHealth, Telemedicine, and Social Medicine}, 
    title={Remote Camera-based Pulse Oximetry}, 
    year={2014}, 
    month={Mar}, 
    pages={59-63}, 
    ISSN={2308-4359}
}

@INPROCEEDINGS{Kong, 
    author={Lingqin Kong and Yuejin Zhao and Liquan Dong and Yiyun Jian and Xiaoli Jin and Bing Li and Yun Feng and Ming Liu and Xiaohua Liu and Hong Wu}, 
    booktitle={Optics Express 21}, 
    title={Non-contact detection of oxygen saturation based on visible light imaging device using ambient light}, 
    year={2013}, 
    ISSN={1094-4087}
}

@inbook{Irani,
    title = "Improved Pulse Detection from Head Motions Using DCT",
    keywords = "Heartbeat rate, Head motion detection, Trajectory tracking, Feature point tracker, Electrocardiogram, Discrete cosine transforms, Principle component analysis",
    publisher = "Institute for Systems and Technologies of Information, Control and Communication",
    author = "Ramin Irani and Kamal Nasrollahi and Moeslund, {Thomas B.}",
    year = "2014",
    booktitle = "9th International Conference on Computer Vision Theory and Applications",
}

@InProceedings{6619284,
  author    = {Guha Balakrishnan and Fredo Durand and John Guttag},
  title     = {Detecting Pulse from Head Motions in Video},
  booktitle = {Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on},
  year      = {2013},
  pages     = {3430-3437},
  month     = {June},
  publisher = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  doi       = {10.1109/cvpr.2013.440},
  issn      = {1063-6919},
  url       = {http://dx.doi.org/10.1109/cvpr.2013.440},
}

@article{poh2011advancements,
  title={Advancements in noncontact, multiparameter physiological measurements using a webcam},
  author={Poh, Ming-Zher and McDuff, Daniel J and Picard, Rosalind W},
  journal={Biomedical Engineering, IEEE Transactions on},
  volume={58},
  number={1},
  pages={7--11},
  year={2011},
  publisher={IEEE}
}

@Proceedings{Datcu_2013,
  title       = {Noncontact automatic heart rate analysis in visible spectrum by specific face regions},
  year        = {2013},
  volume      = {767},
  address     = {Ruse},
  publisher   = {Association for Computing Machinery ({ACM})},
  attachments = {http://ii.tudelft.nl/sites/default/files/compsystech13[2].pdf},
  author      = {Dragos Datcu and Marina Cidota and Stephan Lukosch and Leon Rothkrantz},
  booktitle   = {Proceedings of the 14th International Conference on Computer Systems and Technologies - {CompSysTech} {\textquotesingle}13},
  doi         = {10.1145/2516775.2516805},
  isbn        = {978-1-4503-2021-4},
  journal     = {CompSysTech{\textquoteright}13 14-th International Conference on Computer Systems and Technologies},
  url         = {http://dx.doi.org/10.1145/2516775.2516805},
}

@ARTICLE{Landowska, 
    author={Agnieszka Landowska}, 
    journal={Metrology and Measurement Systems},
    title={Emotion Monitoring Verification of Physiological Characteristics Measurement Procedures},
    year={2014},
    volume={21}, 
    number={4}, 
    pages={719-732}, 
    month={Dec}, 
    doi={10.2478/mms-2014-0049}, 
    ISSN={2300-1941}
}

@INPROCEEDINGS{Sereevoravitgul, 
    author={Thundluck Sereevoravitgul and Toshiaki Kondo}, 
    booktitle={5th International Conference on Information and Communication Technology for Embedded Systems (ICICTES2014)}, 
    title={A Comparative Study for Heart Rate Measurement in Video Sequences}, 
    year={2014}, 
    month={Jan}
}

@INPROCEEDINGS{ViolaJones,
    author = {Paul Viola and Michael Jones},
    title = {Robust Real-time Object Detection},
    booktitle = {International Journal of Computer Vision},
    year = {2001}
}

@inproceedings{EdwardsAAM,
     author = {Edwards, G. J. and Taylor, C. J. and Cootes, T. F.},
     title = {Interpreting Face Images Using Active Appearance Models},
     booktitle = {Proceedings of the 3rd. International Conference on Face \& Gesture Recognition},
     series = {FG '98},
     year = {1998},
     isbn = {0-8186-8344-9},
     pages = {300--},
     url = {http://dl.acm.org/citation.cfm?id=520809.796067},
     acmid = {796067},
     publisher = {IEEE Computer Society},
     address = {Washington, DC, USA},
} 

@Article{Hjortskov_2004,
  author    = {Nis Hjortskov and Dag Rissén and AnneKatrine Blangsted and Nils Fallentin and Ulf Lundberg and Karen Søgaard},
  title     = {The effect of mental stress on heart rate variability and blood pressure during computer work},
  journal   = {European Journal of Applied Physiology},
  year      = {2004},
  volume    = {92},
  number    = {1-2},
  pages     = {84--89},
  month     = {jun},
  abstract  = {The aim was to evaluate the cardiovascular and subjective stress response to a combined physical and mental workload, and the effect of rest. Twelve females who had no prior experience of laboratory experiments participated in the study. Computer-work-related mental stressors were either added to or removed from a standardized computer work session in the laboratory. Beat-to-beat blood pressure and electrocardiogram (ECG) were recorded continuously during the experiment. The participants reported subjective experiences of stress in six categories using an 11-point scale before and at the end of the work. Heart rate variability (HRV) variables were calculated from the ECG recordings, and a reduction in the high-frequency component of HRV and an increase in the low- to high-frequency ratio were observed in the stress situation compared to the control session. No changes were seen in the low-frequency component of HRV. The stressors induced an increase in blood pressure compared to baseline that persisted, and for the diastolic pressure it even increased in the subsequent control session. No differences were observed for subjective experience of stress with the exception of a time trend in the exhaustion scale, i.e. a progression in reported exhaustion with time. The results and the dissociation between HRV and blood pressure variables—indicate that HRV is a more sensitive and selective measure of mental stress. It could be speculated that heart rate-derived variables reflect a central pathway in cardiovascular control mechanisms (‘‘central command’’), while the blood pressure response is more influenced by local conditions in the working muscles that partly mask the effect of changes in mental workloads. In the rest period after each work session, HRV and blood pressure variables were partly normalized as expected. However, an 8-min period of rest was insufficient to restore blood pressure to resting values.},
  doi       = {10.1007/s00421-004-1055-z},
  file      = {:Hjortskov_2004 - The effect of mental stress on heart rate variability and blood pressure during computer work.pdf:PDF},
  issue     = {1},
  masid     = {32693887},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00421-004-1055-z},
}

@InProceedings{Moses_2007,
  author    = {Ziev B. Moses and Linda J. Luecken and James C. Eason},
  title     = {Measuring Task-related Changes in Heart Rate Variability},
  booktitle = {2007 29th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society},
  year      = {2007},
  pages     = {644--647},
  month     = {aug},
  publisher = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  abstract  = {Small beat-to-beat differences in heart rate are the
result of dynamic control of the cardiovascular system by the
sympathetic and parasympathetic nervous systems. Heart
rate variability (HRV) has been positively correlated with
both mental and physical health. While many studies measure
HRV under rest conditions, few have measured HRV during
stressful situations. We describe an experimental protocol
designed to measure baseline, task, and recovery values of
HRV as a function of three different types of stressors. These
stressors involve an attention task, a cold pressor test, and a
videotaped speech presentation. We found a measurable
change in heart rate in participants (n=10) during each task
(all p’s < 0.05). The relative increase or decrease from pretask
heart rate was predicted by task (one-way ANOVA,
p=0.0001). Spectral analysis of HRV during the attention task
revealed consistently decreased measures of both high
(68±7%, mean±S.E.) and low (62±13%) frequency HRV
components as compared to baseline. HRV spectra for the
cold pressor and speech tasks revealed no consistent patterns
of increase or decrease from baseline measurements. We also
found no correlation in reactivity measures between any of
our tasks. These findings suggest that each of the tasks in our
experimental design elicits a different type of stress response
in an individual. Our experimental approach may prove
useful to biobehavioral researchers searching for factors that
determine individual differences in responses to stress in
daily life.},
  doi       = {10.1109/iembs.2007.4352372},
  file      = {:Moses_2007 - Measuring Task-related Changes in Heart Rate Variability.pdf:PDF},
  masid     = {50590784},
  url       = {http://dx.doi.org/10.1109/IEMBS.2007.4352372},
}

@INPROCEEDINGS{mental, 
    author={Dawei Zhou and Jiebo Luo and Vincent M.B. Silenzio and Yun Zhou and Jile Hu and Glenn Currier and Henry Kautz}, 
    booktitle={Proceedings Of The 29th AAAI Conference On Artificial Intelligence And The 27th Innovative Applications Of Artificial Intelligence Conferenc}, 
    title={Tackling Mental Health by Integrating Unobtrusive Multimodal Sensing}, 
    year={2015}, 
    month={April}, 
    ISSN={2374-3468}
}

@book{picard2000affective,
  title={Affective computing},
  author={Picard, Rosalind W},
  year={2000},
  publisher={MIT press}
}

@article{liu2009dynamic,
  title={Dynamic difficulty adjustment in computer games through real-time anxiety-based affective feedback},
  author={Liu, Changchun and Agrawal, Pramila and Sarkar, Nilanjan and Chen, Shuo},
  journal={International Journal of Human-Computer Interaction},
  volume={25},
  number={6},
  pages={506-529},
  year={2009},
  publisher={Taylor \& Francis}
}

@book{csikszentmihalyi1990psychology,
  title={The psychology of optimal experience},
  author={Csikszentmihalyi, Mihaly},
  year={1990},
  publisher={Harper \& Row}
}

@article{cowie2001emotion,
  title={Emotion recognition in human-computer interaction},
  author={Cowie, Roddy and Douglas-Cowie, Ellen and Tsapatsoulis, Nicolas and Votsis, George and Kollias, Stefanos and Fellenz, Winfried and Taylor, John G},
  journal={Signal Processing Magazine, IEEE},
  volume={18},
  number={1},
  pages={32--80},
  year={2001},
  publisher={IEEE}
}

@Article{allen2007photoplethysmography,
  author    = {John Allen},
  title     = {Photoplethysmography and its application in clinical physiological measurement},
  journal   = {Physiological measurement},
  year      = {2007},
  volume    = {28},
  number    = {3},
  pages     = {R1--R39},
  month     = {feb},
  abstract  = {Photoplethysmography (PPG) is a simple and low-cost optical technique that
can be used to detect blood volume changes in the microvascular bed of tissue.
It is often used non-invasively to make measurements at the skin surface. The
PPG waveform comprises a pulsatile (‘AC’) physiological waveform attributed
to cardiac synchronous changes in the blood volume with each heart beat,
and is superimposed on a slowly varying (‘DC’) baseline with various lower
frequency components attributed to respiration, sympathetic nervous system
activity and thermoregulation. Although the origins of the components of
the PPG signal are not fully understood, it is generally accepted that they
can provide valuable information about the cardiovascular system. There has
been a resurgence of interest in the technique in recent years, driven by the
demand for low cost, simple and portable technology for the primary care
and community based clinical settings, the wide availability of low cost and
small semiconductor components, and the advancement of computer-based
pulse wave analysis techniques. The PPG technology has been used in a
wide range of commercially available medical devices for measuring oxygen
saturation, blood pressure and cardiac output, assessing autonomic function
and also detecting peripheral vascular disease. The introductory sections of the
topical review describe the basic principle of operation and interaction of light
with tissue, early and recent history of PPG, instrumentation, measurement
protocol, and pulse wave analysis. The review then focuses on the applications
of PPG in clinical physiological measurements, including clinical physiological
monitoring, vascular assessment and autonomic function.},
  doi       = {10.1088/0967-3334/28/3/r01},
  file      = {:allen2007photoplethysmography - Photoplethysmography and its application in clinical physiological measurement.pdf:PDF},
  publisher = {{IOP} Publishing},
  url       = {http://dx.doi.org/10.1088/0967-3334/28/3/r01},
}


@article{susi2007serious,
  title={Serious games: An overview},
  author={Susi, Tarja and Johannesson, Mikael and Backlund, Per},
  year={2007},
  publisher={Institutionen f{\"o}r kommunikation och information}
}

@inproceedings{ravaja20051,
  title={The Psychophysiology of Video Gaming: Phasic Emotional Responses to Game Events},
  author={Ravaja, Niklas and Saari, Timo and Laarni, Jari and Kallinen, Kari and Salminen, Mikko and Holopainen, Jussi and J{\"a}rvinen, Aki},
  booktitle={International DiGRA Conference},
  year={2005}
}

@article{boyle2012engagement,
  title={Engagement in digital entertainment games: A systematic review},
  author={Boyle, Elizabeth A and Connolly, Thomas M and Hainey, Thomas and Boyle, James M},
  journal={Computers in Human Behavior},
  volume={28},
  number={3},
  pages={771--780},
  year={2012},
  publisher={Elsevier}
}

@article{jennett2008measuring,
  title={Measuring and defining the experience of immersion in games},
  author={Jennett, Charlene and Cox, Anna L and Cairns, Paul and Dhoparee, Samira and Epps, Andrew and Tijs, Tim and Walton, Alison},
  journal={International journal of human-computer studies},
  volume={66},
  number={9},
  pages={641--661},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{brown2004grounded,
  title={A grounded investigation of game immersion},
  author={Brown, Emily and Cairns, Paul},
  booktitle={CHI'04 extended abstracts on Human factors in computing systems},
  pages={1297--1300},
  year={2004},
  organization={ACM}
}

@article{weibel2011immersion,
  title={Immersion in computer games: The role of spatial presence and flow},
  author={Weibel, David and Wissmath, Bartholom{\"a}us},
  journal={International Journal of Computer Games Technology},
  volume={2011},
  pages={6},
  year={2011},
  publisher={Hindawi Publishing Corp.}
}

@article{engstrom2016impact,
  title={The impact of contextualization on immersion in healthcare simulation},
  author={Engstr{\"o}m, Henrik and Hagiwara, Magnus Andersson and Backlund, Per and Lebram, Mikael and Lundberg, Lars and Johannesson, Mikael and Sterner, Anders and S{\"o}derholm, Hanna Maurin},
  journal={Advances in Simulation},
  volume={1},
  number={1},
  pages={1},
  year={2016},
  publisher={BioMed Central}
}

@article{melcer2015games,
  title={Games Research Today: Analyzing the Academic Landscape 2000-2014},
  author={Melcer, Edward and Nguyen, Truong-Huy Dinh and Chen, Zhengxing and Canossa, Alessandro and El-Nasr, Magy Seif and Isbister, Katherine},
  journal={network},
  volume={17},
  pages={20},
  year={2015}
}

@book{koster2013theory,
  title={Theory of fun for game design},
  author={Koster, Raph},
  year={2013},
  publisher={" O'Reilly Media, Inc."}
}

@book{schell2014art,
  title={The Art of Game Design: A book of lenses},
  author={Schell, Jesse},
  year={2014},
  publisher={CRC Press}
}

@article{rani2006empirical,
  title={An empirical study of machine learning techniques for affect recognition in human--robot interaction},
  author={Rani, Pramila and Liu, Changchun and Sarkar, Nilanjan and Vanman, Eric},
  journal={Pattern Analysis and Applications},
  volume={9},
  number={1},
  pages={58--69},
  year={2006},
  publisher={Springer}
}

@article{sharma2006assessment,
  title={Assessment of computer game as a psychological stressor},
  author={Sharma, Ratna and Khera, SHVETA and Mohan, AMIT and Gupta, NIDHI and Ray, ROOMA BASU},
  journal={Indian journal of physiology and pharmacology},
  volume={50},
  number={4},
  pages={367},
  year={2006},
  publisher={DEPARTMENT OF PHYSIOLOGY ALL INDIAN INSTITUTE OF}
}

@article{fenton2012emotion,
  title={Emotion regulation and trader expertise: Heart rate variability on the trading floor.},
  author={Fenton-O'Creevy, Mark and Lins, Jeffrey T and Vohra, Shalini and Richards, Daniel W and Davies, Gareth and Schaaff, Kristina},
  journal={Journal of Neuroscience, Psychology, and Economics},
  volume={5},
  number={4},
  pages={227},
  year={2012},
  publisher={Educational Publishing Foundation}
}

@Article{appelhans2006heart,
  author    = {Appelhans, Bradley M and Luecken, Linda J},
  title     = {Heart rate variability as an index of regulated emotional responding.},
  journal   = {Review of general psychology},
  year      = {2006},
  volume    = {10},
  number    = {3},
  pages     = {229},
  abstract  = {The study of individual differences in emotional responding can provide considerable
insight into interpersonal dynamics and the etiology of psychopathology. Heart rate
variability (HRV) analysis is emerging as an objective measure of regulated emotional
responding (generating emotional responses of appropriate timing and magnitude). This
review provides a theoretical and empirical rationale for the use of HRV as an index of
individual differences in regulated emotional responding. Two major theoretical frameworks
that articulate the role of HRV in emotional responding are presented, and
relevant empirical literature is reviewed. The case is made that HRV is an accessible
research tool that can increase the understanding of emotion in social and psychopathological
processes.},
  file      = {:appelhans2006heart - Heart rate variability as an index of regulated emotional responding.pdf:PDF},
  publisher = {Educational Publishing Foundation},
}

@article{kivikangas2011review,
  title={A review of the use of psychophysiological methods in game research},
  author={Kivikangas, J Matias and Chanel, Guillaume and Cowley, Ben and Ekman, Inger and Salminen, Mikko and J{\"a}rvel{\"a}, Simo and Ravaja, Niklas},
  journal={Journal of Gaming \& Virtual Worlds},
  volume={3},
  number={3},
  pages={181--199},
  year={2011},
  publisher={Intellect}
}

@incollection{tijs2008dynamic,
  title={Dynamic game balancing by recognizing affect},
  author={Tijs, Tim JW and Brokken, Dirk and IJsselsteijn, Wijnand A},
  booktitle={Fun and Games},
  pages={88--93},
  year={2008},
  publisher={Springer}
}

@inproceedings{yamakoshi2007preliminary,
  title={A preliminary study on driver's stress index using a new method based on differential skin temperature measurement},
  author={Yamakoshi, Takehiro and Yamakoshi, Ken-ichi and Tanaka, Shinobu and Nogawa, Masamichi and Shibata, Mariko and Sawada, Y and Rolfe, P and Hirose, Yukio},
  booktitle={Engineering in Medicine and Biology Society, 2007. EMBS 2007. 29th Annual International Conference of the IEEE},
  pages={722--725},
  year={2007},
  organization={IEEE}
}

@inproceedings{yamaguchi2006evaluation,
  title={Evaluation of driver stress using biomarker in motor-vehicle driving simulator},
  author={Yamaguchi, Motonori and Wakasugi, J and Sakakima, J},
  booktitle={Engineering in Medicine and Biology Society, 2006. EMBS'06. 28th Annual International Conference of the IEEE},
  pages={1834--1837},
  year={2006},
  organization={IEEE}
}

@article{healey2005detecting,
  title={Detecting stress during real-world driving tasks using physiological sensors},
  author={Healey, Jennifer A and Picard, Rosalind W},
  journal={Intelligent Transportation Systems, IEEE Transactions on},
  volume={6},
  number={2},
  pages={156--166},
  year={2005},
  publisher={IEEE}
}


@article{schubert2009effects,
  title={Effects of stress on heart rate complexity—a comparison between short-term and chronic stress},
  author={Schubert, C and Lambertz, M and Nelesen, RA and Bardwell, W and Choi, J-B and Dimsdale, JE},
  journal={Biological psychology},
  volume={80},
  number={3},
  pages={325--332},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{choi2009using,
  title={Using heart rate monitors to detect mental stress},
  author={Choi, Jongyoon and Gutierrez-Osuna, Ricardo},
  booktitle={Wearable and Implantable Body Sensor Networks, 2009. BSN 2009. Sixth International Workshop on},
  pages={219--223},
  year={2009},
  organization={IEEE}
}

@article{cardena2000psychometric,
  title={Psychometric properties of the Stanford Acute Stress Reaction Questionnaire (SASRQ): A valid and reliable measure of acute stress},
  author={Cardena, Etzel and Koopman, Cheryl and Classen, Catherine and Waelde, Lynn C and Spiegel, David},
  journal={Journal of traumatic stress},
  volume={13},
  number={4},
  pages={719--734},
  year={2000},
  publisher={Springer}
}


@article{morris1995observations,
  title={Observations: SAM: the Self-Assessment Manikin; an efficient cross-cultural measurement of emotional response},
  author={Morris, Jon D},
  journal={Journal of advertising research},
  volume={35},
  number={6},
  pages={63--68},
  year={1995}
}

@book{kirk1982experimental,
  title={Experimental design},
  author={Kirk, Roger E},
  year={1982},
  publisher={Wiley Online Library}
}


@book{lane2015online,
  title={Online statistics education: An interactive multimedia course of study},
  author={Lane, David M},
  year={2015}
}


@article{trochim2001research,
  title={Research methods knowledge base},
  author={Trochim, William MK and Donnelly, James P},
  year={2001},
  publisher={Atomic Dog Pub.}
}


@article{campbell1986relabeling,
  title={Relabeling internal and external validity for applied social scientists},
  author={Campbell, Donald T},
  journal={New Directions for Program Evaluation},
  volume={1986},
  number={31},
  pages={67--77},
  year={1986},
  publisher={Wiley Online Library}
}

@Article{giannakakis2017stress,
  author    = {G. Giannakakis and M. Pediaditis and D. Manousos and E. Kazantzaki and F. Chiarugi and P.G. Simos and K. Marias and M. Tsiknakis},
  title     = {Stress and anxiety detection using facial cues from videos},
  journal   = {Biomedical Signal Processing and Control},
  year      = {2017},
  volume    = {31},
  pages     = {89--101},
  month     = {jan},
  abstract  = {This study develops a framework for the detection and analysis of stress/anxiety emotional states through video-recorded facial cues. A thorough experimental protocol was established to induce systematic variability in affective states (neutral, relaxed and stressed/anxious) through a variety of external and internal stressors. The analysis was focused mainly on non-voluntary and semi-voluntary facial cues in order to estimate the emotion representation more objectively. Features under investigation included eye-related events, mouth activity, head motion parameters and heart rate estimated through camera-based photoplethysmography. A feature selection procedure was employed to select the most robust features followed by classification schemes discriminating between stress/anxiety and neutral states with reference to a relaxed state in each experimental phase. In addition, a ranking transformation was proposed utilizing self reports in order to investigate the correlation of facial parameters with a participant perceived amount of stress/anxiety. The results indicated that, specific facial cues, derived from eye activity, mouth activity, head movements and camera based heart activity achieve good accuracy and are suitable as discriminative indicators of stress and anxiety.},
  doi       = {10.1016/j.bspc.2016.06.020},
  file      = {:giannakakis2017stress - Stress and anxiety detection using facial cues from videos.pdf:PDF},
  publisher = {Elsevier},
  url       = {http://dx.doi.org/10.1016/j.bspc.2016.06.020},
}

@Article{kranjec2014non,
  author    = {J. Kranjec and S. Begu{\v{s}} and G. Ger{\v{s}}ak and J. Drnov{\v{s}}ek},
  title     = {Non-contact heart rate and heart rate variability measurements: A review},
  journal   = {Biomedical Signal Processing and Control},
  year      = {2014},
  volume    = {13},
  pages     = {102--112},
  month     = {sep},
  abstract  = {The following paper investigates published work on non-contact human physiological parameter measurement, more precisely measurement of the human heart rate (HR) and consequently the heart rate variability (HRV), which is considered to be an important marker of autonomic nervous system activity proven to be predictive of the likelihood of future health related events. The ability to perform measurements of cardiac activity in a non-contact manner could prove to become an important alternative to the conventional methods in the clinical field as well as in the more commercially oriented fields. Some of the published work so far indicates that the measurement of cardiac activity in a non-contact manner is indeed possible and in some cases also very precise, however there are several limitations to the methods which need to be taken into account when performing the measurements. The following paper includes a short description of the two conventional methods, electrocardiogram (ECG) and photoplethysmography (PPG), and later on focuses on the novel methods of non-contact measuring of HR with capacitively coupled ECG, Doppler radar, optical vibrocardiography, thermal imaging, RGB camera and HR from speech. Our study represents a comparative review of these methods while emphasising their advantages and disadvantages.},
  doi       = {10.1016/j.bspc.2014.03.004},
  file      = {:kranjec2014non - Non-contact heart rate and heart rate variability measurements_ A review.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-08-24},
  url       = {http://dx.doi.org/10.1016/j.bspc.2014.03.004},
}

@InProceedings{li2014remote,
  author    = {Xiaobai Li and Jie Chen and Guoying Zhao and Matti Pietikainen},
  title     = {Remote Heart Rate Measurement from Face Videos under Realistic Situations},
  booktitle = {2014 {IEEE} Conference on Computer Vision and Pattern Recognition},
  year      = {2014},
  pages     = {4264--4271},
  month     = {jun},
  publisher = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  abstract  = {Heart rate is an important indicator of people’s physiological
state. Recently, several papers reported methods to
measure heart rate remotely from face videos. Those methods
work well on stationary subjects under well controlled
conditions, but their performance significantly degrades if
the videos are recorded under more challenging conditions,
specifically when subjects’ motions and illumination variations
are involved. We propose a framework which utilizes
face tracking and Normalized Least Mean Square adaptive
filtering methods to counter their influences. We test
our framework on a large difficult and public database
MAHNOB-HCI and demonstrate that our method substantially
outperforms all previous methods. We also use our
method for long term heart rate monitoring in a game evaluation
scenario and achieve promising results},
  doi       = {10.1109/cvpr.2014.543},
  file      = {:li2014remote - Remote Heart Rate Measurement from Face Videos under Realistic Situations.pdf:PDF},
  timestamp = {2016-08-23},
  url       = {http://dx.doi.org/10.1109/cvpr.2014.543},
}

@Article{blanik2014hybrid,
  author    = {Blanik, Nikolai and Abbas, Abbas K. and Venema, Boudewijn and Blazek, Vladimir and Leonhardt, Steffen},
  title     = {Hybrid optical imaging technology for long-term remote monitoring of skin perfusion and temperature behavior},
  journal   = {Journal of Biomedical Optics},
  year      = {2014},
  volume    = {19},
  number    = {1},
  pages     = {016012},
  abstract  = {Photoplethysmography imaging (PPGI) and infrared thermography imaging (IRTI) are contactless camera-based measurement methods for monitoring a wide range of basic vital parameters. In particular, PPGI enhances the classical contact-based photoplethysmography. Approved evaluation algorithms of the well-established PPG method can easily be adapted for detection of heart rate, heart rate variability, respiration rate (RR), respiratory variability (RV), and vasomotional activity with PPGI. The IRTI method primarily records temperature distribution of the observed object, but information on RR and RV can also be derived from IRTI by analyzing the development of temperature distribution in the nasal region. The main advantages of both monitoring methods are unobtrusive data acquisition and the possibility of assessing spatial assignment between vital parameters and body region. Hence, these methods enable long-term monitoring or the monitoring of effects with special local characteristics. Because the two systems supplement each, a combined hybrid application is proposed and its feasibility discussed.},
  doi       = {10.1117/1.JBO.19.1.016012},
  file      = {:blanik2014hybrid - Hybrid optical imaging technology for long-term remote monitoring of skin perfusion and temperature behavior.pdf:PDF},
  isbn      = {1083-3668},
  timestamp = {2016-08-23},
  url       = { http://dx.doi.org/10.1117/1.JBO.19.1.016012},
}

@Article{McDuff_2014,
  author    = {Daniel McDuff and Sarah Gontarek and Rosalind W. Picard},
  title     = {Remote Detection of Photoplethysmographic Systolic and Diastolic Peaks Using a Digital Camera},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2014},
  volume    = {61},
  number    = {12},
  pages     = {2948--2954},
  month     = {dec},
  abstract  = {We present a new method for measuring photoplethysmogram
(PPG) signals remotely using ambient light
and a digital camera that allows for accurate recovery of the
waveform morphology (from a distance of 3m). In particular,
we show that the peak-to-peak time between the systolic peak
and diastolic peak/inflection can be automatically recovered using
the second order derivative of the remotely measured waveform.
We compare measurements from the face with those captured
using a contact finger-tip sensor and show high agreement in
peak and interval timings. Furthermore, we show that results
can be significantly improved using orange, green and cyan color
channels compared to the tradition red, green and blue channel
combination. The absolute error in inter-beat-intervals was 26ms
and the absolute error in mean systolic-diastolic peak-to-peak
times was 12ms. The mean systolic-diastolic peak-to-peak times
measured using the contact sensor and the camera were highly
correlated, ρ = 0.94 (p<0.001). The results were obtained with a
camera frame-rate of only 30Hz. This technology has significant
potential for advancing healthcare.},
  doi       = {10.1109/tbme.2014.2340991},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp = {2016-08-23},
  url       = {http://dx.doi.org/10.1109/tbme.2014.2340991},
}

@InProceedings{tasli2014remote,
  author       = {H. Emrah Tasli and Amogh Gudi and Marten den Uyl},
  title        = {Remote {PPG} based vital sign measurement using adaptive facial regions},
  booktitle    = {2014 {IEEE} International Conference on Image Processing ({ICIP})},
  year         = {2014},
  pages        = {1410--1414},
  month        = {oct},
  organization = {IEEE},
  publisher    = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  doi          = {10.1109/icip.2014.7025282},
  file         = {:tasli2014remote - Remote PPG based vital sign measurement using adaptive facial regions.pdf:PDF},
  timestamp    = {2016-08-23},
  url          = {http://dx.doi.org/10.1109/icip.2014.7025282},
}

@InProceedings{lee2015heart,
  author       = {Dongseok Lee and Jeehoon Kim and Sungjun Kwon and Kwangsuk Park},
  title        = {Heart rate estimation from facial photoplethysmography during dynamic illuminance changes},
  booktitle    = {2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  year         = {2015},
  pages        = {2758--2761},
  month        = {aug},
  organization = {IEEE},
  publisher    = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  abstract     = {Camera-based remote photoplethysmography
(rPPG) enables low-cost, non-contact cardiovascular activity
monitoring. However, applying rPPG to practical use has some
limitations caused from the artifacts by illuminance changes.
During watching a video in a dark room, for example, watching
a TV at night without illuminance, there is a high correlation
between the brightness changes of a video and the illuminance
variation on the skin of the viewer’s face. In this study, we
propose an artifact reduction method in rPPG, which is caused
by the variation of the illuminance. The method subtracts the
artifacts from the raw facial rPPG signal by applying
multi-order curve fitting between the illuminance information
from the facial rPPG signal and the brightness information
from a video. On average, the results showed that signal-to-noise
ratio (SNR) increased from -11.74 to -4.19 dB and from -15.27 to
7.99 dB for low-dynamic-brightness and
high-dynamic-brightness video, respectively. In addition, the
root-mean-square-error (RMSE) of estimated heart rate
decreased from 11.00 to 1.82 bpm and from 9.88 to 4.65 bpm for
the videos, respectively.},
  doi          = {10.1109/embc.2015.7318963},
  file         = {:lee2015heart - Heart rate estimation from facial photoplethysmography during dynamic illuminance changes.pdf:PDF},
  url          = {http://dx.doi.org/10.1109/embc.2015.7318963},
}

@InProceedings{tulyakov2016self,
  author    = {Tulyakov, Sergey and Alameda-Pineda, Xavier and Ricci, Elisa and Yin, Lijun and Cohn, Jeffrey F and Sebe, Nicu},
  title     = {Self-adaptive matrix completion for heart rate estimation from face videos under realistic conditions},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2016},
  pages     = {2396--2404},
  abstract  = {Recent studies in computer vision have shown that, while practically invisible to a human observer, skin color changes due to blood flow can be captured on face videos and, surprisingly, be used to estimate the heart rate (HR). While considerable progress has been made in the last few years, still many issues remain open. In particular, state-of-the-art approaches are not robust enough to operate in natural conditions (e.g. in case of spontaneous movements, facial expressions, or illumination changes). Opposite to previous approaches that estimate the HR by processing all the skin pixels inside a fixed region of interest, we introduce a strategy to dynamically select face regions useful for robust HR estimation. Our approach, inspired by recent advances on matrix completion theory, allows us to predict the HR while simultaneously discover the best regions of the face to be used for estimation. Thorough experimental evaluation conducted on public benchmarks suggests that the proposed approach significantly outperforms state-of-the-art HR estimation methods in naturalistic conditions.},
  file      = {:tulyakov2016self - Self-adaptive matrix completion for heart rate estimation from face videos under realistic conditions.pdf:PDF},
}

@InProceedings{zhang2016multimodal,
  author    = {Zhang, Zheng and Girard, Jeff M and Wu, Yue and Zhang, Xing and Liu, Peng and Ciftci, Umur and Canavan, Shaun and Reale, Michael and Horowitz, Andy and Yang, Huiyuan and others},
  title     = {Multimodal spontaneous emotion corpus for human behavior analysis},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2016},
  pages     = {3438--3446},
  abstract  = {Emotion is expressed in multiple modalities, yet most research
has considered at most one or two. This stems in
part from the lack of large, diverse, well-annotated, multimodal
databases with which to develop and test algorithms.
We present a well-annotated, multimodal, multidimensional
spontaneous emotion corpus of 140 participants. Emotion
inductions were highly varied. Data were acquired from a
variety of sensors of the face that included high-resolution
3D dynamic imaging, high-resolution 2D video, and thermal
(infrared) sensing, and contact physiological sensors
that included electrical conductivity of the skin, respiration,
blood pressure, and heart rate. Facial expression was annotated
for both the occurrence and intensity of facial action
units from 2D video by experts in the Facial Action Coding
System (FACS). The corpus further includes derived features
from 3D, 2D, and IR (infrared) sensors and baseline
results for facial expression and action unit detection. The
entire corpus will be made available to the research community.},
}

@InProceedings{chwyl2016sapphire,
  author       = {B. Chwyl and A. G. Chung and R. Amelara and J. Deglint and D. A. Clausi and A. Wong},
  title        = {{SAPPHIRE}: Stochastically acquired photoplethysmogram for heart rate inference in realistic environments},
  booktitle    = {2016 {IEEE} International Conference on Image Processing ({ICIP})},
  year         = {2016},
  pages        = {1230--1234},
  month        = {sep},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {A novel method, Stochastically Acquired Photoplethysmogram
for Heart rate Inference in Realistic Environments
(SAPPHIRE), is proposed for robust remote heart rate measurement
through broadband video. A set of stochastically
sampled points from the cheek region is tracked and used
to construct corresponding time series observations via skin
erythema transforms. From these observations, a photoplethysmogram
(PPG) waveform is estimated via Bayesian
minimization, with the required posterior probability inferred
using a Monte Carlo approach. To mitigate the effects of
noise, the contribution of each observation is weighted based
on the observation’s likelihood to contain relevant data. A
bandpass filter is applied to the estimated PPG waveform to
omit implausible heart rate frequencies, and the heart rate
is estimated through frequency domain analysis. Experimental
results acquired from a set of thirty videos indicate
significantly improved performance in comparison to stateof-the-art
methods},
  doi          = {10.1109/icip.2016.7532554},
  file         = {:chwyl2016sapphire - SAPPHIRE_ Stochastically acquired photoplethysmogram for heart rate inference in realistic environments.pdf:PDF},
  review       = {t pf},
  url          = {http://dx.doi.org/10.1109/icip.2016.7532554},
}

@Article{takano2007heart,
  author    = {Chihiro Takano and Yuji Ohta},
  title     = {Heart rate measurement based on a time-lapse image},
  journal   = {Medical Engineering {\&} Physics},
  year      = {2007},
  volume    = {29},
  number    = {8},
  pages     = {853--857},
  month     = {oct},
  abstract  = {Using a time-lapse image acquired from a CCD camera, we developed a non-contact and non-invasive device, which could measure both
the respiratory and pulse rate simultaneously. The time-lapse image of a part of the subject’s skin was consecutively captured, and the changes
in the average image brightness of the region of interest (ROI) were measured for 30 s. The brightness data were processed by a series of
operations of interpolation as follows a first-order derivative, a low pass filter of 2 Hz, and a sixth-order auto-regressive (AR) spectral analysis.
Fourteen sound and healthy female subjects (22–27 years of age) participated in the experiments. Each subject was told to keep a relaxed
seating posture with no physical restriction. At the same time, heart rate was measured by a pulse oximeter and respiratory rate was measured
by a thermistor placed at the external naris. Using AR spectral analysis, two clear peaks could be detected at approximately 0.3 and 1.2 Hz.
The peaks were thought to correspond to the respiratory rate and the heart rate. Correlation coefficients of 0.90 and 0.93 were obtained for
the measurement of heart rate and respiratory rate, respectively.
© 2006 IPEM. Published by Elsevier Ltd. All rights reserved.},
  doi       = {10.1016/j.medengphy.2006.09.006},
  file      = {:takano2007heart - Heart rate measurement based on a time-lapse image.pdf:PDF},
  publisher = {Elsevier {BV}},
  review    = {- One of the first PPG initiatives;
- Able to rudimentary detect HR and RR signals, however no HR nor RR (e.g. bpm) is provided.
- ROI is selected manually
- Tests were performed for 30 seconds.},
  timestamp = {2016-08-25},
  url       = {http://dx.doi.org/10.1016/j.medengphy.2006.09.006},
}

@Article{bousefsaf2013continuous,
  author    = {Fr{\'{e}}d{\'{e}}ric Bousefsaf and Choubeila Maaoui and Alain Pruski},
  title     = {Continuous wavelet filtering on webcam photoplethysmographic signals to remotely assess the instantaneous heart rate},
  journal   = {Biomedical Signal Processing and Control},
  year      = {2013},
  volume    = {8},
  number    = {6},
  pages     = {568--574},
  month     = {nov},
  abstract  = {Photoplethysmographic signals obtained from a webcam are analyzed through a continuous wavelettransform to assess the instantaneous heart rate. The measurements are performed on human faces.Robust image and signal processing are introduced to overcome drawbacks induced by light and motionartifacts. In addition, the respiration signal is recovered using the heart rate series by respiratory sinusarrhythmia, the natural variation in heart rate driven by the respiration. The presented algorithms areimplemented on a mid-range computer and the overall method works in real-time. The performanceof the proposed heart and breathing rates assessment method was evaluated using approved contactprobes on a set of 12 healthy subjects. Results show high degrees of correlation between physiologi-cal measurements even in the presence of motion. This paper provides a motion-tolerant method thatremotely measures the instantaneous heart and breathing rates. These parameters are particularly usedin telemedicine and affective computing, where the heart rate variability analysis can provide an indexof the autonomic nervous system.},
  doi       = {10.1016/j.bspc.2013.05.010},
  file      = {:bousefsaf2013continuous - Continuous wavelet filtering on webcam photoplethysmographic signals to remotely assess the instantaneous heart rate.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.bspc.2013.05.010},
}

@Article{verkruysse2008remote,
  author    = {Wim Verkruysse and Lars O Svaasand and J Stuart Nelson},
  title     = {Remote plethysmographic imaging using ambient light},
  journal   = {Opt. Express},
  year      = {2008},
  volume    = {16},
  number    = {26},
  pages     = {21434},
  month     = {dec},
  abstract  = {Plethysmographic signals were measured remotely (>1m) using ambient light and a simple consumer level digital camera in movie mode. Heart and respiration rates could be quantified up to several harmonics. Although the green channel featuring the strongest plethysmographic signal, corresponding to an absorption peak by (oxy-) hemoglobin, the red and blue channels also contained plethysmographic information. The results show that ambient light photo-plethysmography may be useful for medical purposes such as characterization of vascular skin lesions (e.g., port wine stains) and remote sensing of vital signs (e.g., heart and respiration rates) for triage or sports purposes.},
  doi       = {10.1364/oe.16.021434},
  file      = {:verkruysse2008remote - Remote plethysmographic imaging using ambient light.pdf:PDF},
  publisher = {The Optical Society},
  timestamp = {2016-08-24},
  url       = {http://dx.doi.org/10.1364/oe.16.021434},
}

@Article{sun2012noncontact,
  author    = {Yu Sun and Sijung Hu and Vicente Azorin-Peris and Roy Kalawsky and Stephen Greenwald},
  title     = {Noncontact imaging photoplethysmography to effectively access pulse rate variability},
  journal   = {J. Biomed. Opt},
  year      = {2012},
  volume    = {18},
  number    = {6},
  pages     = {061205},
  month     = {oct},
  abstract  = {Noncontact imaging photoplethysmography (PPG) can provide physiological assessment at various anatomical locations with no discomfort to the patient. However, most previous imaging PPG (iPPG) systems have been limited by a low sample frequency, which restricts their use clinically, for instance, in the assessment of pulse rate variability (PRV). In the present study, plethysmographic signals are remotely captured via an iPPG system at a rate of 200 fps. The physiological parameters (i.e., heart and respiration rate and PRV) derived from the iPPG datasets yield statistically comparable results to those acquired using a contact PPG sensor, the gold standard. More importantly, we present evidence that the negative influence of initial low sample frequency could be compensated via interpolation to improve the time domain resolution. We thereby provide further strong support for the low-cost webcam-based iPPG technique and, importantly, open up a new avenue for effective noncontact assessment of multiple physiological parameters, with potential applications in the evaluation of cardiac autonomic activity and remote sensing of vital physiological signs.},
  doi       = {10.1117/1.jbo.18.6.061205},
  file      = {:sun2012noncontact - Noncontact imaging photoplethysmography to effectively access pulse rate variability.pdf:PDF},
  publisher = {{SPIE}-Intl Soc Optical Eng},
  review    = {- Support that low-end camera  (e.g. 20 FPS) is as good as a 200 FPS camera
- Low sample frequency (e.g. 20 fps) can be compensated using Interpolation to improve time domain resolution},
  url       = {http://dx.doi.org/10.1117/1.jbo.18.6.061205},
}

@Article{valenza2014revealing,
  author    = {Gaetano Valenza and Luca Citi and Antonio Lanat{\'{a}} and Enzo Pasquale Scilingo and Riccardo Barbieri},
  title     = {Revealing Real-Time Emotional Responses: a Personalized Assessment based on Heartbeat Dynamics},
  journal   = {Sci. Rep.},
  year      = {2014},
  volume    = {4},
  month     = {may},
  doi       = {10.1038/srep04998},
  file      = {:valenza2014revealing - Revealing Real-Time Emotional Responses a Personalized Assessment based on Heartbeat Dynamics.pdf:PDF},
  publisher = {Nature Publishing Group},
  url       = {http://dx.doi.org/10.1038/srep04998},
}

@Article{poh2010non,
  author    = {Ming-Zher Poh and Daniel J. McDuff and Rosalind W. Picard},
  title     = {Non-contact, automated cardiac pulse measurements using video imaging and blind source separation},
  journal   = {Opt. Express},
  year      = {2010},
  volume    = {18},
  number    = {10},
  pages     = {10762},
  month     = {may},
  abstract  = {Remote measurements of the cardiac pulse can provide comfortable physiological assessment without electrodes. However, attempts so far are non-automated, susceptible to motion artifacts and typically expensive. In this paper, we introduce a new methodology that overcomes these problems. This novel approach can be applied to color video recordings of the human face and is based on automatic face tracking along with blind source separation of the color channels into independent components. Using Bland-Altman and correlation analysis, we compared the cardiac pulse rate extracted from videos recorded by a basic webcam to an FDA-approved finger blood volume pulse (BVP) sensor and achieved high accuracy and correlation even in the presence of movement artifacts. Furthermore, we applied this technique to perform heart rate measurements from three participants simultaneously. This is the first demonstration of a low-cost accurate video-based method for contact-free heart rate measurements that is automated, motion-tolerant and capable of performing concomitant measurements on more than one person at a time.},
  doi       = {10.1364/oe.18.010762},
  publisher = {The Optical Society},
  url       = {http://dx.doi.org/10.1364/oe.18.010762},
}

@Article{mcduff2014improvements,
  author    = {Daniel McDuff and Sarah Gontarek and Rosalind W. Picard},
  title     = {Improvements in Remote Cardiopulmonary Measurement Using a Five Band Digital Camera},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2014},
  volume    = {61},
  number    = {10},
  pages     = {2593--2601},
  month     = {oct},
  abstract  = {Remote measurement of the blood volume pulse via photoplethysmography (PPG) using digital cameras and ambient light has great potential for healthcare and affective computing. However, traditional RGB cameras have limited frequency resolution. We present results of PPG measurements from a novel five band camera and show that alternate frequency bands, in particular an orange band, allowed physiological measurements much more highly correlated with an FDA approved contact PPG sensor. In a study with participants (n = 10) at rest and under stress, correlations of over 0.92 (p < 0.01) were obtained for heart rate, breathing rate, and heart rate variability measurements. In addition, the remotely measured heart rate variability spectrograms closely matched those from the contact approach. The best results were obtained using a combination of cyan, green, and orange (CGO) bands; incorporating red and blue channel observations did not improve performance. In short, RGB is not optimal for this problem: CGO is better. Incorporating alternative color channel sensors should not increase the cost of such cameras dramatically.},
  doi       = {10.1109/tbme.2014.2323695},
  file      = {:mcduff2014improvements - Improvements in Remote Cardiopulmonary Measurement Using a Five Band Digital Camera.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/tbme.2014.2323695},
}

@Article{de_Haan_2013,
  author    = {Gerard de Haan and Vincent Jeanne},
  title     = {Robust Pulse Rate From Chrominance-Based {rPPG}},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2013},
  volume    = {60},
  number    = {10},
  pages     = {2878--2886},
  month     = {oct},
  abstract  = {Remote photoplethysmography (rPPG) enables contactless monitoring of the blood volume pulse using a regular camera. Recent research focused on improved motion robustness, but the proposed blind source separation techniques (BSS) in RGB color space show limited success. We present an analysis of the motion problem, from which far superior chrominance-based methods emerge. For a population of 117 stationary subjects, we show our methods to perform in 92% good agreement (±1.96σ) with contact PPG, with RMSE and standard deviation both a factor of two better than BSS-based methods. In a fitness setting using a simple spectral peak detector, the obtained pulse-rate for modest motion (bike) improves from 79% to 98% correct, and for vigorous motion (stepping) from less than 11% to more than 48% correct. We expect the greatly improved robustness to considerably widen the application scope of the technology.},
  doi       = {10.1109/tbme.2013.2266196},
  file      = {:de_Haan_2013 - Robust Pulse Rate From Chrominance-Based rPPG.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/tbme.2013.2266196},
}

@Article{dingli2016webcam,
  author    = {Alexiei Dingli and Andreas Giordimaina},
  title     = {Webcam-based detection of emotional states},
  journal   = {The Visual Computer},
  year      = {2016},
  pages     = {1--11},
  month     = {sep},
  abstract  = {Game designers have to deal with the complex task of monitoring the emotional state of players in games. There are different elements with the game, which effect the player’s emotional status. Since the game play experience occurs almost unconsciously, traditional methods such as think aloud may disrupt the playing experience, thus skewing the results obtained. Other methods include fitting cables and electrodes to the player to monitor biological information. Although such devices can offer significant accurate results, they are not commonly found and may cause discomfort while playing games. Because of this, we propose a webcambased heart rate monitoring method that can be used to predict the player’s emotional state. We first analyzed the change in heart rate with respect to the players emotional state. This allowed us to find a correlation between emotional states, such as frustration, fun, challenge, and boredom. The second objective was to create a webcam-based method to monitor the heart rate. This was performed by extracting the RGB channels from the face region and then retrieving the underlying components using a dimensionality-reduction method. The results obtained from the webcam-based method were far from perfect, but this was expected, since we were performing the tests under realistic conditions. The last objective  was to predict the player’s emotional state using the heart rate obtained from the webcam-based method. The accuracy of the prediction was up to 76 %, which exceeded our initial aim. This system will be implemented in Unity 3D to make its integration and adoption easier.},
  doi       = {10.1007/s00371-016-1309-x},
  file      = {:dingli2016webcam - Webcam-based detection of emotional states.pdf:PDF},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/s00371-016-1309-x},
}

@Article{shao2016simultaneous,
  author    = {Dangdang Shao and Francis Tsow and Chenbin Liu and Yuting Yang and Nongjian Tao},
  title     = {Simultaneous Monitoring of Ballistocardiogram and Photoplethysmogram Using Camera},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2016},
  pages     = {1--1},
  abstract  = {We present a noncontact method to measure Ballistocardiogram (BCG) and Photoplethysmogram (PPG) simultaneously using a single camera. The method tracks the motion of facial features to determine displacement BCG, and extracts the corresponding velocity and acceleration BCGs by taking first and second temporal derivatives from the displacement BCG, respectively. The measured BCG waveforms are consistent with those reported in literature and also with those recorded with an accelerometer-based reference method. The method also tracks PPG based on the reflected light from the same facial region, which makes it possible to track both BCG and PPG with the same optics. We verify the robustness and reproducibility of the noncontact method with a small pilot study with 23 subjects. The presented method is the first demonstration of simultaneous BCG and PPG monitoring without wearing any extra equipment or marker by the subject.},
  doi       = {10.1109/tbme.2016.2585109},
  file      = {:shao2016simultaneous - Simultaneous Monitoring of Ballistocardiogram and Photoplethysmogram Using Camera.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/tbme.2016.2585109},
}

@Article{tarvainen2002advanced,
  author    = {M.P. Tarvainen and P.O. Ranta-aho and P.A. Karjalainen},
  title     = {An advanced detrending method with application to {HRV} analysis},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2002},
  volume    = {49},
  number    = {2},
  pages     = {172--175},
  abstract  = {An advanced, simple to use, detrending method to be used before heart rate variability analysis (HRV) is presented. The method is based on smoothness priors approach and operates like a time-varying FIR high pass filter. The effect of the detrending on time and frequency domain analysis of HRV is studied.},
  doi       = {10.1109/10.979357},
  file      = {:tarvainen2002advanced - An advanced detrending method with application to HRV analysis.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/10.979357},
}

@Article{qi2017video,
  author    = {Huan Qi and Zhenyu Guo and Xun Chen and Zhiqi Shen and Z. Jane Wang},
  title     = {Video-based human heart rate measurement using joint blind source separation},
  journal   = {Biomedical Signal Processing and Control},
  year      = {2017},
  volume    = {31},
  pages     = {309--320},
  month     = {jan},
  abstract  = {Remote (non-contact) measurements of human cardiopulmonary physiological parameters based on photoplethysmography (PPG) can lead to efficient and comfortable medical assessment, which is important in human healthcare. It was shown that human facial blood volume variation during cardiac cycle can be indirectly captured by common Red–Green–Blue (RGB) cameras. In this paper, we show that it is promising to incorporate data from different facial sub-regions to improve remote measurement performance. We propose a novel method for non-contact video-based human heart rate (HR) measurement by exploring correlations among facial sub-regions via joint blind source separation (J-BSS). To our knowledge, this is the first time that J-BSS approaches, instead of prevailing BSS techniques such as independent component analysis (ICA), is successfully applied in non-contact physiological parameter measurement. We test the proposed method on a large public database, which provides the subjects’ left-thumb plethysmograph signals as ground truth. Experimental results show that the proposed J-BSS method outperforms previous ICA-based methodologies.},
  doi       = {10.1016/j.bspc.2016.08.020},
  file      = {:qi2017video - Video-based human heart rate measurement using joint blind source separation.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.bspc.2016.08.020},
}

@Article{Wang_2016algorithmic,
  author    = {Wenjin Wang and Albertus den Brinker and Sander Stuijk and Gerard de Haan},
  title     = {Algorithmic Principles of Remote-{PPG}},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2016},
  pages     = {1--1},
  abstract  = {—This paper introduces a mathematical model that incorporates the pertinent optical and physiological properties of skin reflections with the objective to increase our understanding of the algorithmic principles behind remote photoplethysmography (rPPG). The model is used to explain the different choices that were made in existing rPPG methods for pulse extraction. The understanding that comes from the model can be used to design robust or application-specific rPPG solutions. We illustrate this by designing an alternative rPPG method where a projection plane orthogonal to the skin-tone is used for pulse extraction. A large benchmark on the various discussed rPPG methods shows that their relative merits can indeed be understood from the proposed model.},
  doi       = {10.1109/TBME.2016.2609282},
  file      = {:Wang_2016 - Algorithmic Principles of Remote-PPG.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/TBME.2016.2609282},
}

@Article{Wang_2016novel,
  author    = {Wenjin Wang and Sander Stuijk and Gerard de Haan},
  title     = {A Novel Algorithm for Remote Photoplethysmography: Spatial Subspace Rotation},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2016},
  volume    = {63},
  number    = {9},
  pages     = {1974--1984},
  month     = {sep},
  doi       = {10.1109/TBME.2015.2508602},
  file      = {Wang_2016 - Algorithmic Principles of Remote-PPG.pdf:Wang_2016 - Algorithmic Principles of Remote-PPG.pdf:PDF},
  issn      = {0018-9294},
  keywords  = {biomedical equipment;cameras;cardiology;image denoising;independent component analysis;medical image processing;photoplethysmography;reviews;2SR algorithm;2SR outperforms;ICA-based approach;MATLAB code;Pearson correlation and precision;SNR;benchmark dataset;body-motions;camera;complex illuminance conditions;pulse extraction;pulse frequency spectrum;pulse-rate recovery;remote photoplethysmography;skin mask;skin-tone;spatial subspace rotation;spatially redundant pixel-sensors;state-of-the-art algorithms;temporal rotation;Blood;Cameras;Color;Photoplethysmography;Robustness;Skin;Biomedical monitoring;colors;photoplethysmography;remote sensing},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/TBME.2015.2508602},
}

@InCollection{taelman2009influence,
  author       = {Joachim Taelman and S. Vandeput and A. Spaepen and S. Van Huffel},
  title        = {Influence of Mental Stress on Heart Rate and Heart Rate Variability},
  booktitle    = {{IFMBE} Proceedings},
  publisher    = {Springer Science $\mathplus$ Business Media},
  year         = {2009},
  pages        = {1366--1369},
  abstract     = {Stress is a huge problem in today’s society. Being able to measure stress, therefore, may help to address this problem. Although stress has a psychological origin, it affects several physiological processes in the human body: increased muscle tension in the neck, change in concentration of several hormones and a change in heart rate (HR) and heart rate variability (HRV). The brain innervates the heart by means of stimuli via the Autonomic Nervous System (ANS), which is divided into sympathetic and parasympathetic branches. The sympathetic activity leads to an increase in HR (e.g. during sports exercise), while parasympathetic activity induces a lower HR (e.g. during sleep). The two circuits are constantly interacting and this interaction is reflected in HRV. HRV, therefore, provides a measure to express the activity of the ANS, and may consequently provide a measure for stress. We therefore explored measures of HR and HRV with an imposed stressful situation. We recorded changes in HR and HRV in a group of 28 subjects at rest, and with a mental stressor. The results suggest that HR and HRV change with a mental task. HR and HRV recordings may have the potential, therefore, to measure stress levels and guide preventive measures to reduce stress related illnesses.},
  doi          = {10.1007/978-3-540-89208-3_324},
  file         = {:taelman2009influence - Influence of Mental Stress on Heart Rate and Heart Rate Variability.pdf:PDF},
  organization = {Springer},
  timestamp    = {2016-10-14},
  url          = {http://dx.doi.org/10.1007/978-3-540-89208-3_324},
}

@Article{wang2015exploiting,
  author    = {Wenjin Wang and Sander Stuijk and Gerard de Haan},
  title     = {Exploiting Spatial Redundancy of Image Sensor for Motion Robust {rPPG}},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2015},
  volume    = {62},
  number    = {2},
  pages     = {415--425},
  month     = {feb},
  abstract  = {Remote photoplethysmography (rPPG) techniques can measure cardiac activity by detecting pulse-induced color variations on human skin using an RGB camera. State-of-the-art rPPG methods are sensitive to subject body motions (e.g., motion-induced color distortions). This study proposes a novel framework to improve the motion robustness of rPPG. The basic idea of this paper originates from the observation that a camera can simultaneously sample multiple skin regions in parallel, and each of them can be treated as an independent sensor for pulse measurement. The spatial redundancy of an image sensor can thus be exploited to distinguish the pulse signal from motion-induced noise. To this end, the pixel-based rPPG sensors are constructed to estimate a robust pulse signal using motion-compensated pixel-to-pixel pulse extraction, spatial pruning, and temporal filtering. The evaluation of this strategy is not based on a full clinical trial, but on 36 challenging benchmark videos consisting of subjects that differ in gender, skin types, and performed motion categories. Experimental results show that the proposed method improves the SNR of the state-of-the-art rPPG technique from 3.34 to 6.76 dB, and the agreement (±1.96σ) with instantaneous reference pulse rate from 55% to 80% correct. ANOVA with post hoc comparison shows that the improvement on motion robustness is significant. The rPPG method developed in this study has a performance that is very close to that of the contact-based sensor under realistic situations, while its computational efficiency allows real-time processing on an off-the-shelf computer.},
  doi       = {10.1109/tbme.2014.2356291},
  file      = {:wang2015exploiting - Exploiting Spatial Redundancy of Image Sensor for Motion Robust rPPG.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/tbme.2014.2356291},
}

@InProceedings{bevilacqua2016variations,
  author       = {Fernando Bevilacqua and Per Backlund and Henrik Engstrom},
  title        = {Variations of Facial Actions While Playing Games with Inducing Boredom and Stress},
  booktitle    = {2016 8th International Conference on Games and Virtual Worlds for Serious Applications ({VS}-{GAMES})},
  year         = {2016},
  pages        = {1--8},
  month        = {sep},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {This paper presents an experiment aimed at empirically exploring the variations of facial actions (FA) during gaming sessions with induced boredom and stress. Twenty adults with different ages and gaming experiences played three games while being recorded by a video camera and monitored by a heart rate sensor. The games were carefully designed to have a linear progression from a boring to a stressful state. Selfreported answers indicate participants perceived the games as being boring at the beginning and stressful at the end. The 6 hours of recordings of all subjects were manually analyzed and FA were annotated. We annotated FA that appeared in the recordings at least twice; annotations were categorized by the period when they happened (boring/stressful part of the games) and analysed on a group and on an individual level. Group level analysis revealed that FA patterns were related to no more than 25% of the subjects. The individual level analysis revealed particular patterns for 50% of the subjects. More FA annotations were made during the stressful part of the games. We conclude that, for the context of our experiment, FA provide an unclear foundation for detection of boredom/stressful states when observed from a group level perspective, while the individual level perspective might produce more information.},
  doi          = {10.1109/vs-games.2016.7590374},
  file         = {bevilacqua2016variations - Variations of Facial Actions While Playing Games with Inducing Boredom and Stress.pdf:bevilacqua2016variations - Variations of Facial Actions While Playing Games with Inducing Boredom and Stress.pdf:PDF},
  url          = {http://dx.doi.org/10.1109/vs-games.2016.7590374},
}

@Article{eleuteri2012efficient,
  author    = {Eleuteri, Antonio and Fisher, Anthony C and Groves, David and Dewhurst, Christpher J},
  title     = {An Efficient Time-Varying Filter for Detrending and Bandwidth Limiting the Heart Rate Variability Tachogram without Resampling: {MATLAB} Open-Source Code and Internet Web-Based Implementation},
  journal   = {Computational and Mathematical Methods in Medicine},
  year      = {2012},
  volume    = {2012},
  pages     = {1--6},
  abstract  = {The heart rate variability (HRV) signal derived from the ECG is a beat-to-beat record of RR intervals and is, as a time series, irregularly sampled. It is common engineering practice to resample this record, typically at 4 Hz, onto a regular time axis for analysis in advance of time domain filtering and spectral analysis based on the DFT. However, it is recognised that resampling introduces noise and frequency bias. The present work describes the implementation of a time-varying filter using a smoothing priors approach based on a Gaussian process model, which does not require data to be regular in time. Its output is directly compatible with the Lomb-Scargle algorithm for power density estimation. A web-based demonstration is available over the Internet for exemplar data. The MATLAB (MathWorks Inc.) code can be downloaded as open source.},
  doi       = {10.1155/2012/578785},
  file      = {:eleuteri2012efficient - An Efficient Time-Varying Filter for Detrending and Bandwidth Limiting the Heart Rate Variability Tachogram without Resampling.pdf:PDF},
  publisher = {Hindawi Publishing Corporation},
  timestamp = {2016-12-06},
  url       = {http://dx.doi.org/10.1155/2012/578785},
}

@InProceedings{xu2016study,
  author       = {Beilei Xu and Himanshu Madhu and Lalit K. Mestha},
  title        = {A study of the effect of subject motion to pulse rate estimation},
  booktitle    = {2016 38th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
  year         = {2016},
  pages        = {4901--4904},
  month        = {aug},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {we presented a systematic study of how subject head motion affects pulse rate estimation using photoplethysmography from the subject’s face. We evaluated the performance at various steps in the process, including object tracking, skin blob detection, pulse signal extraction and pulse rate estimation. We demonstrated that the signal-to-noise ratio of the power spectrum is a good indicator of signal artifacts induced by subject motion, thus can be used as a quantitative metric in continuous pulse rate monitoring to reduce estimation errors.},
  doi          = {10.1109/embc.2016.7591826},
  file         = {:xu2016study - A study of the effect of subject motion to pulse rate estimation.pdf:PDF},
  timestamp    = {2016-12-07},
  url          = {http://dx.doi.org/10.1109/embc.2016.7591826},
}

@Article{sun2016photoplethysmography,
  author    = {Yu Sun and Nitish Thakor},
  title     = {Photoplethysmography Revisited: From Contact to Noncontact, From Point to Imaging},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2016},
  volume    = {63},
  number    = {3},
  pages     = {463--477},
  month     = {mar},
  abstract  = {Photoplethysmography (PPG) is a noninvasive optical technique for detecting microvascular blood volume changes in tissues. Its ease of use, low cost and convenience make it an attractive area of research in the biomedical and clinical communities. Nevertheless, its single spot monitoring and the need to apply a PPG sensor directly to the skin limit its practicality in situations such as perfusion mapping and healing assessments or when free movement is required. The introduction of fast digital cameras into clinical imaging monitoring and diagnosis systems, the desire to reduce the physical restrictions, and the possible new insights that might come from perfusion imaging and mapping inspired the evolution of the conventional PPG technology to imaging PPG (IPPG). IPPG is a noncontact method that can detect heartgenerated pulse waves by means of peripheral blood perfusion measurements. Since its inception, IPPG has attracted significant public interest and provided opportunities to improve personal healthcare. This study presents an overview of the wide range of IPPG systems currently being introduced along with examples of their application in various physiological assessments. We believe that the widespread acceptance of IPPG is happening, and it will dramatically accelerate the promotion of this healthcare model in the near future.},
  doi       = {10.1109/tbme.2015.2476337},
  file      = {:sun2016photoplethysmography - Photoplethysmography Revisited_ From Contact to Noncontact, From Point to Imaging.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/tbme.2015.2476337},
}

@Article{fauquet2016heart,
  author    = {Philippe Fauquet-Alekhine and Laetitia Rouillac and J{\'{e}}r{\^{o}}me Berton and Jean-Claude Granry},
  title     = {Heart Rate vs Stress Indicator for Short Term Mental Stress},
  journal   = {British Journal of Medicine and Medical Research},
  year      = {2016},
  volume    = {17},
  number    = {7},
  pages     = {1--11},
  month     = {jan},
  abstract  = {Heart rate variation (HR) being identified as depending on subjects’ stress state when submitted to short term mental stress, this study aimed at analyzing whether or not it could be possible to find a mathematical relationship between the average heart rate variation and the intensity S of a stress indicator in case of short term mental stress, whatever the stress indicator is. The method consisted in working the hypothesis by gathering data providing HR and ratio of frequency power of HRV (Heart Rate Variability) for different level of stress, HRV being considered as a stress indicator and presenting the advantage of being widely used in studies, therefore providing numerous data in the literature. From this data, a mathematical model was designed and then assessed by testing its reliability when applied to HR variation versus different types of stress indicators (EMG, GSR, Work Load, questionnaires such as STAI-S, ALES). The correlation obtained between the model and the data provided by the literature (24 points from 8 studies gathering 272 subjects) gave r=.95 (p<.0001) which allowed us to validate the model. Limits of the model were identified and discussed.},
  doi       = {10.9734/bjmmr/2016/27593},
  file      = {:fauquet2016heart - Heart Rate vs Stress Indicator for Short Term Mental Stress.pdf:PDF},
  publisher = {Sciencedomain International},
  url       = {http://dx.doi.org/10.9734/bjmmr/2016/27593},
}

@InProceedings{mcduff2016discovering,
  author       = {Daniel McDuff},
  title        = {Discovering facial expressions for states of amused, persuaded, informed, sentimental and inspired},
  booktitle    = {Proceedings of the 18th {ACM} International Conference on Multimodal Interaction - {ICMI} 2016},
  year         = {2016},
  pages        = {71--75},
  organization = {ACM},
  publisher    = {Association for Computing Machinery ({ACM})},
  abstract     = {Facial expressions play a significant role in everyday interactions. A majority of the research on facial expressions of emotion has focused on a small set of "basic" states. However, in real-life the expression of emotions is highly context dependent and prototypic expressions of "basic" emotions may not always be present. In this paper we attempt to discover expressions associated with alternate states of informed, inspired, persuaded, sentimental and amused based on a very large dataset of observed facial responses. We used a curated set of 395 everyday videos that were found to reliably elicit the states and recorded 49,869 facial responses as viewers watched the videos in their homes. Using automated facial coding we quantified the presence of 18 facial actions in each of the 23.4 million frames. Lip corner pulls, lip sucks and inner brow raises were prominent in sentimental responses. Outer brow raises and eye widening were prominent in persuaded and informed responses. More brow furrowing distinguished informed from persuaded responses potentially indicating higher cognition.},
  doi          = {10.1145/2993148.2993192},
  file         = {:mcduff2016discovering - Discovering facial expressions for states of amused, persuaded, informed, sentimental and inspired.pdf:PDF},
  url          = {http://dx.doi.org/10.1145/2993148.2993192},
}

@InCollection{samara2016sensing,
  author       = {Anas Samara and Leo Galway and Raymond Bond and Hui Wang},
  title        = {Sensing Affective States Using Facial Expression Analysis},
  booktitle    = {Ubiquitous Computing and Ambient Intelligence},
  publisher    = {Springer Nature},
  year         = {2016},
  pages        = {341--352},
  abstract     = {An important factor for the next generation of Human Computer Interaction is the implementation of an interaction model that automatically reasons in context of the users goals, attitudes, affective characteristics and capabilities, and adapts the system accordingly. Although various techniques have been proposed for automatically detecting affective states using facial expression, this is still a research challenge in terms of classification accuracy. This paper investigates an extensible automatic affective state detection approach via the analysis of facial expressions from digital photographs. The main contribution of this study can be summarised in two points. Firstly, utilising facial point distance vectors within the representation of facial expressions is shown to be more accurate and robust in comparison to using standard Cartesian coordinates. Secondly, employing a two-stage Support Vector Machine-based classification model, entitled Hierarchical Parallelised Binary Support Vector Machines (HPBSVM), is shown to improve classification performance over other machine learning techniques. The resulting classification model has been evaluated using two different facial expression datasets (namely CKPLUS and KDEF), yielding accuracy rates of 96.9% and 96.2% over each dataset respectively.},
  doi          = {10.1007/978-3-319-48746-5_35},
  file         = {:samara2016sensing - Sensing Affective States Using Facial Expression Analysis.pdf:PDF},
  organization = {Springer},
}

@InProceedings{arroyo2008towards,
  author    = {Arroyo-Palacios, J and Romano, DM},
  title     = {Towards a standardization in the use of physiological signals for affective recognition systems},
  booktitle = {Measuring Behavior},
  year      = {2008},
  abstract  = {The implementation of physiological signals, as an approach for emotion recognition in computer systems, is not a straight forward task. This paper discusses five main areas that lack of standards and guided principles, which have led Human-Computer Interaction (HCI) researchers to take critical decisions about (i) models, (ii) stimulus, (iii) measures, (iv) features and (v) algorithms with some degree of uncertainty about their results. Methodology standardization would allow comparison of results, reusability of findings and easier integration of the various affective recognition systems created. The background theory is given for each of the five areas and the related work from psychology is briefly reviewed. A comparison table of the HCI common approaches of the five discussed areas is presented, and finally some considerations to take the best decisions are discussed. The aim of this paper is to provide directions on which the future research efforts for affective recognition in HCI should be focused on.},
  file      = {:arroyo2008towards - Towards a standardization in the use of physiological signals for affective recognition systems.pdf:PDF},
}

@InProceedings{brogni2006variations,
  author       = {Andrea Brogni and Vinoba Vinayagamoorthy and Anthony Steed and Mel Slater},
  title        = {Variations in physiological responses of participants during different stages of an immersive virtual environment experiment},
  booktitle    = {Proceedings of the {ACM} symposium on Virtual reality software and technology - {VRST} {\textquotesingle}06},
  year         = {2006},
  pages        = {376--382},
  organization = {ACM},
  publisher    = {Association for Computing Machinery ({ACM})},
  abstract     = {This paper presents a study of the fine grain physiological responses of participants to an immersive virtual simulation of an urban environment. The analysis of differences in participant responses at various stages of the experiment (baseline recordings, training, first half and second half of the urban simulation) are examined in detail. It was found that participants typically show a stress response during the training phase and a stress response towards the end of the simulation of the urban experience. There is also some evidence that variations in the level of visual realism based the texture strategy used was associated with changes in mental stress.},
  doi          = {10.1145/1180495.1180572},
  file         = {:brogni2006variations - Variations in physiological responses of participants during different stages of an immersive virtual environment experiment.pdf:PDF},
}

@InProceedings{lin2008using,
  author       = {Tao Lin and Akinobu Maejima and Shigeo Morishima},
  title        = {Using subjective and physiological measures to evaluate audience-participating movie experience},
  booktitle    = {Proceedings of the working conference on Advanced visual interfaces - {AVI} {\textquotesingle}08},
  year         = {2008},
  pages        = {49--56},
  organization = {ACM},
  publisher    = {Association for Computing Machinery ({ACM})},
  abstract     = {In this paper we subjectively and physiologically investigate the effects of the audiences 3D virtual actor in a movie on their movie experience, using the audience participating movie DIM as the object of study. In DIM, the photo-realistic 3D virtual actors of audience are constructed by combining current computer graphics (CG) technologies and can act different roles in a pre-rendered CG movie. To facilitate the investigation, we presented three versions of a CG movie to an audience - a Traditional version, its Self-DIM (SDIM) version with the participation of the audience’s virtual actor, and its Self-Friend-DIM (SFDIM) version with the co-participation of the audience and his friends virtual actors. The results show that the participation of audience’s 3D virtual actors indeed cause increased subjective sense of presence and engagement, and emotional reaction; moreover, SFDIM performs significantly better than SDIM, due to increased social presence. Interestingly, when watching the three movie versions, subjects experienced not only significantly different galvanic skin response (GSR) changes on average - changing trend over time, and number of fluctuations - but they also experienced phasic GSR increase when watching their own and friends virtual 3D actors appearing on the movie screen. These results suggest that the participation of the 3D virtual actors in a movie can improve interaction and communication between audience and the movie.},
  doi          = {10.1145/1385569.1385580},
  file         = {:lin2008using - Using subjective and physiological measures to evaluate audience-participating movie experience.pdf:PDF},
}

@Article{meehan2002physiological,
  author    = {Michael Meehan and Brent Insko and Mary Whitton and Frederick P. Brooks},
  title     = {Physiological measures of presence in stressful virtual environments},
  journal   = {{ACM} Transactions on Graphics},
  year      = {2002},
  volume    = {21},
  number    = {3},
  pages     = {645--652},
  month     = {jul},
  abstract  = {A common measure of the quality or effectiveness of a virtual environment (VE) is the amount of presence it evokes in users. Presence is often defined as the sense of being there in a VE. There has been much debate about the best way to measure presence, and presence researchers need, and have sought, a measure that is reliable, valid, sensitive, and objective. We hypothesized that to the degree that a VE seems real, it would evoke physiological responses similar to those evoked by the corresponding real environment, and that greater presence would evoke a greater response. To examine this, we conducted three experiments, the results of which support the use of physiological reaction as a reliable, valid, sensitive, and objective presence measure. The experiments compared participants’ physiological reactions to a non-threatening virtual room and their reactions to a stressful virtual height situation. We found that change in heart rate satisfied our requirements for a measure of presence, change in skin conductance did to a lesser extent, and that change in skin temperature did not. Moreover, the results showed that inclusion of a passive haptic element in the VE significantly increased presence and that for presence evoked: 30FPS > 20FPS > 15FPS.},
  doi       = {10.1145/566654.566630},
  file      = {:meehan2002physiological - Physiological measures of presence in stressful virtual environments.pdf:PDF},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Comment{jabref-meta: databaseType:bibtex;}
