% Encoding: UTF-8

@Article{dlib09,
  author        = {Davis E. King},
  title         = {Dlib-ml: A Machine Learning Toolkit},
  journal       = {Journal of Machine Learning Research},
  year          = {2009},
  volume        = {10},
  pages         = {1755-1758},
  __markedentry = {[bevf:6]},
  crossref      = {a},
}
@article{lai2015deep,
  title={Deep Cascaded Regression for Face Alignment},
  author={Lai, Hanjian and Xiao, Shengtao and Cui, Zhen and Pan, Yan and Xu, Chunyan and Yan, Shuicheng},
  journal={arXiv preprint arXiv : 1510 . 09083},
  year={2015}
}

@inproceedings{wu2015robust,
  title={Robust Facial Landmark Detection under Significant Head Poses and Occlusion},
  author={Wu, Yue and Ji, Qiang},
  booktitle={Proc. Int. Conf. Comput. Vision. IEEE},
  volume={1},
  year={2015}
}

@inproceedings{burgos2013robust,
  title={Robust face landmark estimation under occlusion},
  author={Burgos-Artizzu, Xavier P and Perona, Pietro and Doll{\'a}r, Piotr},
  booktitle={Computer Vision (ICCV), 2013 IEEE International Conference on},
  pages={1513--1520},
  year={2013},
  organization={IEEE}
}

@inproceedings{kazemi2014one,
  title={One millisecond face alignment with an ensemble of regression trees},
  author={Kazemi, Vahdat and Sullivan, Josephine},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},
  pages={1867--1874},
  year={2014},
  organization={IEEE}
}

@inproceedings{xiong2013supervised,
  title={Supervised descent method and its applications to face alignment},
  author={Xiong, Xuehan and De la Torre, Fernando},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on},
  pages={532--539},
  year={2013},
  organization={IEEE}
}

@inproceedings{baltruvsaitis20123d,
  title={3D constrained local model for rigid and non-rigid facial tracking},
  author={Baltru{\v{s}}aitis, Tadas and Robinson, Peter and Morency, Louis-Philippe},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on},
  pages={2610--2617},
  year={2012},
  organization={IEEE}
}

@article{cao2014face,
  title={Face alignment by explicit shape regression},
  author={Cao, Xudong and Wei, Yichen and Wen, Fang and Sun, Jian},
  journal={International Journal of Computer Vision},
  volume={107},
  number={2},
  pages={177--190},
  year={2014},
  publisher={Springer}
}

@inproceedings{ren2014face,
  title={Face alignment at 3000 fps via regressing local binary features},
  author={Ren, Shaoqing and Cao, Xudong and Wei, Yichen and Sun, Jian},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},
  pages={1685--1692},
  year={2014},
  organization={IEEE}
}

@article{viola2004robust,
  title={Robust real-time face detection},
  author={Viola, Paul and Jones, Michael J},
  journal={International journal of computer vision},
  volume={57},
  number={2},
  pages={137--154},
  year={2004},
  publisher={Springer}
}

@inproceedings{cristinacce2006feature,
  title={Feature Detection and Tracking with Constrained Local Models.},
  author={Cristinacce, David and Cootes, Timothy F},
  booktitle={BMVC},
  volume={1},
  number={2},
  pages={3},
  year={2006},
  organization={Citeseer}
}

@inproceedings{cheng20143d,
  title={3D facial geometric features for constrained local model},
  author={Cheng, Shiyang and Zafeiriou, Stefanos and Asthana, Akshay and Pantic, Maja},
  booktitle={Image Processing (ICIP), 2014 IEEE International Conference on},
  pages={1425--1429},
  year={2014},
  organization={IEEE}
}

@inproceedings{sagonas2013300,
  title={300 faces in-the-wild challenge: The first facial landmark localization challenge},
  author={Christos Sagonas and Georgios Tzimiropoulos and Stefanos Zafeiriou and Maja Pantic},
  booktitle={Computer Vision Workshops (ICCVW), 2013 IEEE International Conference on},
  pages={397--403},
  year={2013},
  organization={IEEE}
}

@article{belhumeur2013localizing,
  title={Localizing parts of faces using a consensus of exemplars},
  author={Belhumeur, Peter N and Jacobs, David W and Kriegman, David J and Kumar, Narendra},
  journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  volume={35},
  number={12},
  pages={2930--2940},
  year={2013},
  publisher={IEEE}
}

@incollection{le2012interactive,
  title={Interactive facial feature localization},
  author={Le, Vuong and Brandt, Jonathan and Lin, Zhe and Bourdev, Lubomir and Huang, Thomas S},
  booktitle={Computer Vision--ECCV 2012},
  pages={679--692},
  year={2012},
  publisher={Springer}
}

@Book{csikszentmihalyi1991flow,
  title     = {Flow: The psychology of optimal experience},
  publisher = {Harper Perennial},
  year      = {1991},
  author    = {Csikszentmihalyi, Mihaly},
  volume    = {41},
  address   = {New York},
}

@phdthesis{yu2010facial,
  title={Facial feature detection and tracking with a 3D constrained local model},
  author={Yu, Meng},
  year={2010},
  school={University of St Andrews}
}

@techreport{maris2015,
  title={Implementation and Study of Cascaded-Regression Methods for Facial Feature Points Detection},
  author={Andrej Maris},
  year={2015},
  school={Imperial College London}
}

@article{bradski2000opencv,
  title={The opencv library},
  author={Bradski, Gary and others},
  journal={Doctor Dobbs Journal},
  volume={25},
  number={11},
  pages={120--126},
  year={2000},
  publisher={M AND T PUBLISHING INC}
}

@InCollection{heylen2005facial,
  author    = {Heylen, Dirk and Ghijsen, Mattijs and Nijholt, Anton and op den Akker, Rieks},
  title     = {Facial signs of affect during tutoring sessions},
  booktitle = {Affective Computing and Intelligent Interaction},
  publisher = {Springer},
  year      = {2005},
  pages     = {24--31},
  file      = {:heylen2005facial - Facial signs of affect during tutoring sessions.pdf:PDF},
}

@InProceedings{jerritta2011physiological,
  author       = {S Jerritta and M Murugappan and R Nagarajan and Khairunizam Wan},
  title        = {Physiological signals based human emotion Recognition: a review},
  booktitle    = {2011 {IEEE} 7th International Colloquium on Signal Processing and its Applications},
  year         = {2011},
  pages        = {410--415},
  month        = {mar},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {Recent research in the field of Human Computer Interaction aims at recognizing the user’s emotional state in order to provide a smooth interface between humans and computers. This would make life easier and can be used in vast applications involving areas such as education, medicine etc. Human emotions can be recognized by several approaches such as gesture, facial images, physiological signals and neuro imaging methods. Most of the researchers have developed user dependent emotion recognition system and achieved maximum classification rate. Very few researchers have tried to develop a user independent system and obtained lower classification rate. Efficient emotion stimulus method, larger data samples and intelligent signal processing techniques are essential for improving the classification rate of the user independent system. In this paper, we present a review on emotion recognition using physiological signals. The various theories on emotion, emotion recognition methodology and the current advancements in emotion research are discussed in subsequent topics. This would provide an insight on the current state of research and its challenges on emotion recognition using physiological signals, so that research can be advanced to obtain better recognition.},
  doi          = {10.1109/cspa.2011.5759912},
  file         = {:jerritta2011physiological - Physiological signals based human emotion Recognition_ a review.pdf:PDF},
}

@Article{kukolja2014comparative,
  author    = {Davor Kukolja and Sini{\v{s}}a Popovi{\'{c}} and Marko Horvat and Bernard Kova{\v{c}} and Kre{\v{s}}imir {\'{C}}osi{\'{c}}},
  title     = {Comparative analysis of emotion estimation methods based on physiological measurements for real-time applications},
  journal   = {International Journal of Human-Computer Studies},
  year      = {2014},
  volume    = {72},
  number    = {10-11},
  pages     = {717--727},
  month     = {oct},
  abstract  = {In  order to improve intelligent Human-Computer Interaction it  is  important to create a personalized
 adaptive emotion estimator that  is  able  to  learn  over  time  emotional  response 
 idiosyncrasies of individual person and thus  enhance estimation accuracy.  This   paper,  with the  aim of  identifying preferable methods  for  such a  concept, presents  an   experiment-based  comparative study of  seven feature reduction and seven machine learning methods commonly used for  
emotion estimation based on   physiological  signals.  The   analysis was  performed  on   data  
obtained in   an   emotion  elicitation experiment  involving 14  participants. Speciﬁc discrete 
emotions were targeted with stimuli from the International Affective Picture System database. The 
experiment was necessary to achieve the uniformity in   the  various aspects  of   emotion  
elicitation, data  processing, feature  calculation, self-reporting procedures and estimation 
evaluation, in order to avoid inconsistencyproblems that arise when results from studies that use 
different emotion-related databases are mutually compared. The  results of  the performed 
experiment indicate that the combination of a multilayer perceptron (MLP) with sequential ﬂoating 
forward selection (SFFS) exhibited the highest accuracy in discrete emotionclassiﬁcation based on 
physiological features calculated from ECG, respiration, skin conductance and skin temperature. 
Using leave-one-session-out crossvalidation method, 60.3\% accuracy in  classiﬁcation of  5  
discrete emotions (sadness, disgust, fear, happiness and neutral) was obtained. In order to 
identify whichmethods may be the most suitable for real-time estimator adaptation, execution and 
learning times of emotion estimators were also comparatively analyzed. Based on  this analysis, 
preferred feature reduction method for  real- time estimator adaptation was minimum redundancy - 
maximum relevance (mRMR), which was thefastest approach in  terms of  combined execution and 
learning time, as  well as  the second best in accuracy,  after  SFFS.  In   combination with  
mRMR,   highest  accuracies were  achieved by   k-nearest neighbor (kNN)  and MLP with  negligible 
difference (50.33\% versus 50.54\%); however,  mRMR þ kNN  is preferable option forreal-time 
estimator adaptation due to considerably lower combined execution and
 learning time of kNN  versus MLP.},
  doi       = {10.1016/j.ijhcs.2014.05.006},
  file      = {:kukolja2014comparative - Comparative analysis of emotion estimation methods based on physiological measurements for real-time applications.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.ijhcs.2014.05.006},
}

@Article{bailenson2008real,
  author    = {Jeremy N. Bailenson and Emmanuel D. Pontikakis and Iris B. Mauss and James J. Gross and Maria E. Jabon and Cendri A.C. Hutcherson and Clifford Nass and Oliver John},
  title     = {Real-time classification of evoked emotions using facial feature tracking and physiological responses},
  journal   = {International Journal of Human-Computer Studies},
  year      = {2008},
  volume    = {66},
  number    = {5},
  pages     = {303--317},
  month     = {may},
  abstract  = {We present automated, real-time models built with machine learning algorithms which use videotapes of subjects’ faces in conjunction
with physiological measurements to predict rated emotion (trained coders’ second-by-second assessments of sadness or amusement).
Input consisted of videotapes of 41 subjects watching emotionally evocative films along with measures of their cardiovascular activity,
somatic activity, and electrodermal responding. We built algorithms based on extracted points from the subjects’ faces as well as their
physiological responses. Strengths of the current approach are (1) we are assessing real behavior of subjects watching emotional videos
instead of actors making facial poses, (2) the training data allow us to predict both emotion type (amusement versus sadness) as well as
the intensity level of each emotion, (3) we provide a direct comparison between person-specific, gender-specific, and general models.
Results demonstrated good fits for the models overall, with better performance for emotion categories than for emotion intensity, for
amusement ratings than sadness ratings, for a full model using both physiological measures and facial tracking than for either cue alone,
and for person-specific models than for gender-specific or general models.
r 2007 Elsevier Ltd. All rights reserved.},
  doi       = {10.1016/j.ijhcs.2007.10.011},
  file      = {:bailenson2008real - Real-time classification of evoked emotions using facial feature tracking and physiological responses.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.ijhcs.2007.10.011},
}

@InProceedings{grundlehner2009design,
  author       = {Bernard Grundlehner and Lindsay Brown and Julien Penders and Bert Gyselinckx},
  title        = {The Design and Analysis of a Real-Time, Continuous Arousal Monitor},
  booktitle    = {2009 Sixth International Workshop on Wearable and Implantable Body Sensor Networks},
  year         = {2009},
  pages        = {156--161},
  month        = {jun},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {The recent development of miniaturized, lowpower components for body sensor networks pave the way towards intelligent and ambulatory monitoring devices with a plurality of applications. Here, the design and development of a real-time arousal monitor, based on Human++ Body Area Network components is described. A new set of biomarkers is proposed based on psychophysiological observations and principles. A strong relation between the estimated arousal level and the expected arousal level is reported for responses triggered by movie clips, in a controlled environment. This relation is shown to extend to stimuli of a different nature, such as sounds and mental stress tests. The system will enable new applications in the field of stress management, safety, elearning and gaming.},
  doi          = {10.1109/bsn.2009.21},
  file         = {:grundlehner2009design - The Design and Analysis of a Real-Time, Continuous Arousal Monitor.pdf:PDF},
}

@InProceedings{grafsgaard2013automatically,
  author    = {Grafsgaard, Joseph F and Wiggins, Joseph B and Boyer, Kristy Elizabeth and Wiebe, Eric N and Lester, James C},
  title     = {Automatically Recognizing Facial Expression: Predicting Engagement and Frustration},
  booktitle = {EDM},
  year      = {2013},
  pages     = {43--50},
  abstract  = {Learning involves a rich array of cognitive and affective states. Recognizing and understanding these cognitive and affective dimensions of learning is key to designing informed interventions. Prior research has highlighted the importance of facial expressions in learning-centered affective states, but tracking facial expression poses significant challenges. This paper presents an automated analysis of fine-grained facial movements that occur during computer-mediated tutoring. We use the Computer Expression Recognition Toolbox (CERT) to track fine-grained facial movements consisting of eyebrow raising (inner and outer), brow lowering, eyelid tightening, and mouth dimpling within a naturalistic video corpus of tutorial dialogue (N=65). Within the dataset, upper face movements were found to be predictive of engagement, frustration, and learning, while mouth dimpling was a positive predictor of learning and self-reported performance. These results highlight how both intensity and frequency of facial expressions predict tutoring outcomes. Additionally, this paper presents a novel validation of an automated tracking tool on a naturalistic tutoring dataset, comparing CERT results with manual annotations across a prior video corpus. With the advent of readily available fine-grained facial expression recognition, the developments introduced here represent a next step toward automatically understanding moment-by-moment affective states during learning.},
  file      = {:grafsgaard2013automatically - Automatically Recognizing Facial Expression Predicting Engagement and Frustration.pdf:PDF},
}

@inproceedings{mandryk2006continuous,
  title={A continuous and objective evaluation of emotional experience with interactive play environments},
  author={Mandryk, Regan L and Atkins, M Stella and Inkpen, Kori M},
  booktitle={Proceedings of the SIGCHI conference on Human Factors in computing systems},
  pages={1027--1036},
  year={2006},
  organization={ACM}
}

@article{garde2002effects,
  title={Effects of mental and physical demands on heart rate variability during computer work},
  author={Garde, Anne and Laursen, Bjarne and J{\o}rgensen, Anker and Jensen, Bente},
  journal={European journal of applied physiology},
  volume={87},
  number={4-5},
  pages={456--461},
  year={2002},
  publisher={Springer}
}

@inproceedings{vandeput2009heart,
  title={Heart rate variability as a tool to distinguish periods of physical and mental stress in a laboratory environment},
  author={Vandeput, Steven and Taelman, Joachim and Spaepen, A and Van Huffel, Sabine},
  booktitle={Proceedings of the 6th international workshop on biosignal interpretation (BSI), New Haven, CT},
  pages={187--190},
  year={2009}
}

@inproceedings{zhang2015noncontact,
  title={Noncontact Extraction of Breathing Waveform},
  author={Zhang, Yuzhe and Shang, Fei},
  booktitle={2015 International Power, Electronics and Materials Engineering Conference},
  year={2015},
  organization={Atlantis Press}
}

@InProceedings{yun2009game,
  author       = {Chang Yun and Dvijesh Shastri and Ioannis Pavlidis and Zhigang Deng},
  title        = {O{\textquotesingle} game, can you feel my frustration?},
  booktitle    = {Proceedings of the 27th international conference on Human factors in computing systems - {CHI} 09},
  year         = {2009},
  pages        = {2195--2204},
  organization = {ACM},
  publisher    = {Association for Computing Machinery ({ACM})},
  abstract     = {One of the major challenges of video game design is to have appropriate difficulty levels for users in order to maximize the entertainment value of the game. Game players may lose interests if a game is either too easy or too difficult. This paper presents a novel methodology to improve user’s experience in computer games by automatically adjusting the level of the game difficulty. The difficulty level is computed from measurements of the facial physiology of the players at a distance. The measurements are based on the assumption that the players performance during the game-playing session alters blood flow in the supraorbital region, which is an indirect measurement of increased mental activities. This alters heat dissipation, which can be monitored in a contact-free manner through a thermal imaging-based stress monitoring and analysis system, known as StressCam. In this work, we investigated on two primary objectives: (1)  the feasibility of utilizing the facial physiology in automatically adjusting the difficulty level of the game and (2) the capability of the automatic difficulty level adjustment in improving game players experience. We employed and extended a XNA video game for this study, and performed an in-depth, comparative usability evaluation on it. Our results show that the automatic difficulty adjustable system successfully maintains game players’ interests and substantially outperforms traditional fixed-difficulty mode games. Although a number of issues of this preliminary study remain to be investigated further, this research opens a new direction that utilizes non-contact stress measurements for monitoring and further enhancing a variety of user-centric, interactive entertainment activities.},
  doi          = {10.1145/1518701.1519036},
  file         = {:yun2009game - O_game, can you feel my frustration_.pdf:PDF},
}

@Article{rodriguez2015vr,
  author    = {Alejandro Rodriguez and Beatriz Rey and Ma Dolores Vara and Maja Wrzesien and Mariano Alcaniz and Rosa Ma Banos and David Perez-Lopez},
  title     = {A {VR}-Based Serious Game for Studying Emotional Regulation in Adolescents},
  journal   = {{IEEE} Comput. Grap. Appl.},
  year      = {2015},
  volume    = {35},
  number    = {1},
  pages     = {65--73},
  month     = {jan},
  doi       = {10.1109/mcg.2015.8},
  file      = {:rodriguez2015vr - A VR-Based Serious Game for Studying Emotional Regulation in Adolescents.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/mcg.2015.8},
}

@InProceedings{mcduffcogcam,
  author    = {Daniel J. McDuff and Javier Hernandez and Sarah Gontarek and Rosalind W. Picard},
  title     = {COGCAM: Contact-free Measurement of Cognitive Stress During Computer Tasks with a Digital Camera},
  booktitle = {Proceedings of the 2016 {CHI} Conference on Human Factors in Computing Systems - {CHI} {\textquotesingle}16},
  year      = {2016},
  publisher = {Association for Computing Machinery ({ACM})},
  abstract  = {Contact-free camera-based measurement of cognitive stress opens up new possibilities for human-computer interaction with applications in remote learning, stress monitoring, and optimization of workload for user experience. The autonomic nervous system controls the inter-beat intervals of the heart and breathing patterns, and these signals change under cognitive stress. We built a participant-independent cognitive stress recognition model based on photoplethysmographic signals measured remotely at a distance of 3 meters. We tested the model on naturalistic responses from 10 individuals completing randomized-order computer-based tasks (ball control and card sorting). The system successfully detected increased stress during the tasks, which were consistent with self-report measures. Changes in heart rate variability were more discriminative indicators of cognitive stress than were heart rate and breathing rate.},
  doi       = {10.1145/2858036.2858247},
  file      = {:mcduffcogcam - COGCAM_ Contact-free Measurement of Cognitive Stress During Computer Tasks with a Digital Camera.pdf:PDF},
  url       = {http://dx.doi.org/10.1145/2858036.2858247},
}

@InProceedings{bousefsaf2013remote,
  author       = {Fr{\'{e}}d{\'{e}}ric Bousefsaf and Choubeila Maaoui and Alain Pruski},
  title        = {Remote assessment of the Heart Rate Variability to detect mental stress},
  booktitle    = {Proceedings of the {ICTs} for improving Patients Rehabilitation Research Techniques},
  year         = {2013},
  pages        = {348--351},
  organization = {IEEE},
  publisher    = {Institute for Computer Sciences, Social Informatics and Telecommunications Engineering ({ICST})},
  abstract     = {In the present paper, we introduce a new framework for detecting workload changes using video frames obtained from a low-cost webcam. The measurements are performed on human faces and the proposed algorithms were developed to be motion-tolerant. An interactive Stroop color word test is employed to induce stress on a set of twelve participants. We record the skin conductance and compare these responses to the stress curve assessed by a webcam-derived heart rate variability analysis. The results offer further support for the applicability of stress detection by remote and low-cost means, providing an alternative to conventional contact techniques.},
  doi          = {10.4108/icst.pervasivehealth.2013.252181},
  file         = {:bousefsaf2013remote - Remote assessment of the Heart Rate Variability to detect mental stress.pdf:PDF},
}

@InProceedings{xiao2015towards,
  author       = {Xiang Xiao and Jingtao Wang},
  title        = {Towards Attentive, Bi-directional {MOOC} Learning on Mobile Devices},
  booktitle    = {Proceedings of the 2015 {ACM} on International Conference on Multimodal Interaction - {ICMI} {\textquotesingle}15},
  year         = {2015},
  pages        = {163--170},
  organization = {ACM},
  publisher    = {Association for Computing Machinery ({ACM})},
  doi          = {10.1145/2818346.2820754},
  file         = {:xiao2015towards - Towards Attentive, Bi-directional MOOC Learning on Mobile Devices.pdf:PDF},
}

@incollection{stockhausen2013beats,
  title={Beats down: Using heart rate for game interaction in mobile settings},
  author={Stockhausen, Claudia and Smyzek, Justine and Kr{\"o}mker, Detlef},
  booktitle={Human-Computer Interaction--INTERACT 2013},
  pages={523--530},
  year={2013},
  publisher={Springer}
}

@inproceedings{yun2010pads,
  title={PADS: enhancing gaming experience using profile-based adaptive difficulty system},
  author={Yun, Chang and Trevino, Philip and Holtkamp, William and Deng, Zhigang},
  booktitle={Proceedings of the 5th ACM SIGGRAPH Symposium on Video Games},
  pages={31--36},
  year={2010},
  organization={ACM}
}

@incollection{moussa2009applying,
  title={Applying affect recognition in serious games: The playmancer project},
  author={Moussa, Maher Ben and Magnenat-Thalmann, Nadia},
  booktitle={Motion in Games},
  pages={53--62},
  year={2009},
  publisher={Springer}
}

@inproceedings{yu2014video,
  title={Video based heart rate estimation under different light illumination intensities},
  author={Yu, Yong-Poh and Paramesran, Raveendran and Lim, Chern-Loon},
  booktitle={Intelligent Signal Processing and Communication Systems (ISPACS), 2014 International Symposium on},
  pages={216--221},
  year={2014},
  organization={IEEE}
}

@article{golden1978stroop,
  title={Stroop colour and word test},
  author={Golden, CJ},
  journal={age},
  volume={15},
  pages={90},
  year={1978}
}

@InProceedings{mcduff2015survey,
  author       = {Daniel J. McDuff and Justin R. Estepp and Alyssa M. Piasecki and Ethan B. Blackford},
  title        = {A survey of remote optical photoplethysmographic imaging methods},
  booktitle    = {2015 37th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
  year         = {2015},
  pages        = {6398--6404},
  month        = {aug},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  doi          = {10.1109/embc.2015.7319857},
  file         = {:mcduff2015survey - A survey of remote optical photoplethysmographic imaging methods.pdf:PDF},
  url          = {http://dx.doi.org/10.1109/embc.2015.7319857},
}

@article{berg1948simple,
  title={A simple objective technique for measuring flexibility in thinking},
  author={Berg, Esta A},
  journal={The Journal of general psychology},
  volume={39},
  number={1},
  pages={15--22},
  year={1948},
  publisher={Taylor \& Francis}
}

@article{ekman1977facial,
  title={Facial action coding system},
  author={Ekman, Paul and Friesen, Wallace V},
  year={1977},
  publisher={Consulting Psychologists Press, Stanford University, Palo Alto}
}

@article{unsworth2015playing,
  title={Is playing video games related to cognitive abilities?},
  author={Unsworth, Nash and Redick, Thomas S and McMillan, Brittany D and Hambrick, David Z and Kane, Michael J and Engle, Randall W},
  journal={Psychological science},
  volume={26},
  number={6},
  pages={759--774},
  year={2015},
  publisher={SAGE Publications}
}

@article{terlecki2005important,
  title={How important is the digital divide? The relation of computer and videogame usage to gender differences in mental rotation ability},
  author={Terlecki, Melissa S and Newcombe, Nora S},
  journal={Sex Roles},
  volume={53},
  number={5},
  pages={433--441},
  year={2005},
  publisher={Springer}
}

@article{goodie2000validation,
  title={Validation of Polar heart rate monitor for assessing heart rate during physical and mental stress.},
  author={Goodie, Jeffrey L and Larkin, Kevin T and Schauss, Scott},
  journal={Journal of Psychophysiology},
  volume={14},
  number={3},
  pages={159},
  year={2000},
  publisher={Hogrefe \& Huber Publishers}
}

@InProceedings{bevilacqua2015proposal,
  author       = {Fernando Bevilacqua and Per Backlund and Henrik Engstrom},
  title        = {Proposal for Non-Contact Analysis of Multimodal Inputs to Measure Stress Level in Serious Games},
  booktitle    = {2015 7th International Conference on Games and Virtual Worlds for Serious Applications ({VS}-Games)},
  year         = {2015},
  pages        = {1--4},
  month        = {sep},
  organization = {IEEE},
  publisher    = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  abstract     = {The process of monitoring user emotions in seriousgames  or  human-computer  interaction  is  usually  obtrusive.  Thework-flow   is   typically   based   on   sensors   that   are   physicallyattached to the user. Sometimes those sensors completely disturbthe  user  experience,  such  as  finger  sensors  that  prevent  the  useof  keyboard/mouse.  This  short  paper  presents  techniques  usedto  remotely  measure  different  signals  produced  by  a  person,e.g.  heart  rate,  through  the  use  of  a  camera  and  computervision  techniques.  The  analysis  of  a  combination  of  such  signals(multimodal input) can be used in a variety of applications suchas  emotion  assessment  and  measurement  of  cognitive  stress.  Wepresent  a  research  proposal  for  measurement  of  player’s  stresslevel based on a non-contact analysis of multimodal user inputs.Our main contribution is a survey of commonly used methods toremotely measure user input signals related to stress assessment.},
  doi          = {10.1109/vs-games.2015.7295783},
  file         = {:bevilacqua2015proposal - Proposal for Non-Contact Analysis of Multimodal Inputs to Measure Stress Level in Serious Games.pdf:PDF},
  url          = {http://dx.doi.org/10.1109/vs-games.2015.7295783},
}

@article{cohn2007observer,
  title={Observer-based measurement of facial expression with the Facial Action Coding System},
  author={Cohn, Jeffrey F and Ambadar, Zara and Ekman, Paul},
  journal={The handbook of emotion elicitation and assessment},
  pages={203--221},
  year={2007},
  publisher={Oxford University Press, New York, NY}
}

@Article{Chanel_2011,
  author    = {Guillaume Chanel and Cyril Rebetez and Mireille Bétrancourt and Thierry Pun},
  title     = {Emotion Assessment From Physiological Signals for Adaptation of Game Difficulty},
  journal   = {{IEEE} Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
  year      = {2011},
  volume    = {41},
  number    = {6},
  pages     = {1052--1063},
  month     = {nov},
  abstract  = {This paper proposes to maintain player’s engagement
by adapting game difficulty according to player’s emotions
assessed from physiological signals. The validity of this approach
was first tested by analyzing the questionnaire responses, electroencephalogram
(EEG) signals, and peripheral signals of the
players playing a Tetris game at three difficulty levels. This analysis
confirms that the different difficulty levels correspond to
distinguishable emotions, and that, playing several times at the
same difficulty level gives rise to boredom. The next step was to
train several classifiers to automatically detect the three emotional
classes from EEG and peripheral signals in a player-independent
framework. By using either type of signals, the emotional classes
were successfully recovered, with EEG having a better accuracy
than peripheral signals on short periods of time. After the fusion
of the two signal categories, the accuracy raised up to 63\%.},
  doi       = {10.1109/tsmca.2011.2116000},
  file      = {:Chanel_2011 - Emotion Assessment From Physiological Signals for Adaptation of Game Difficulty.pdf:PDF},
  issue     = {6},
  masid     = {51193703},
  publisher = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/TSMCA.2011.2116000},
}

@InProceedings{mcduff2014remote,
  author    = {Daniel McDuff and Sarah Gontarek and Rosalind Picard},
  title     = {Remote measurement of cognitive stress via heart rate variability},
  booktitle = {2014 36th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society},
  year      = {2014},
  pages     = {2957-2960},
  month     = {aug},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  doi       = {10.1109/embc.2014.6944243},
  file      = {:mcduff2014remote - Remote measurement of cognitive stress via heart rate variability.pdf:PDF},
  issn      = {1557-170X},
  url       = {http://dx.doi.org/10.1109/EMBC.2014.6944243},
}


@INPROCEEDINGS{Ubiratan, 
    author={Ubiratan S. Freitas}, 
    booktitle={eTELEMED 2014, The Sixth International Conference on eHealth, Telemedicine, and Social Medicine}, 
    title={Remote Camera-based Pulse Oximetry}, 
    year={2014}, 
    month={Mar}, 
    pages={59-63}, 
    ISSN={2308-4359}
}

@INPROCEEDINGS{Kong, 
    author={Lingqin Kong and Yuejin Zhao and Liquan Dong and Yiyun Jian and Xiaoli Jin and Bing Li and Yun Feng and Ming Liu and Xiaohua Liu and Hong Wu}, 
    booktitle={Optics Express 21}, 
    title={Non-contact detection of oxygen saturation based on visible light imaging device using ambient light}, 
    year={2013}, 
    ISSN={1094-4087}
}

@inbook{Irani,
    title = "Improved Pulse Detection from Head Motions Using DCT",
    keywords = "Heartbeat rate, Head motion detection, Trajectory tracking, Feature point tracker, Electrocardiogram, Discrete cosine transforms, Principle component analysis",
    publisher = "Institute for Systems and Technologies of Information, Control and Communication",
    author = "Ramin Irani and Kamal Nasrollahi and Moeslund, {Thomas B.}",
    year = "2014",
    booktitle = "9th International Conference on Computer Vision Theory and Applications",
}

@InProceedings{6619284,
  author    = {Guha Balakrishnan and Fredo Durand and John Guttag},
  title     = {Detecting Pulse from Head Motions in Video},
  booktitle = {2013 {IEEE} Conference on Computer Vision and Pattern Recognition},
  year      = {2013},
  pages     = {3430-3437},
  month     = {jun},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract  = {We extract heart rate and beat lengths from videos by measuring subtle head motion caused by the Newtonian reaction to the influx of blood at each beat. Our method tracks features on the head and performs principal component analysis (PCA) to decompose their trajectories into a set of component motions. It then chooses the component that best corresponds to heartbeats based on its temporal frequency spectrum. Finally, we analyze the motion projected to this component and identify peaks of the trajectories, which correspond to heartbeats. When evaluated on 18 subjects, our approach reported heart rates nearly identical to an electrocardiogram device. Additionally we were able to capture clinically relevant information about heart rate variability.},
  doi       = {10.1109/cvpr.2013.440},
  file      = {:6619284 - Detecting Pulse from Head Motions in Video.pdf:PDF},
  issn      = {1063-6919},
  url       = {http://dx.doi.org/10.1109/cvpr.2013.440},
}

@article{poh2011advancements,
  title={Advancements in noncontact, multiparameter physiological measurements using a webcam},
  author={Poh, Ming-Zher and McDuff, Daniel J and Picard, Rosalind W},
  journal={Biomedical Engineering, IEEE Transactions on},
  volume={58},
  number={1},
  pages={7--11},
  year={2011},
  publisher={IEEE}
}

@InProceedings{Datcu_2013,
  author    = {Dragos Datcu and Marina Cidota and Stephan Lukosch and Leon Rothkrantz},
  title     = {Noncontact automatic heart rate analysis in visible spectrum by specific face regions},
  booktitle = {Proceedings of the 14th International Conference on Computer Systems and Technologies},
  year      = {2013},
  series    = {CompSysTech '13},
  pages     = {120--127},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2516805},
  doi       = {10.1145/2516775.2516805},
  isbn      = {978-1-4503-2021-4},
  keywords  = {face analysis, heart rate detection, photoplethysmography},
  location  = {Ruse, Bulgaria},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2516775.2516805},
}

@ARTICLE{Landowska, 
    author={Agnieszka Landowska}, 
    journal={Metrology and Measurement Systems},
    title={Emotion Monitoring Verification of Physiological Characteristics Measurement Procedures},
    year={2014},
    volume={21}, 
    number={4}, 
    pages={719-732}, 
    month={Dec}, 
    doi={10.2478/mms-2014-0049}, 
    ISSN={2300-1941}
}

@INPROCEEDINGS{Sereevoravitgul, 
    author={Thundluck Sereevoravitgul and Toshiaki Kondo}, 
    booktitle={5th International Conference on Information and Communication Technology for Embedded Systems (ICICTES2014)}, 
    title={A Comparative Study for Heart Rate Measurement in Video Sequences}, 
    year={2014}, 
    month={Jan}
}

@INPROCEEDINGS{ViolaJones,
    author = {Paul Viola and Michael Jones},
    title = {Robust Real-time Object Detection},
    booktitle = {International Journal of Computer Vision},
    year = {2001}
}

@inproceedings{EdwardsAAM,
     author = {Edwards, G. J. and Taylor, C. J. and Cootes, T. F.},
     title = {Interpreting Face Images Using Active Appearance Models},
     booktitle = {Proceedings of the 3rd. International Conference on Face \& Gesture Recognition},
     series = {FG '98},
     year = {1998},
     isbn = {0-8186-8344-9},
     pages = {300--},
     url = {http://dl.acm.org/citation.cfm?id=520809.796067},
     acmid = {796067},
     publisher = {IEEE Computer Society},
     address = {Washington, DC, USA},
} 

@Article{Hjortskov_2004,
  author    = {Nis Hjortskov and Dag Rissén and AnneKatrine Blangsted and Nils Fallentin and Ulf Lundberg and Karen Søgaard},
  title     = {The effect of mental stress on heart rate variability and blood pressure during computer work},
  journal   = {European Journal of Applied Physiology},
  year      = {2004},
  volume    = {92},
  number    = {1-2},
  pages     = {84--89},
  month     = {jun},
  abstract  = {The aim was to evaluate the cardiovascular and subjective stress response to a combined physical and mental workload, and the effect of rest. Twelve females who had no prior experience of laboratory experiments participated in the study. Computer-work-related mental stressors were either added to or removed from a standardized computer work session in the laboratory. Beat-to-beat blood pressure and electrocardiogram (ECG) were recorded continuously during the experiment. The participants reported subjective experiences of stress in six categories using an 11-point scale before and at the end of the work. Heart rate variability (HRV) variables were calculated from the ECG recordings, and a reduction in the high-frequency component of HRV and an increase in the low- to high-frequency ratio were observed in the stress situation compared to the control session. No changes were seen in the low-frequency component of HRV. The stressors induced an increase in blood pressure compared to baseline that persisted, and for the diastolic pressure it even increased in the subsequent control session. No differences were observed for subjective experience of stress with the exception of a time trend in the exhaustion scale, i.e. a progression in reported exhaustion with time. The results and the dissociation between HRV and blood pressure variables—indicate that HRV is a more sensitive and selective measure of mental stress. It could be speculated that heart rate-derived variables reflect a central pathway in cardiovascular control mechanisms (‘‘central command’’), while the blood pressure response is more influenced by local conditions in the working muscles that partly mask the effect of changes in mental workloads. In the rest period after each work session, HRV and blood pressure variables were partly normalized as expected. However, an 8-min period of rest was insufficient to restore blood pressure to resting values.},
  doi       = {10.1007/s00421-004-1055-z},
  file      = {:Hjortskov_2004 - The effect of mental stress on heart rate variability and blood pressure during computer work.pdf:PDF},
  issue     = {1},
  masid     = {32693887},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00421-004-1055-z},
}

@InProceedings{Moses_2007,
  author    = {Ziev B. Moses and Linda J. Luecken and James C. Eason},
  title     = {Measuring Task-related Changes in Heart Rate Variability},
  booktitle = {2007 29th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society},
  year      = {2007},
  pages     = {644--647},
  month     = {aug},
  publisher = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  abstract  = {Small beat-to-beat differences in heart rate are the
result of dynamic control of the cardiovascular system by the
sympathetic and parasympathetic nervous systems. Heart
rate variability (HRV) has been positively correlated with
both mental and physical health. While many studies measure
HRV under rest conditions, few have measured HRV during
stressful situations. We describe an experimental protocol
designed to measure baseline, task, and recovery values of
HRV as a function of three different types of stressors. These
stressors involve an attention task, a cold pressor test, and a
videotaped speech presentation. We found a measurable
change in heart rate in participants (n=10) during each task
(all p’s < 0.05). The relative increase or decrease from pretask
heart rate was predicted by task (one-way ANOVA,
p=0.0001). Spectral analysis of HRV during the attention task
revealed consistently decreased measures of both high
(68±7%, mean±S.E.) and low (62±13%) frequency HRV
components as compared to baseline. HRV spectra for the
cold pressor and speech tasks revealed no consistent patterns
of increase or decrease from baseline measurements. We also
found no correlation in reactivity measures between any of
our tasks. These findings suggest that each of the tasks in our
experimental design elicits a different type of stress response
in an individual. Our experimental approach may prove
useful to biobehavioral researchers searching for factors that
determine individual differences in responses to stress in
daily life.},
  doi       = {10.1109/iembs.2007.4352372},
  file      = {:Moses_2007 - Measuring Task-related Changes in Heart Rate Variability.pdf:PDF},
  masid     = {50590784},
  url       = {http://dx.doi.org/10.1109/IEMBS.2007.4352372},
}

@INPROCEEDINGS{mental, 
    author={Dawei Zhou and Jiebo Luo and Vincent M.B. Silenzio and Yun Zhou and Jile Hu and Glenn Currier and Henry Kautz}, 
    booktitle={Proceedings Of The 29th AAAI Conference On Artificial Intelligence And The 27th Innovative Applications Of Artificial Intelligence Conferenc}, 
    title={Tackling Mental Health by Integrating Unobtrusive Multimodal Sensing}, 
    year={2015}, 
    month={April}, 
    ISSN={2374-3468}
}

@book{picard2000affective,
  title={Affective computing},
  author={Picard, Rosalind W},
  year={2000},
  publisher={MIT press}
}

@article{liu2009dynamic,
  title={Dynamic difficulty adjustment in computer games through real-time anxiety-based affective feedback},
  author={Liu, Changchun and Agrawal, Pramila and Sarkar, Nilanjan and Chen, Shuo},
  journal={International Journal of Human-Computer Interaction},
  volume={25},
  number={6},
  pages={506-529},
  year={2009},
  publisher={Taylor \& Francis}
}

@article{cowie2001emotion,
  title={Emotion recognition in human-computer interaction},
  author={Cowie, Roddy and Douglas-Cowie, Ellen and Tsapatsoulis, Nicolas and Votsis, George and Kollias, Stefanos and Fellenz, Winfried and Taylor, John G},
  journal={Signal Processing Magazine, IEEE},
  volume={18},
  number={1},
  pages={32--80},
  year={2001},
  publisher={IEEE}
}

@Article{allen2007photoplethysmography,
  author    = {John Allen},
  title     = {Photoplethysmography and its application in clinical physiological measurement},
  journal   = {Physiological measurement},
  year      = {2007},
  volume    = {28},
  number    = {3},
  pages     = {R1--R39},
  month     = {feb},
  abstract  = {Photoplethysmography (PPG) is a simple and low-cost optical technique that
can be used to detect blood volume changes in the microvascular bed of tissue.
It is often used non-invasively to make measurements at the skin surface. The
PPG waveform comprises a pulsatile (‘AC’) physiological waveform attributed
to cardiac synchronous changes in the blood volume with each heart beat,
and is superimposed on a slowly varying (‘DC’) baseline with various lower
frequency components attributed to respiration, sympathetic nervous system
activity and thermoregulation. Although the origins of the components of
the PPG signal are not fully understood, it is generally accepted that they
can provide valuable information about the cardiovascular system. There has
been a resurgence of interest in the technique in recent years, driven by the
demand for low cost, simple and portable technology for the primary care
and community based clinical settings, the wide availability of low cost and
small semiconductor components, and the advancement of computer-based
pulse wave analysis techniques. The PPG technology has been used in a
wide range of commercially available medical devices for measuring oxygen
saturation, blood pressure and cardiac output, assessing autonomic function
and also detecting peripheral vascular disease. The introductory sections of the
topical review describe the basic principle of operation and interaction of light
with tissue, early and recent history of PPG, instrumentation, measurement
protocol, and pulse wave analysis. The review then focuses on the applications
of PPG in clinical physiological measurements, including clinical physiological
monitoring, vascular assessment and autonomic function.},
  doi       = {10.1088/0967-3334/28/3/r01},
  file      = {:allen2007photoplethysmography - Photoplethysmography and its application in clinical physiological measurement.pdf:PDF},
  publisher = {{IOP} Publishing},
  url       = {http://dx.doi.org/10.1088/0967-3334/28/3/r01},
}


@article{susi2007serious,
  title={Serious games: An overview},
  author={Susi, Tarja and Johannesson, Mikael and Backlund, Per},
  year={2007},
  publisher={Institutionen f{\"o}r kommunikation och information}
}

@inproceedings{ravaja20051,
  title={The Psychophysiology of Video Gaming: Phasic Emotional Responses to Game Events},
  author={Ravaja, Niklas and Saari, Timo and Laarni, Jari and Kallinen, Kari and Salminen, Mikko and Holopainen, Jussi and J{\"a}rvinen, Aki},
  booktitle={International DiGRA Conference},
  year={2005}
}

@article{boyle2012engagement,
  title={Engagement in digital entertainment games: A systematic review},
  author={Boyle, Elizabeth A and Connolly, Thomas M and Hainey, Thomas and Boyle, James M},
  journal={Computers in Human Behavior},
  volume={28},
  number={3},
  pages={771--780},
  year={2012},
  publisher={Elsevier}
}

@article{jennett2008measuring,
  title={Measuring and defining the experience of immersion in games},
  author={Jennett, Charlene and Cox, Anna L and Cairns, Paul and Dhoparee, Samira and Epps, Andrew and Tijs, Tim and Walton, Alison},
  journal={International journal of human-computer studies},
  volume={66},
  number={9},
  pages={641--661},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{brown2004grounded,
  title={A grounded investigation of game immersion},
  author={Brown, Emily and Cairns, Paul},
  booktitle={CHI'04 extended abstracts on Human factors in computing systems},
  pages={1297--1300},
  year={2004},
  organization={ACM}
}

@article{weibel2011immersion,
  title={Immersion in computer games: The role of spatial presence and flow},
  author={Weibel, David and Wissmath, Bartholom{\"a}us},
  journal={International Journal of Computer Games Technology},
  volume={2011},
  pages={6},
  year={2011},
  publisher={Hindawi Publishing Corp.}
}

@article{engstrom2016impact,
  title={The impact of contextualization on immersion in healthcare simulation},
  author={Engstr{\"o}m, Henrik and Hagiwara, Magnus Andersson and Backlund, Per and Lebram, Mikael and Lundberg, Lars and Johannesson, Mikael and Sterner, Anders and S{\"o}derholm, Hanna Maurin},
  journal={Advances in Simulation},
  volume={1},
  number={1},
  pages={1},
  year={2016},
  publisher={BioMed Central}
}

@article{melcer2015games,
  title={Games Research Today: Analyzing the Academic Landscape 2000-2014},
  author={Melcer, Edward and Nguyen, Truong-Huy Dinh and Chen, Zhengxing and Canossa, Alessandro and El-Nasr, Magy Seif and Isbister, Katherine},
  journal={network},
  volume={17},
  pages={20},
  year={2015}
}

@book{koster2013theory,
  title={Theory of fun for game design},
  author={Koster, Raph},
  year={2013},
  publisher={" O'Reilly Media, Inc."}
}

@book{schell2014art,
  title={The Art of Game Design: A book of lenses},
  author={Schell, Jesse},
  year={2014},
  publisher={CRC Press}
}

@article{rani2006empirical,
  title={An empirical study of machine learning techniques for affect recognition in human--robot interaction},
  author={Rani, Pramila and Liu, Changchun and Sarkar, Nilanjan and Vanman, Eric},
  journal={Pattern Analysis and Applications},
  volume={9},
  number={1},
  pages={58--69},
  year={2006},
  publisher={Springer}
}

@article{sharma2006assessment,
  title={Assessment of computer game as a psychological stressor},
  author={Sharma, Ratna and Khera, SHVETA and Mohan, AMIT and Gupta, NIDHI and Ray, ROOMA BASU},
  journal={Indian journal of physiology and pharmacology},
  volume={50},
  number={4},
  pages={367},
  year={2006},
  publisher={DEPARTMENT OF PHYSIOLOGY ALL INDIAN INSTITUTE OF}
}

@article{fenton2012emotion,
  title={Emotion regulation and trader expertise: Heart rate variability on the trading floor.},
  author={Fenton-O'Creevy, Mark and Lins, Jeffrey T and Vohra, Shalini and Richards, Daniel W and Davies, Gareth and Schaaff, Kristina},
  journal={Journal of Neuroscience, Psychology, and Economics},
  volume={5},
  number={4},
  pages={227},
  year={2012},
  publisher={Educational Publishing Foundation}
}

@Article{appelhans2006heart,
  author    = {Appelhans, Bradley M and Luecken, Linda J},
  title     = {Heart rate variability as an index of regulated emotional responding.},
  journal   = {Review of general psychology},
  year      = {2006},
  volume    = {10},
  number    = {3},
  pages     = {229},
  abstract  = {The study of individual differences in emotional responding can provide considerable
insight into interpersonal dynamics and the etiology of psychopathology. Heart rate
variability (HRV) analysis is emerging as an objective measure of regulated emotional
responding (generating emotional responses of appropriate timing and magnitude). This
review provides a theoretical and empirical rationale for the use of HRV as an index of
individual differences in regulated emotional responding. Two major theoretical frameworks
that articulate the role of HRV in emotional responding are presented, and
relevant empirical literature is reviewed. The case is made that HRV is an accessible
research tool that can increase the understanding of emotion in social and psychopathological
processes.},
  file      = {:appelhans2006heart - Heart rate variability as an index of regulated emotional responding.pdf:PDF},
  publisher = {Educational Publishing Foundation},
}

@Article{kivikangas2011review,
  author    = {J. Matias Kivikangas and Guillaume Chanel and Ben Cowley and Inger Ekman and Mikko Salminen and Simo Järvelä and Niklas Ravaja},
  title     = {A review of the use of psychophysiological methods in game research},
  journal   = {Journal of Gaming {\&} Virtual Worlds},
  year      = {2011},
  volume    = {3},
  number    = {3},
  pages     = {181--199},
  month     = {sep},
  doi       = {10.1386/jgvw.3.3.181_1},
  file      = {:kivikangas2011review - A review of the use of psychophysiological methods in game research.pdf:PDF},
  publisher = {Intellect},
}

@InCollection{tijs2008dynamic,
  author    = {Tim J. W. Tijs and Dirk Brokken and Wijnand A. IJsselsteijn},
  title     = {Dynamic Game Balancing by Recognizing Affect},
  booktitle = {Fun and Games},
  publisher = {Springer Nature},
  year      = {2008},
  pages     = {88--93},
  abstract  = {Dynamic game balancing concerns changing parameters in a game to avoid undesired player emotions, such as boredom and frustration. This is e.g. done by adjusting the game's difficulty level to the (increasing) skill level of the player during the game. Currently, most balancing techniques are based on ingame performance, such as the player's position in a race. This is, however, insufficient since different types of players exist, with different goals, preferences and emotional responses. Therefore, to deal effectively with a player's emotions, a game needs to look beyond the player's performance. This paper provides an overview of two groups of potentially useful sources for dynamic game balancing: Overt behavior and physiological responses. In addition, we present EMOPacman, a design case that aims to implement these new balancing techniques into the game PacMan.},
  doi       = {10.1007/978-3-540-88322-7_9},
  file      = {:tijs2008dynamic - Dynamic Game Balancing by Recognizing Affect.pdf:PDF},
}

@InProceedings{yamakoshi2007preliminary,
  author       = {T. Yamakoshi and K. Yamakoshi and S. Tanaka and M. Nogawa and M. Shibata and Y. Sawada and P. Rolfe and Y. Hirose},
  title        = {A Preliminary Study on Driver{\textquotesingle}s Stress Index Using a New Method Based on Differential Skin Temperature Measurement},
  booktitle    = {2007 29th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society},
  year         = {2007},
  pages        = {722--725},
  month        = {aug},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  doi          = {10.1109/iembs.2007.4352392},
  file         = {:yamakoshi2007preliminary - A Preliminary Study on Driver_textquotesingles Stress Index Using a New Method Based on Differential Skin Temperature Measurement.pdf:PDF},
}

@InProceedings{yamaguchi2006evaluation,
  author       = {M. Yamaguchi and J. Wakasugi and J. Sakakima},
  title        = {Evaluation of driver stress using biomarker in motor-vehicle driving simulator},
  booktitle    = {2006 International Conference of the {IEEE} Engineering in Medicine and Biology Society},
  year         = {2006},
  pages        = {1834--1837},
  month        = {aug},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {Employing the analysis of a biomarker, an oculomotor angle and a subjective evaluation, we have examined the acute, psychological effect human stress of driving using a motor-vehicle driving simulator. Salivary amylase is used as a biomarker, as it is considered to be one of the indicators of sympathetic nervous activity. 20 healthy female subjects in their early twenties were enrolled in this study. The time-course change of their salivary amylase activity (sAMY) is analyzed before and during the driving. At the same time, using a questionnaire, subjective evaluations are conducted with each subject. As for comparison, the effect of operating a car navigation device, which is not directly associated with driving, is also evaluated. Our results indicate that the psychological effect of driving-induced stress, a condition that can not be easily detected or recognized by a subjective evaluation, is quickly quantified using a biomarker in saliva. Moreover, the results suggest that operation of a non-driving-related device may also reduce the capacity to concentrate on driving. These data imply that evaluation of driver stress using a biomarker can be very useful for improvement of safety during driving.},
  doi          = {10.1109/iembs.2006.260001},
  file         = {:yamaguchi2006evaluation - Evaluation of driver stress using biomarker in motor-vehicle driving simulator.pdf:PDF},
}

@article{healey2005detecting,
  title={Detecting stress during real-world driving tasks using physiological sensors},
  author={Healey, Jennifer A and Picard, Rosalind W},
  journal={Intelligent Transportation Systems, IEEE Transactions on},
  volume={6},
  number={2},
  pages={156--166},
  year={2005},
  publisher={IEEE}
}


@article{schubert2009effects,
  title={Effects of stress on heart rate complexity—a comparison between short-term and chronic stress},
  author={Schubert, C and Lambertz, M and Nelesen, RA and Bardwell, W and Choi, J-B and Dimsdale, JE},
  journal={Biological psychology},
  volume={80},
  number={3},
  pages={325--332},
  year={2009},
  publisher={Elsevier}
}

@InProceedings{choi2009using,
  author       = {Jongyoon Choi and Ricardo Gutierrez-Osuna},
  title        = {Using Heart Rate Monitors to Detect Mental Stress},
  booktitle    = {2009 Sixth International Workshop on Wearable and Implantable Body Sensor Networks},
  year         = {2009},
  pages        = {219--223},
  month        = {jun},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {This article describes an approach to detecting mental stress using unobtrusive wearable sensors. The approach relies on estimating the state of the autonomic nervous system from an analysis of heart rate variability. Namely, we use a non-linear system identification technique known as principal dynamic modes (PDM) to predict the activation level of the two autonomic branches: sympathetic (i.e. stress-inducing) and parasympathetic (i.e. relaxationrelated). We validate the method on a discrimination problem with two psychophysiological conditions, one associated with mental tasks and one induced by relaxation exercises. Our results indicate that PDM features are more stable and less subject-dependent than spectral features, though the latter provide higher classification performance within subjects. When PDM and spectral features are combined, our system discriminates stressful events with a success rate of 83\% within subjects (69\% between subjects).},
  doi          = {10.1109/bsn.2009.13},
  file         = {:choi2009using - Using Heart Rate Monitors to Detect Mental Stress.pdf:PDF},
}

@article{cardena2000psychometric,
  title={Psychometric properties of the Stanford Acute Stress Reaction Questionnaire (SASRQ): A valid and reliable measure of acute stress},
  author={Cardena, Etzel and Koopman, Cheryl and Classen, Catherine and Waelde, Lynn C and Spiegel, David},
  journal={Journal of traumatic stress},
  volume={13},
  number={4},
  pages={719--734},
  year={2000},
  publisher={Springer}
}


@article{morris1995observations,
  title={Observations: SAM: the Self-Assessment Manikin; an efficient cross-cultural measurement of emotional response},
  author={Morris, Jon D},
  journal={Journal of advertising research},
  volume={35},
  number={6},
  pages={63--68},
  year={1995}
}

@book{kirk1982experimental,
  title={Experimental design},
  author={Kirk, Roger E},
  year={1982},
  publisher={Wiley Online Library}
}


@book{lane2015online,
  title={Online statistics education: An interactive multimedia course of study},
  author={Lane, David M},
  year={2015}
}


@article{trochim2001research,
  title={Research methods knowledge base},
  author={Trochim, William MK and Donnelly, James P},
  year={2001},
  publisher={Atomic Dog Pub.}
}


@article{campbell1986relabeling,
  title={Relabeling internal and external validity for applied social scientists},
  author={Campbell, Donald T},
  journal={New Directions for Program Evaluation},
  volume={1986},
  number={31},
  pages={67--77},
  year={1986},
  publisher={Wiley Online Library}
}

@Article{giannakakis2017stress,
  author    = {G. Giannakakis and M. Pediaditis and D. Manousos and E. Kazantzaki and F. Chiarugi and P.G. Simos and K. Marias and M. Tsiknakis},
  title     = {Stress and anxiety detection using facial cues from videos},
  journal   = {Biomedical Signal Processing and Control},
  year      = {2017},
  volume    = {31},
  pages     = {89--101},
  month     = {jan},
  abstract  = {This study develops a framework for the detection and analysis of stress/anxiety emotional states through video-recorded facial cues. A thorough experimental protocol was established to induce systematic variability in affective states (neutral, relaxed and stressed/anxious) through a variety of external and internal stressors. The analysis was focused mainly on non-voluntary and semi-voluntary facial cues in order to estimate the emotion representation more objectively. Features under investigation included eye-related events, mouth activity, head motion parameters and heart rate estimated through camera-based photoplethysmography. A feature selection procedure was employed to select the most robust features followed by classification schemes discriminating between stress/anxiety and neutral states with reference to a relaxed state in each experimental phase. In addition, a ranking transformation was proposed utilizing self reports in order to investigate the correlation of facial parameters with a participant perceived amount of stress/anxiety. The results indicated that, specific facial cues, derived from eye activity, mouth activity, head movements and camera based heart activity achieve good accuracy and are suitable as discriminative indicators of stress and anxiety.},
  doi       = {10.1016/j.bspc.2016.06.020},
  file      = {:giannakakis2017stress - Stress and anxiety detection using facial cues from videos.pdf:PDF},
  publisher = {Elsevier},
  url       = {http://dx.doi.org/10.1016/j.bspc.2016.06.020},
}

@Article{kranjec2014non,
  author    = {J. Kranjec and S. Begu{\v{s}} and G. Ger{\v{s}}ak and J. Drnov{\v{s}}ek},
  title     = {Non-contact heart rate and heart rate variability measurements: A review},
  journal   = {Biomedical Signal Processing and Control},
  year      = {2014},
  volume    = {13},
  pages     = {102--112},
  month     = {sep},
  abstract  = {The following paper investigates published work on non-contact human physiological parameter measurement, more precisely measurement of the human heart rate (HR) and consequently the heart rate variability (HRV), which is considered to be an important marker of autonomic nervous system activity proven to be predictive of the likelihood of future health related events. The ability to perform measurements of cardiac activity in a non-contact manner could prove to become an important alternative to the conventional methods in the clinical field as well as in the more commercially oriented fields. Some of the published work so far indicates that the measurement of cardiac activity in a non-contact manner is indeed possible and in some cases also very precise, however there are several limitations to the methods which need to be taken into account when performing the measurements. The following paper includes a short description of the two conventional methods, electrocardiogram (ECG) and photoplethysmography (PPG), and later on focuses on the novel methods of non-contact measuring of HR with capacitively coupled ECG, Doppler radar, optical vibrocardiography, thermal imaging, RGB camera and HR from speech. Our study represents a comparative review of these methods while emphasising their advantages and disadvantages.},
  doi       = {10.1016/j.bspc.2014.03.004},
  file      = {:kranjec2014non - Non-contact heart rate and heart rate variability measurements_ A review.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-08-24},
  url       = {http://dx.doi.org/10.1016/j.bspc.2014.03.004},
}

@InProceedings{li2014remote,
  author    = {Xiaobai Li and Jie Chen and Guoying Zhao and Matti Pietikainen},
  title     = {Remote Heart Rate Measurement from Face Videos under Realistic Situations},
  booktitle = {2014 {IEEE} Conference on Computer Vision and Pattern Recognition},
  year      = {2014},
  pages     = {4264--4271},
  month     = {jun},
  publisher = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  abstract  = {Heart rate is an important indicator of people’s physiological
state. Recently, several papers reported methods to
measure heart rate remotely from face videos. Those methods
work well on stationary subjects under well controlled
conditions, but their performance significantly degrades if
the videos are recorded under more challenging conditions,
specifically when subjects’ motions and illumination variations
are involved. We propose a framework which utilizes
face tracking and Normalized Least Mean Square adaptive
filtering methods to counter their influences. We test
our framework on a large difficult and public database
MAHNOB-HCI and demonstrate that our method substantially
outperforms all previous methods. We also use our
method for long term heart rate monitoring in a game evaluation
scenario and achieve promising results},
  doi       = {10.1109/cvpr.2014.543},
  file      = {:li2014remote - Remote Heart Rate Measurement from Face Videos under Realistic Situations.pdf:PDF},
  timestamp = {2016-08-23},
  url       = {http://dx.doi.org/10.1109/cvpr.2014.543},
}

@Article{blanik2014hybrid,
  author    = {Blanik, Nikolai and Abbas, Abbas K. and Venema, Boudewijn and Blazek, Vladimir and Leonhardt, Steffen},
  title     = {Hybrid optical imaging technology for long-term remote monitoring of skin perfusion and temperature behavior},
  journal   = {Journal of Biomedical Optics},
  year      = {2014},
  volume    = {19},
  number    = {1},
  pages     = {016012},
  abstract  = {Photoplethysmography imaging (PPGI) and infrared thermography imaging (IRTI) are contactless camera-based measurement methods for monitoring a wide range of basic vital parameters. In particular, PPGI enhances the classical contact-based photoplethysmography. Approved evaluation algorithms of the well-established PPG method can easily be adapted for detection of heart rate, heart rate variability, respiration rate (RR), respiratory variability (RV), and vasomotional activity with PPGI. The IRTI method primarily records temperature distribution of the observed object, but information on RR and RV can also be derived from IRTI by analyzing the development of temperature distribution in the nasal region. The main advantages of both monitoring methods are unobtrusive data acquisition and the possibility of assessing spatial assignment between vital parameters and body region. Hence, these methods enable long-term monitoring or the monitoring of effects with special local characteristics. Because the two systems supplement each, a combined hybrid application is proposed and its feasibility discussed.},
  doi       = {10.1117/1.JBO.19.1.016012},
  file      = {:blanik2014hybrid - Hybrid optical imaging technology for long-term remote monitoring of skin perfusion and temperature behavior.pdf:PDF},
  isbn      = {1083-3668},
  timestamp = {2016-08-23},
  url       = { http://dx.doi.org/10.1117/1.JBO.19.1.016012},
}

@Article{McDuff_2014,
  author    = {Daniel McDuff and Sarah Gontarek and Rosalind W. Picard},
  title     = {Remote Detection of Photoplethysmographic Systolic and Diastolic Peaks Using a Digital Camera},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2014},
  volume    = {61},
  number    = {12},
  pages     = {2948--2954},
  month     = {dec},
  abstract  = {We present a new method for measuring photoplethysmogram
(PPG) signals remotely using ambient light
and a digital camera that allows for accurate recovery of the
waveform morphology (from a distance of 3m). In particular,
we show that the peak-to-peak time between the systolic peak
and diastolic peak/inflection can be automatically recovered using
the second order derivative of the remotely measured waveform.
We compare measurements from the face with those captured
using a contact finger-tip sensor and show high agreement in
peak and interval timings. Furthermore, we show that results
can be significantly improved using orange, green and cyan color
channels compared to the tradition red, green and blue channel
combination. The absolute error in inter-beat-intervals was 26ms
and the absolute error in mean systolic-diastolic peak-to-peak
times was 12ms. The mean systolic-diastolic peak-to-peak times
measured using the contact sensor and the camera were highly
correlated, ρ = 0.94 (p<0.001). The results were obtained with a
camera frame-rate of only 30Hz. This technology has significant
potential for advancing healthcare.},
  doi       = {10.1109/tbme.2014.2340991},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp = {2016-08-23},
  url       = {http://dx.doi.org/10.1109/tbme.2014.2340991},
}

@InProceedings{tasli2014remote,
  author       = {H. Emrah Tasli and Amogh Gudi and Marten den Uyl},
  title        = {Remote {PPG} based vital sign measurement using adaptive facial regions},
  booktitle    = {2014 {IEEE} International Conference on Image Processing ({ICIP})},
  year         = {2014},
  pages        = {1410--1414},
  month        = {oct},
  organization = {IEEE},
  publisher    = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  doi          = {10.1109/icip.2014.7025282},
  file         = {:tasli2014remote - Remote PPG based vital sign measurement using adaptive facial regions.pdf:PDF},
  timestamp    = {2016-08-23},
  url          = {http://dx.doi.org/10.1109/icip.2014.7025282},
}

@InProceedings{lee2015heart,
  author       = {Dongseok Lee and Jeehoon Kim and Sungjun Kwon and Kwangsuk Park},
  title        = {Heart rate estimation from facial photoplethysmography during dynamic illuminance changes},
  booktitle    = {2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  year         = {2015},
  pages        = {2758--2761},
  month        = {aug},
  organization = {IEEE},
  publisher    = {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  abstract     = {Camera-based remote photoplethysmography
(rPPG) enables low-cost, non-contact cardiovascular activity
monitoring. However, applying rPPG to practical use has some
limitations caused from the artifacts by illuminance changes.
During watching a video in a dark room, for example, watching
a TV at night without illuminance, there is a high correlation
between the brightness changes of a video and the illuminance
variation on the skin of the viewer’s face. In this study, we
propose an artifact reduction method in rPPG, which is caused
by the variation of the illuminance. The method subtracts the
artifacts from the raw facial rPPG signal by applying
multi-order curve fitting between the illuminance information
from the facial rPPG signal and the brightness information
from a video. On average, the results showed that signal-to-noise
ratio (SNR) increased from -11.74 to -4.19 dB and from -15.27 to
7.99 dB for low-dynamic-brightness and
high-dynamic-brightness video, respectively. In addition, the
root-mean-square-error (RMSE) of estimated heart rate
decreased from 11.00 to 1.82 bpm and from 9.88 to 4.65 bpm for
the videos, respectively.},
  doi          = {10.1109/embc.2015.7318963},
  file         = {:lee2015heart - Heart rate estimation from facial photoplethysmography during dynamic illuminance changes.pdf:PDF},
  url          = {http://dx.doi.org/10.1109/embc.2015.7318963},
}

@InProceedings{tulyakov2016self,
  author    = {Tulyakov, Sergey and Alameda-Pineda, Xavier and Ricci, Elisa and Yin, Lijun and Cohn, Jeffrey F and Sebe, Nicu},
  title     = {Self-adaptive matrix completion for heart rate estimation from face videos under realistic conditions},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2016},
  pages     = {2396--2404},
  abstract  = {Recent studies in computer vision have shown that, while practically invisible to a human observer, skin color changes due to blood flow can be captured on face videos and, surprisingly, be used to estimate the heart rate (HR). While considerable progress has been made in the last few years, still many issues remain open. In particular, state-of-the-art approaches are not robust enough to operate in natural conditions (e.g. in case of spontaneous movements, facial expressions, or illumination changes). Opposite to previous approaches that estimate the HR by processing all the skin pixels inside a fixed region of interest, we introduce a strategy to dynamically select face regions useful for robust HR estimation. Our approach, inspired by recent advances on matrix completion theory, allows us to predict the HR while simultaneously discover the best regions of the face to be used for estimation. Thorough experimental evaluation conducted on public benchmarks suggests that the proposed approach significantly outperforms state-of-the-art HR estimation methods in naturalistic conditions.},
  file      = {:tulyakov2016self - Self-adaptive matrix completion for heart rate estimation from face videos under realistic conditions.pdf:PDF},
}

@InProceedings{zhang2016multimodal,
  author    = {Zhang, Zheng and Girard, Jeff M and Wu, Yue and Zhang, Xing and Liu, Peng and Ciftci, Umur and Canavan, Shaun and Reale, Michael and Horowitz, Andy and Yang, Huiyuan and others},
  title     = {Multimodal spontaneous emotion corpus for human behavior analysis},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2016},
  pages     = {3438--3446},
  abstract  = {Emotion is expressed in multiple modalities, yet most research
has considered at most one or two. This stems in
part from the lack of large, diverse, well-annotated, multimodal
databases with which to develop and test algorithms.
We present a well-annotated, multimodal, multidimensional
spontaneous emotion corpus of 140 participants. Emotion
inductions were highly varied. Data were acquired from a
variety of sensors of the face that included high-resolution
3D dynamic imaging, high-resolution 2D video, and thermal
(infrared) sensing, and contact physiological sensors
that included electrical conductivity of the skin, respiration,
blood pressure, and heart rate. Facial expression was annotated
for both the occurrence and intensity of facial action
units from 2D video by experts in the Facial Action Coding
System (FACS). The corpus further includes derived features
from 3D, 2D, and IR (infrared) sensors and baseline
results for facial expression and action unit detection. The
entire corpus will be made available to the research community.},
}

@InProceedings{chwyl2016sapphire,
  author       = {B. Chwyl and A. G. Chung and R. Amelara and J. Deglint and D. A. Clausi and A. Wong},
  title        = {{SAPPHIRE}: Stochastically acquired photoplethysmogram for heart rate inference in realistic environments},
  booktitle    = {2016 {IEEE} International Conference on Image Processing ({ICIP})},
  year         = {2016},
  pages        = {1230--1234},
  month        = {sep},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {A novel method, Stochastically Acquired Photoplethysmogram
for Heart rate Inference in Realistic Environments
(SAPPHIRE), is proposed for robust remote heart rate measurement
through broadband video. A set of stochastically
sampled points from the cheek region is tracked and used
to construct corresponding time series observations via skin
erythema transforms. From these observations, a photoplethysmogram
(PPG) waveform is estimated via Bayesian
minimization, with the required posterior probability inferred
using a Monte Carlo approach. To mitigate the effects of
noise, the contribution of each observation is weighted based
on the observation’s likelihood to contain relevant data. A
bandpass filter is applied to the estimated PPG waveform to
omit implausible heart rate frequencies, and the heart rate
is estimated through frequency domain analysis. Experimental
results acquired from a set of thirty videos indicate
significantly improved performance in comparison to stateof-the-art
methods},
  doi          = {10.1109/icip.2016.7532554},
  file         = {:chwyl2016sapphire - SAPPHIRE_ Stochastically acquired photoplethysmogram for heart rate inference in realistic environments.pdf:PDF},
  review       = {t pf},
  url          = {http://dx.doi.org/10.1109/icip.2016.7532554},
}

@Article{takano2007heart,
  author    = {Chihiro Takano and Yuji Ohta},
  title     = {Heart rate measurement based on a time-lapse image},
  journal   = {Medical Engineering {\&} Physics},
  year      = {2007},
  volume    = {29},
  number    = {8},
  pages     = {853--857},
  month     = {oct},
  abstract  = {Using a time-lapse image acquired from a CCD camera, we developed a non-contact and non-invasive device, which could measure both
the respiratory and pulse rate simultaneously. The time-lapse image of a part of the subject’s skin was consecutively captured, and the changes
in the average image brightness of the region of interest (ROI) were measured for 30 s. The brightness data were processed by a series of
operations of interpolation as follows a first-order derivative, a low pass filter of 2 Hz, and a sixth-order auto-regressive (AR) spectral analysis.
Fourteen sound and healthy female subjects (22–27 years of age) participated in the experiments. Each subject was told to keep a relaxed
seating posture with no physical restriction. At the same time, heart rate was measured by a pulse oximeter and respiratory rate was measured
by a thermistor placed at the external naris. Using AR spectral analysis, two clear peaks could be detected at approximately 0.3 and 1.2 Hz.
The peaks were thought to correspond to the respiratory rate and the heart rate. Correlation coefficients of 0.90 and 0.93 were obtained for
the measurement of heart rate and respiratory rate, respectively.
© 2006 IPEM. Published by Elsevier Ltd. All rights reserved.},
  doi       = {10.1016/j.medengphy.2006.09.006},
  file      = {:takano2007heart - Heart rate measurement based on a time-lapse image.pdf:PDF},
  publisher = {Elsevier {BV}},
  review    = {- One of the first PPG initiatives;
- Able to rudimentary detect HR and RR signals, however no HR nor RR (e.g. bpm) is provided.
- ROI is selected manually
- Tests were performed for 30 seconds.},
  timestamp = {2016-08-25},
  url       = {http://dx.doi.org/10.1016/j.medengphy.2006.09.006},
}

@Article{bousefsaf2013continuous,
  author    = {Fr{\'{e}}d{\'{e}}ric Bousefsaf and Choubeila Maaoui and Alain Pruski},
  title     = {Continuous wavelet filtering on webcam photoplethysmographic signals to remotely assess the instantaneous heart rate},
  journal   = {Biomedical Signal Processing and Control},
  year      = {2013},
  volume    = {8},
  number    = {6},
  pages     = {568--574},
  month     = {nov},
  abstract  = {Photoplethysmographic signals obtained from a webcam are analyzed through a continuous wavelettransform to assess the instantaneous heart rate. The measurements are performed on human faces.Robust image and signal processing are introduced to overcome drawbacks induced by light and motionartifacts. In addition, the respiration signal is recovered using the heart rate series by respiratory sinusarrhythmia, the natural variation in heart rate driven by the respiration. The presented algorithms areimplemented on a mid-range computer and the overall method works in real-time. The performanceof the proposed heart and breathing rates assessment method was evaluated using approved contactprobes on a set of 12 healthy subjects. Results show high degrees of correlation between physiologi-cal measurements even in the presence of motion. This paper provides a motion-tolerant method thatremotely measures the instantaneous heart and breathing rates. These parameters are particularly usedin telemedicine and affective computing, where the heart rate variability analysis can provide an indexof the autonomic nervous system.},
  doi       = {10.1016/j.bspc.2013.05.010},
  file      = {:bousefsaf2013continuous - Continuous wavelet filtering on webcam photoplethysmographic signals to remotely assess the instantaneous heart rate.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.bspc.2013.05.010},
}

@Article{verkruysse2008remote,
  author    = {Wim Verkruysse and Lars O Svaasand and J Stuart Nelson},
  title     = {Remote plethysmographic imaging using ambient light},
  journal   = {Opt. Express},
  year      = {2008},
  volume    = {16},
  number    = {26},
  pages     = {21434},
  month     = {dec},
  abstract  = {Plethysmographic signals were measured remotely (>1m) using ambient light and a simple consumer level digital camera in movie mode. Heart and respiration rates could be quantified up to several harmonics. Although the green channel featuring the strongest plethysmographic signal, corresponding to an absorption peak by (oxy-) hemoglobin, the red and blue channels also contained plethysmographic information. The results show that ambient light photo-plethysmography may be useful for medical purposes such as characterization of vascular skin lesions (e.g., port wine stains) and remote sensing of vital signs (e.g., heart and respiration rates) for triage or sports purposes.},
  doi       = {10.1364/oe.16.021434},
  file      = {:verkruysse2008remote - Remote plethysmographic imaging using ambient light.pdf:PDF},
  publisher = {The Optical Society},
  timestamp = {2016-08-24},
  url       = {http://dx.doi.org/10.1364/oe.16.021434},
}

@Article{sun2012noncontact,
  author    = {Yu Sun and Sijung Hu and Vicente Azorin-Peris and Roy Kalawsky and Stephen Greenwald},
  title     = {Noncontact imaging photoplethysmography to effectively access pulse rate variability},
  journal   = {J. Biomed. Opt},
  year      = {2012},
  volume    = {18},
  number    = {6},
  pages     = {061205},
  month     = {oct},
  abstract  = {Noncontact imaging photoplethysmography (PPG) can provide physiological assessment at various anatomical locations with no discomfort to the patient. However, most previous imaging PPG (iPPG) systems have been limited by a low sample frequency, which restricts their use clinically, for instance, in the assessment of pulse rate variability (PRV). In the present study, plethysmographic signals are remotely captured via an iPPG system at a rate of 200 fps. The physiological parameters (i.e., heart and respiration rate and PRV) derived from the iPPG datasets yield statistically comparable results to those acquired using a contact PPG sensor, the gold standard. More importantly, we present evidence that the negative influence of initial low sample frequency could be compensated via interpolation to improve the time domain resolution. We thereby provide further strong support for the low-cost webcam-based iPPG technique and, importantly, open up a new avenue for effective noncontact assessment of multiple physiological parameters, with potential applications in the evaluation of cardiac autonomic activity and remote sensing of vital physiological signs.},
  doi       = {10.1117/1.jbo.18.6.061205},
  file      = {:sun2012noncontact - Noncontact imaging photoplethysmography to effectively access pulse rate variability.pdf:PDF},
  publisher = {{SPIE}-Intl Soc Optical Eng},
  review    = {- Support that low-end camera  (e.g. 20 FPS) is as good as a 200 FPS camera
- Low sample frequency (e.g. 20 fps) can be compensated using Interpolation to improve time domain resolution},
  url       = {http://dx.doi.org/10.1117/1.jbo.18.6.061205},
}

@Article{valenza2014revealing,
  author    = {Gaetano Valenza and Luca Citi and Antonio Lanat{\'{a}} and Enzo Pasquale Scilingo and Riccardo Barbieri},
  title     = {Revealing Real-Time Emotional Responses: a Personalized Assessment based on Heartbeat Dynamics},
  journal   = {Sci. Rep.},
  year      = {2014},
  volume    = {4},
  month     = {may},
  doi       = {10.1038/srep04998},
  file      = {:valenza2014revealing - Revealing Real-Time Emotional Responses a Personalized Assessment based on Heartbeat Dynamics.pdf:PDF},
  publisher = {Nature Publishing Group},
  url       = {http://dx.doi.org/10.1038/srep04998},
}

@Article{poh2010non,
  author    = {Ming-Zher Poh and Daniel J. McDuff and Rosalind W. Picard},
  title     = {Non-contact, automated cardiac pulse measurements using video imaging and blind source separation},
  journal   = {Opt. Express},
  year      = {2010},
  volume    = {18},
  number    = {10},
  pages     = {10762},
  month     = {may},
  abstract  = {Remote measurements of the cardiac pulse can provide comfortable physiological assessment without electrodes. However, attempts so far are non-automated, susceptible to motion artifacts and typically expensive. In this paper, we introduce a new methodology that overcomes these problems. This novel approach can be applied to color video recordings of the human face and is based on automatic face tracking along with blind source separation of the color channels into independent components. Using Bland-Altman and correlation analysis, we compared the cardiac pulse rate extracted from videos recorded by a basic webcam to an FDA-approved finger blood volume pulse (BVP) sensor and achieved high accuracy and correlation even in the presence of movement artifacts. Furthermore, we applied this technique to perform heart rate measurements from three participants simultaneously. This is the first demonstration of a low-cost accurate video-based method for contact-free heart rate measurements that is automated, motion-tolerant and capable of performing concomitant measurements on more than one person at a time.},
  doi       = {10.1364/oe.18.010762},
  file      = {poh2010non - Non-contact automated cardiac pulse measurements using video imaging and blind source separation.pdf:poh2010non - Non-contact automated cardiac pulse measurements using video imaging and blind source separation.pdf:PDF},
  publisher = {The Optical Society},
  url       = {http://dx.doi.org/10.1364/oe.18.010762},
}

@Article{mcduff2014improvements,
  author    = {Daniel McDuff and Sarah Gontarek and Rosalind W. Picard},
  title     = {Improvements in Remote Cardiopulmonary Measurement Using a Five Band Digital Camera},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2014},
  volume    = {61},
  number    = {10},
  pages     = {2593--2601},
  month     = {oct},
  abstract  = {Remote measurement of the blood volume pulse via photoplethysmography (PPG) using digital cameras and ambient light has great potential for healthcare and affective computing. However, traditional RGB cameras have limited frequency resolution. We present results of PPG measurements from a novel five band camera and show that alternate frequency bands, in particular an orange band, allowed physiological measurements much more highly correlated with an FDA approved contact PPG sensor. In a study with participants (n = 10) at rest and under stress, correlations of over 0.92 (p < 0.01) were obtained for heart rate, breathing rate, and heart rate variability measurements. In addition, the remotely measured heart rate variability spectrograms closely matched those from the contact approach. The best results were obtained using a combination of cyan, green, and orange (CGO) bands; incorporating red and blue channel observations did not improve performance. In short, RGB is not optimal for this problem: CGO is better. Incorporating alternative color channel sensors should not increase the cost of such cameras dramatically.},
  doi       = {10.1109/tbme.2014.2323695},
  file      = {:mcduff2014improvements - Improvements in Remote Cardiopulmonary Measurement Using a Five Band Digital Camera.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/tbme.2014.2323695},
}

@Article{de_Haan_2013,
  author    = {Gerard de Haan and Vincent Jeanne},
  title     = {Robust Pulse Rate From Chrominance-Based {rPPG}},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2013},
  volume    = {60},
  number    = {10},
  pages     = {2878--2886},
  month     = {oct},
  abstract  = {Remote photoplethysmography (rPPG) enables contactless monitoring of the blood volume pulse using a regular camera. Recent research focused on improved motion robustness, but the proposed blind source separation techniques (BSS) in RGB color space show limited success. We present an analysis of the motion problem, from which far superior chrominance-based methods emerge. For a population of 117 stationary subjects, we show our methods to perform in 92\% good agreement (±1.96σ) with contact PPG, with RMSE and standard deviation both a factor of two better than BSS-based methods. In a fitness setting using a simple spectral peak detector, the obtained pulse-rate for modest motion (bike) improves from 79\% to 98\% correct, and for vigorous motion (stepping) from less than 11\% to more than 48\% correct. We expect the greatly improved robustness to considerably widen the application scope of the technology.},
  doi       = {10.1109/tbme.2013.2266196},
  file      = {:de_Haan_2013 - Robust Pulse Rate From Chrominance-Based rPPG.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/tbme.2013.2266196},
}

@Article{dingli2016webcam,
  author    = {Alexiei Dingli and Andreas Giordimaina},
  title     = {Webcam-based detection of emotional states},
  journal   = {The Visual Computer},
  year      = {2016},
  pages     = {1--11},
  month     = {sep},
  abstract  = {Game designers have to deal with the complex task of monitoring the emotional state of players in games. There are different elements with the game, which effect the player’s emotional status. Since the game play experience occurs almost unconsciously, traditional methods such as think aloud may disrupt the playing experience, thus skewing the results obtained. Other methods include fitting cables and electrodes to the player to monitor biological information. Although such devices can offer significant accurate results, they are not commonly found and may cause discomfort while playing games. Because of this, we propose a webcambased heart rate monitoring method that can be used to predict the player’s emotional state. We first analyzed the change in heart rate with respect to the players emotional state. This allowed us to find a correlation between emotional states, such as frustration, fun, challenge, and boredom. The second objective was to create a webcam-based method to monitor the heart rate. This was performed by extracting the RGB channels from the face region and then retrieving the underlying components using a dimensionality-reduction method. The results obtained from the webcam-based method were far from perfect, but this was expected, since we were performing the tests under realistic conditions. The last objective  was to predict the player’s emotional state using the heart rate obtained from the webcam-based method. The accuracy of the prediction was up to 76\%, which exceeded our initial aim. This system will be implemented in Unity 3D to make its integration and adoption easier.},
  doi       = {10.1007/s00371-016-1309-x},
  file      = {:dingli2016webcam - Webcam-based detection of emotional states.pdf:PDF},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/s00371-016-1309-x},
}

@Article{shao2016simultaneous,
  author    = {Dangdang Shao and Francis Tsow and Chenbin Liu and Yuting Yang and Nongjian Tao},
  title     = {Simultaneous Monitoring of Ballistocardiogram and Photoplethysmogram Using Camera},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2016},
  pages     = {1--1},
  abstract  = {We present a noncontact method to measure Ballistocardiogram (BCG) and Photoplethysmogram (PPG) simultaneously using a single camera. The method tracks the motion of facial features to determine displacement BCG, and extracts the corresponding velocity and acceleration BCGs by taking first and second temporal derivatives from the displacement BCG, respectively. The measured BCG waveforms are consistent with those reported in literature and also with those recorded with an accelerometer-based reference method. The method also tracks PPG based on the reflected light from the same facial region, which makes it possible to track both BCG and PPG with the same optics. We verify the robustness and reproducibility of the noncontact method with a small pilot study with 23 subjects. The presented method is the first demonstration of simultaneous BCG and PPG monitoring without wearing any extra equipment or marker by the subject.},
  doi       = {10.1109/tbme.2016.2585109},
  file      = {:shao2016simultaneous - Simultaneous Monitoring of Ballistocardiogram and Photoplethysmogram Using Camera.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/tbme.2016.2585109},
}

@Article{tarvainen2002advanced,
  author    = {M.P. Tarvainen and P.O. Ranta-aho and P.A. Karjalainen},
  title     = {An advanced detrending method with application to {HRV} analysis},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2002},
  volume    = {49},
  number    = {2},
  pages     = {172--175},
  abstract  = {An advanced, simple to use, detrending method to be used before heart rate variability analysis (HRV) is presented. The method is based on smoothness priors approach and operates like a time-varying FIR high pass filter. The effect of the detrending on time and frequency domain analysis of HRV is studied.},
  doi       = {10.1109/10.979357},
  file      = {:tarvainen2002advanced - An advanced detrending method with application to HRV analysis.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/10.979357},
}

@Article{qi2017video,
  author    = {Huan Qi and Zhenyu Guo and Xun Chen and Zhiqi Shen and Z. Jane Wang},
  title     = {Video-based human heart rate measurement using joint blind source separation},
  journal   = {Biomedical Signal Processing and Control},
  year      = {2017},
  volume    = {31},
  pages     = {309--320},
  month     = {jan},
  abstract  = {Remote (non-contact) measurements of human cardiopulmonary physiological parameters based on photoplethysmography (PPG) can lead to efficient and comfortable medical assessment, which is important in human healthcare. It was shown that human facial blood volume variation during cardiac cycle can be indirectly captured by common Red–Green–Blue (RGB) cameras. In this paper, we show that it is promising to incorporate data from different facial sub-regions to improve remote measurement performance. We propose a novel method for non-contact video-based human heart rate (HR) measurement by exploring correlations among facial sub-regions via joint blind source separation (J-BSS). To our knowledge, this is the first time that J-BSS approaches, instead of prevailing BSS techniques such as independent component analysis (ICA), is successfully applied in non-contact physiological parameter measurement. We test the proposed method on a large public database, which provides the subjects’ left-thumb plethysmograph signals as ground truth. Experimental results show that the proposed J-BSS method outperforms previous ICA-based methodologies.},
  doi       = {10.1016/j.bspc.2016.08.020},
  file      = {:qi2017video - Video-based human heart rate measurement using joint blind source separation.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.bspc.2016.08.020},
}

@Article{Wang_2016algorithmic,
  author    = {Wenjin Wang and Albertus den Brinker and Sander Stuijk and Gerard de Haan},
  title     = {Algorithmic Principles of Remote-{PPG}},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2016},
  pages     = {1--1},
  abstract  = {—This paper introduces a mathematical model that incorporates the pertinent optical and physiological properties of skin reflections with the objective to increase our understanding of the algorithmic principles behind remote photoplethysmography (rPPG). The model is used to explain the different choices that were made in existing rPPG methods for pulse extraction. The understanding that comes from the model can be used to design robust or application-specific rPPG solutions. We illustrate this by designing an alternative rPPG method where a projection plane orthogonal to the skin-tone is used for pulse extraction. A large benchmark on the various discussed rPPG methods shows that their relative merits can indeed be understood from the proposed model.},
  doi       = {10.1109/tbme.2016.2609282},
  file      = {:Wang_2016 - Algorithmic Principles of Remote-PPG.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/TBME.2016.2609282},
}

@Article{Wang_2016novel,
  author    = {Wenjin Wang and Sander Stuijk and Gerard de Haan},
  title     = {A Novel Algorithm for Remote Photoplethysmography: Spatial Subspace Rotation},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2016},
  volume    = {63},
  number    = {9},
  pages     = {1974--1984},
  month     = {sep},
  doi       = {10.1109/TBME.2015.2508602},
  file      = {Wang_2016 - Algorithmic Principles of Remote-PPG.pdf:Wang_2016 - Algorithmic Principles of Remote-PPG.pdf:PDF},
  issn      = {0018-9294},
  keywords  = {biomedical equipment;cameras;cardiology;image denoising;independent component analysis;medical image processing;photoplethysmography;reviews;2SR algorithm;2SR outperforms;ICA-based approach;MATLAB code;Pearson correlation and precision;SNR;benchmark dataset;body-motions;camera;complex illuminance conditions;pulse extraction;pulse frequency spectrum;pulse-rate recovery;remote photoplethysmography;skin mask;skin-tone;spatial subspace rotation;spatially redundant pixel-sensors;state-of-the-art algorithms;temporal rotation;Blood;Cameras;Color;Photoplethysmography;Robustness;Skin;Biomedical monitoring;colors;photoplethysmography;remote sensing},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/TBME.2015.2508602},
}

@InCollection{taelman2009influence,
  author       = {Joachim Taelman and S. Vandeput and A. Spaepen and S. Van Huffel},
  title        = {Influence of Mental Stress on Heart Rate and Heart Rate Variability},
  booktitle    = {{IFMBE} Proceedings},
  publisher    = {Springer Science $\mathplus$ Business Media},
  year         = {2009},
  pages        = {1366--1369},
  abstract     = {Stress is a huge problem in today’s society. Being able to measure stress, therefore, may help to address this problem. Although stress has a psychological origin, it affects several physiological processes in the human body: increased muscle tension in the neck, change in concentration of several hormones and a change in heart rate (HR) and heart rate variability (HRV). The brain innervates the heart by means of stimuli via the Autonomic Nervous System (ANS), which is divided into sympathetic and parasympathetic branches. The sympathetic activity leads to an increase in HR (e.g. during sports exercise), while parasympathetic activity induces a lower HR (e.g. during sleep). The two circuits are constantly interacting and this interaction is reflected in HRV. HRV, therefore, provides a measure to express the activity of the ANS, and may consequently provide a measure for stress. We therefore explored measures of HR and HRV with an imposed stressful situation. We recorded changes in HR and HRV in a group of 28 subjects at rest, and with a mental stressor. The results suggest that HR and HRV change with a mental task. HR and HRV recordings may have the potential, therefore, to measure stress levels and guide preventive measures to reduce stress related illnesses.},
  doi          = {10.1007/978-3-540-89208-3_324},
  file         = {:taelman2009influence - Influence of Mental Stress on Heart Rate and Heart Rate Variability.pdf:PDF},
  organization = {Springer},
  timestamp    = {2016-10-14},
  url          = {http://dx.doi.org/10.1007/978-3-540-89208-3_324},
}

@Article{wang2015exploiting,
  author    = {Wenjin Wang and Sander Stuijk and Gerard de Haan},
  title     = {Exploiting Spatial Redundancy of Image Sensor for Motion Robust {rPPG}},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2015},
  volume    = {62},
  number    = {2},
  pages     = {415--425},
  month     = {feb},
  abstract  = {Remote photoplethysmography (rPPG) techniques can measure cardiac activity by detecting pulse-induced color variations on human skin using an RGB camera. State-of-the-art rPPG methods are sensitive to subject body motions (e.g., motion-induced color distortions). This study proposes a novel framework to improve the motion robustness of rPPG. The basic idea of this paper originates from the observation that a camera can simultaneously sample multiple skin regions in parallel, and each of them can be treated as an independent sensor for pulse measurement. The spatial redundancy of an image sensor can thus be exploited to distinguish the pulse signal from motion-induced noise. To this end, the pixel-based rPPG sensors are constructed to estimate a robust pulse signal using motion-compensated pixel-to-pixel pulse extraction, spatial pruning, and temporal filtering. The evaluation of this strategy is not based on a full clinical trial, but on 36 challenging benchmark videos consisting of subjects that differ in gender, skin types, and performed motion categories. Experimental results show that the proposed method improves the SNR of the state-of-the-art rPPG technique from 3.34 to 6.76 dB, and the agreement (+-1.96s) with instantaneous reference pulse rate from 55\% to 80\% correct. ANOVA with post hoc comparison shows that the improvement on motion robustness is significant. The rPPG method developed in this study has a performance that is very close to that of the contact-based sensor under realistic situations, while its computational efficiency allows real-time processing on an off-the-shelf computer.},
  doi       = {10.1109/tbme.2014.2356291},
  file      = {:wang2015exploiting - Exploiting Spatial Redundancy of Image Sensor for Motion Robust rPPG.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/tbme.2014.2356291},
}

@InProceedings{bevilacqua2016variations,
  author       = {Fernando Bevilacqua and Per Backlund and Henrik Engstrom},
  title        = {Variations of Facial Actions While Playing Games with Inducing Boredom and Stress},
  booktitle    = {2016 8th International Conference on Games and Virtual Worlds for Serious Applications ({VS}-{GAMES})},
  year         = {2016},
  pages        = {1--8},
  month        = {sep},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {This paper presents an experiment aimed at empirically exploring the variations of facial actions (FA) during gaming sessions with induced boredom and stress. Twenty adults with different ages and gaming experiences played three games while being recorded by a video camera and monitored by a heart rate sensor. The games were carefully designed to have a linear progression from a boring to a stressful state. Selfreported answers indicate participants perceived the games as being boring at the beginning and stressful at the end. The 6 hours of recordings of all subjects were manually analyzed and FA were annotated. We annotated FA that appeared in the recordings at least twice; annotations were categorized by the period when they happened (boring/stressful part of the games) and analysed on a group and on an individual level. Group level analysis revealed that FA patterns were related to no more than 25\% of the subjects. The individual level analysis revealed particular patterns for 50\% of the subjects. More FA annotations were made during the stressful part of the games. We conclude that, for the context of our experiment, FA provide an unclear foundation for detection of boredom/stressful states when observed from a group level perspective, while the individual level perspective might produce more information.},
  doi          = {10.1109/vs-games.2016.7590374},
  file         = {bevilacqua2016variations - Variations of Facial Actions While Playing Games with Inducing Boredom and Stress.pdf:bevilacqua2016variations - Variations of Facial Actions While Playing Games with Inducing Boredom and Stress.pdf:PDF},
  url          = {http://dx.doi.org/10.1109/vs-games.2016.7590374},
}

@Article{eleuteri2012efficient,
  author    = {Eleuteri, Antonio and Fisher, Anthony C and Groves, David and Dewhurst, Christpher J},
  title     = {An Efficient Time-Varying Filter for Detrending and Bandwidth Limiting the Heart Rate Variability Tachogram without Resampling: {MATLAB} Open-Source Code and Internet Web-Based Implementation},
  journal   = {Computational and Mathematical Methods in Medicine},
  year      = {2012},
  volume    = {2012},
  pages     = {1--6},
  abstract  = {The heart rate variability (HRV) signal derived from the ECG is a beat-to-beat record of RR intervals and is, as a time series, irregularly sampled. It is common engineering practice to resample this record, typically at 4 Hz, onto a regular time axis for analysis in advance of time domain filtering and spectral analysis based on the DFT. However, it is recognised that resampling introduces noise and frequency bias. The present work describes the implementation of a time-varying filter using a smoothing priors approach based on a Gaussian process model, which does not require data to be regular in time. Its output is directly compatible with the Lomb-Scargle algorithm for power density estimation. A web-based demonstration is available over the Internet for exemplar data. The MATLAB (MathWorks Inc.) code can be downloaded as open source.},
  doi       = {10.1155/2012/578785},
  file      = {:eleuteri2012efficient - An Efficient Time-Varying Filter for Detrending and Bandwidth Limiting the Heart Rate Variability Tachogram without Resampling.pdf:PDF},
  publisher = {Hindawi Publishing Corporation},
  timestamp = {2016-12-06},
  url       = {http://dx.doi.org/10.1155/2012/578785},
}

@InProceedings{xu2016study,
  author       = {Beilei Xu and Himanshu Madhu and Lalit K. Mestha},
  title        = {A study of the effect of subject motion to pulse rate estimation},
  booktitle    = {2016 38th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
  year         = {2016},
  pages        = {4901--4904},
  month        = {aug},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {we presented a systematic study of how subject head motion affects pulse rate estimation using photoplethysmography from the subject’s face. We evaluated the performance at various steps in the process, including object tracking, skin blob detection, pulse signal extraction and pulse rate estimation. We demonstrated that the signal-to-noise ratio of the power spectrum is a good indicator of signal artifacts induced by subject motion, thus can be used as a quantitative metric in continuous pulse rate monitoring to reduce estimation errors.},
  doi          = {10.1109/embc.2016.7591826},
  file         = {:xu2016study - A study of the effect of subject motion to pulse rate estimation.pdf:PDF},
  timestamp    = {2016-12-07},
  url          = {http://dx.doi.org/10.1109/embc.2016.7591826},
}

@Article{sun2016photoplethysmography,
  author    = {Yu Sun and Nitish Thakor},
  title     = {Photoplethysmography Revisited: From Contact to Noncontact, From Point to Imaging},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2016},
  volume    = {63},
  number    = {3},
  pages     = {463--477},
  month     = {mar},
  abstract  = {Photoplethysmography (PPG) is a noninvasive optical technique for detecting microvascular blood volume changes in tissues. Its ease of use, low cost and convenience make it an attractive area of research in the biomedical and clinical communities. Nevertheless, its single spot monitoring and the need to apply a PPG sensor directly to the skin limit its practicality in situations such as perfusion mapping and healing assessments or when free movement is required. The introduction of fast digital cameras into clinical imaging monitoring and diagnosis systems, the desire to reduce the physical restrictions, and the possible new insights that might come from perfusion imaging and mapping inspired the evolution of the conventional PPG technology to imaging PPG (IPPG). IPPG is a noncontact method that can detect heartgenerated pulse waves by means of peripheral blood perfusion measurements. Since its inception, IPPG has attracted significant public interest and provided opportunities to improve personal healthcare. This study presents an overview of the wide range of IPPG systems currently being introduced along with examples of their application in various physiological assessments. We believe that the widespread acceptance of IPPG is happening, and it will dramatically accelerate the promotion of this healthcare model in the near future.},
  doi       = {10.1109/tbme.2015.2476337},
  file      = {:sun2016photoplethysmography - Photoplethysmography Revisited_ From Contact to Noncontact, From Point to Imaging.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {http://dx.doi.org/10.1109/tbme.2015.2476337},
}

@Article{fauquet2016heart,
  author    = {Philippe Fauquet-Alekhine and Laetitia Rouillac and J{\'{e}}r{\^{o}}me Berton and Jean-Claude Granry},
  title     = {Heart Rate vs Stress Indicator for Short Term Mental Stress},
  journal   = {British Journal of Medicine and Medical Research},
  year      = {2016},
  volume    = {17},
  number    = {7},
  pages     = {1--11},
  month     = {jan},
  abstract  = {Heart rate variation (HR) being identified as depending on subjects’ stress state when submitted to short term mental stress, this study aimed at analyzing whether or not it could be possible to find a mathematical relationship between the average heart rate variation and the intensity S of a stress indicator in case of short term mental stress, whatever the stress indicator is. The method consisted in working the hypothesis by gathering data providing HR and ratio of frequency power of HRV (Heart Rate Variability) for different level of stress, HRV being considered as a stress indicator and presenting the advantage of being widely used in studies, therefore providing numerous data in the literature. From this data, a mathematical model was designed and then assessed by testing its reliability when applied to HR variation versus different types of stress indicators (EMG, GSR, Work Load, questionnaires such as STAI-S, ALES). The correlation obtained between the model and the data provided by the literature (24 points from 8 studies gathering 272 subjects) gave r=.95 (p<.0001) which allowed us to validate the model. Limits of the model were identified and discussed.},
  doi       = {10.9734/bjmmr/2016/27593},
  file      = {:fauquet2016heart - Heart Rate vs Stress Indicator for Short Term Mental Stress.pdf:PDF},
  publisher = {Sciencedomain International},
  url       = {http://dx.doi.org/10.9734/bjmmr/2016/27593},
}

@InProceedings{mcduff2016discovering,
  author       = {Daniel McDuff},
  title        = {Discovering facial expressions for states of amused, persuaded, informed, sentimental and inspired},
  booktitle    = {Proceedings of the 18th {ACM} International Conference on Multimodal Interaction - {ICMI} 2016},
  year         = {2016},
  pages        = {71--75},
  organization = {ACM},
  publisher    = {Association for Computing Machinery ({ACM})},
  abstract     = {Facial expressions play a significant role in everyday interactions. A majority of the research on facial expressions of emotion has focused on a small set of "basic" states. However, in real-life the expression of emotions is highly context dependent and prototypic expressions of "basic" emotions may not always be present. In this paper we attempt to discover expressions associated with alternate states of informed, inspired, persuaded, sentimental and amused based on a very large dataset of observed facial responses. We used a curated set of 395 everyday videos that were found to reliably elicit the states and recorded 49,869 facial responses as viewers watched the videos in their homes. Using automated facial coding we quantified the presence of 18 facial actions in each of the 23.4 million frames. Lip corner pulls, lip sucks and inner brow raises were prominent in sentimental responses. Outer brow raises and eye widening were prominent in persuaded and informed responses. More brow furrowing distinguished informed from persuaded responses potentially indicating higher cognition.},
  doi          = {10.1145/2993148.2993192},
  file         = {:mcduff2016discovering - Discovering facial expressions for states of amused, persuaded, informed, sentimental and inspired.pdf:PDF},
  url          = {http://dx.doi.org/10.1145/2993148.2993192},
}

@InCollection{samara2016sensing,
  author       = {Anas Samara and Leo Galway and Raymond Bond and Hui Wang},
  title        = {Sensing Affective States Using Facial Expression Analysis},
  booktitle    = {Ubiquitous Computing and Ambient Intelligence},
  publisher    = {Springer Nature},
  year         = {2016},
  pages        = {341--352},
  abstract     = {An important factor for the next generation of Human Computer Interaction is the implementation of an interaction model that automatically reasons in context of the users goals, attitudes, affective characteristics and capabilities, and adapts the system accordingly. Although various techniques have been proposed for automatically detecting affective states using facial expression, this is still a research challenge in terms of classification accuracy. This paper investigates an extensible automatic affective state detection approach via the analysis of facial expressions from digital photographs. The main contribution of this study can be summarised in two points. Firstly, utilising facial point distance vectors within the representation of facial expressions is shown to be more accurate and robust in comparison to using standard Cartesian coordinates. Secondly, employing a two-stage Support Vector Machine-based classification model, entitled Hierarchical Parallelised Binary Support Vector Machines (HPBSVM), is shown to improve classification performance over other machine learning techniques. The resulting classification model has been evaluated using two different facial expression datasets (namely CKPLUS and KDEF), yielding accuracy rates of 96.9\% and 96.2\% over each dataset respectively.},
  doi          = {10.1007/978-3-319-48746-5_35},
  file         = {:samara2016sensing - Sensing Affective States Using Facial Expression Analysis.pdf:PDF},
  organization = {Springer},
}

@InProceedings{arroyo2008towards,
  author    = {Arroyo-Palacios, J and Romano, DM},
  title     = {Towards a standardization in the use of physiological signals for affective recognition systems},
  booktitle = {Measuring Behavior},
  year      = {2008},
  abstract  = {The implementation of physiological signals, as an approach for emotion recognition in computer systems, is not a straight forward task. This paper discusses five main areas that lack of standards and guided principles, which have led Human-Computer Interaction (HCI) researchers to take critical decisions about (i) models, (ii) stimulus, (iii) measures, (iv) features and (v) algorithms with some degree of uncertainty about their results. Methodology standardization would allow comparison of results, reusability of findings and easier integration of the various affective recognition systems created. The background theory is given for each of the five areas and the related work from psychology is briefly reviewed. A comparison table of the HCI common approaches of the five discussed areas is presented, and finally some considerations to take the best decisions are discussed. The aim of this paper is to provide directions on which the future research efforts for affective recognition in HCI should be focused on.},
  file      = {:arroyo2008towards - Towards a standardization in the use of physiological signals for affective recognition systems.pdf:PDF},
}

@InProceedings{brogni2006variations,
  author       = {Andrea Brogni and Vinoba Vinayagamoorthy and Anthony Steed and Mel Slater},
  title        = {Variations in physiological responses of participants during different stages of an immersive virtual environment experiment},
  booktitle    = {Proceedings of the {ACM} symposium on Virtual reality software and technology - {VRST} {\textquotesingle}06},
  year         = {2006},
  pages        = {376--382},
  organization = {ACM},
  publisher    = {Association for Computing Machinery ({ACM})},
  abstract     = {This paper presents a study of the fine grain physiological responses of participants to an immersive virtual simulation of an urban environment. The analysis of differences in participant responses at various stages of the experiment (baseline recordings, training, first half and second half of the urban simulation) are examined in detail. It was found that participants typically show a stress response during the training phase and a stress response towards the end of the simulation of the urban experience. There is also some evidence that variations in the level of visual realism based the texture strategy used was associated with changes in mental stress.},
  doi          = {10.1145/1180495.1180572},
  file         = {:brogni2006variations - Variations in physiological responses of participants during different stages of an immersive virtual environment experiment.pdf:PDF},
}

@InProceedings{lin2008using,
  author       = {Tao Lin and Akinobu Maejima and Shigeo Morishima},
  title        = {Using subjective and physiological measures to evaluate audience-participating movie experience},
  booktitle    = {Proceedings of the working conference on Advanced visual interfaces - {AVI} {\textquotesingle}08},
  year         = {2008},
  pages        = {49--56},
  organization = {ACM},
  publisher    = {Association for Computing Machinery ({ACM})},
  abstract     = {In this paper we subjectively and physiologically investigate the effects of the audiences 3D virtual actor in a movie on their movie experience, using the audience participating movie DIM as the object of study. In DIM, the photo-realistic 3D virtual actors of audience are constructed by combining current computer graphics (CG) technologies and can act different roles in a pre-rendered CG movie. To facilitate the investigation, we presented three versions of a CG movie to an audience - a Traditional version, its Self-DIM (SDIM) version with the participation of the audience’s virtual actor, and its Self-Friend-DIM (SFDIM) version with the co-participation of the audience and his friends virtual actors. The results show that the participation of audience’s 3D virtual actors indeed cause increased subjective sense of presence and engagement, and emotional reaction; moreover, SFDIM performs significantly better than SDIM, due to increased social presence. Interestingly, when watching the three movie versions, subjects experienced not only significantly different galvanic skin response (GSR) changes on average - changing trend over time, and number of fluctuations - but they also experienced phasic GSR increase when watching their own and friends virtual 3D actors appearing on the movie screen. These results suggest that the participation of the 3D virtual actors in a movie can improve interaction and communication between audience and the movie.},
  doi          = {10.1145/1385569.1385580},
  file         = {:lin2008using - Using subjective and physiological measures to evaluate audience-participating movie experience.pdf:PDF},
}

@Article{meehan2002physiological,
  author    = {Michael Meehan and Brent Insko and Mary Whitton and Frederick P. Brooks},
  title     = {Physiological measures of presence in stressful virtual environments},
  journal   = {{ACM} Transactions on Graphics},
  year      = {2002},
  volume    = {21},
  number    = {3},
  pages     = {645--652},
  month     = {jul},
  abstract  = {A common measure of the quality or effectiveness of a virtual environment (VE) is the amount of presence it evokes in users. Presence is often defined as the sense of being there in a VE. There has been much debate about the best way to measure presence, and presence researchers need, and have sought, a measure that is reliable, valid, sensitive, and objective. We hypothesized that to the degree that a VE seems real, it would evoke physiological responses similar to those evoked by the corresponding real environment, and that greater presence would evoke a greater response. To examine this, we conducted three experiments, the results of which support the use of physiological reaction as a reliable, valid, sensitive, and objective presence measure. The experiments compared participants’ physiological reactions to a non-threatening virtual room and their reactions to a stressful virtual height situation. We found that change in heart rate satisfied our requirements for a measure of presence, change in skin conductance did to a lesser extent, and that change in skin temperature did not. Moreover, the results showed that inclusion of a passive haptic element in the VE significantly increased presence and that for presence evoked: 30FPS > 20FPS > 15FPS.},
  doi       = {10.1145/566654.566630},
  file      = {:meehan2002physiological - Physiological measures of presence in stressful virtual environments.pdf:PDF},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{shao2014noncontact,
  author    = {Dangdang Shao and Yuting Yang and Chenbin Liu and Francis Tsow and Hui Yu and Nongjian Tao},
  title     = {Noncontact Monitoring Breathing Pattern, Exhalation Flow Rate and Pulse Transit Time},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {2014},
  volume    = {61},
  number    = {11},
  pages     = {2760--2767},
  month     = {nov},
  abstract  = {We present optical imaging-based methods to measure vital physiological signals, including breathing frequency (BF), exhalation flow rate, heart rate (HR), and pulse transit time (PTT). The breathing pattern tracking was based on the detection of body movement associated with breathing using a differential signal processing approach. A motion-tracking algorithm was implemented to correct random body movements that were unrelated to breathing. The heartbeat pattern was obtained from the color change in selected region of interest (ROI) near the subject’s mouth, and the PTT was determined by analyzing pulse patterns at different body parts of the subject. The measured BF, exhaled volume flowrate andHRare consistentwith those measured simultaneously with reference technologies (r = 0.98, p < 0.001 for HR; r = 0.93,p < 0.001 for breathing rate), and the measured PTT difference (30-40 ms between mouth and palm) is comparable to the results obtained with other techniques in the literature. The imaging-based methods are suitable for tracking vital physiological parameters under free-living condition and this is the first demonstration of using noncontact method to obtain PTT difference and exhalation flow rate.},
  doi       = {10.1109/tbme.2014.2327024},
  file      = {:shao2014noncontact - Noncontact Monitoring Breathing Pattern, Exhalation Flow Rate and Pulse Transit Time.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{rouast2016remote,
  author   = {Rouast, Philipp V and ADAM, Marc TP and CHIONG, Raymond and CORNFORTH, David and LUX, Ewa},
  title    = {Remote heart rate measurement using low-cost RGB face video: A technical literature review},
  journal  = {Front. Comput. Sci},
  year     = {2016},
  abstract = {Remote Photoplethysmography (rPPG) allows remote measurement of the heart rate using low-cost RGB imaging equipment. In this paper, we review the development of the field since its emergence in 2008, classify existing approaches for rPPG, and derive a framework that provides an overview of modular steps. Based on this framework, practitioners can use the classification to orchestrate algorithms to an rPPG approach that suits their specific needs. Researchers can use the reviewed and classified algorithms as a starting point to improve particular features of an rPPG algorithm.},
  doi      = {10.1007/s11704-016-6243-6},
  file     = {:rouast2016remote - Remote heart rate measurement using low-cost RGB face video A technical literature review.pdf:PDF},
}

@InProceedings{chatterjee2016real,
  author       = {Avishek Chatterjee and A P Prathosh and Pragathi Praveena},
  title        = {Real-time respiration rate measurement from thoracoabdominal movement with a consumer grade camera},
  booktitle    = {2016 38th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
  year         = {2016},
  pages        = {2708--2711},
  month        = {aug},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {In this paper, we propose a novel computer vision technique to measure respiration rate by counting the periodic thoracoabdominal motion in real-time using an inexpensive consumer grade camera. We compute the component of optical flow parallel to the image gradient at each pixel, which is a computationally inexpensive operation. Then, we find a principal flow field by gathering information over many frames. Subsequently, in each frame, we compute the component of flow along this principal flow field to capture the thoracoabdominal motion. Our method is very simple, easy to implement and needs no specialized hardware. This method is computationally very efficient and can be easily implemented in mobile devices. We demonstrate the efficacy of our method on real world datasets and compare the results with those obtained using impedance pneumography.},
  doi          = {10.1109/embc.2016.7591289},
  file         = {:chatterjee2016real - Real-time respiration rate measurement from thoracoabdominal movement with a consumer grade camera.pdf:PDF},
}

@Article{martinez2013local,
  author    = {Brais Martinez and Michel F. Valstar and Xavier Binefa and Maja Pantic},
  title     = {Local Evidence Aggregation for Regression-Based Facial Point Detection},
  journal   = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2013},
  volume    = {35},
  number    = {5},
  pages     = {1149--1163},
  month     = {may},
  doi       = {10.1109/tpami.2012.205},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{saragih2011deformable,
  author    = {Jason M. Saragih and Simon Lucey and Jeffrey F. Cohn},
  title     = {Deformable Model Fitting by Regularized Landmark Mean-Shift},
  journal   = {International Journal of Computer Vision},
  year      = {2010},
  volume    = {91},
  number    = {2},
  pages     = {200--215},
  month     = {sep},
  doi       = {10.1007/s11263-010-0380-4},
  publisher = {Springer Nature},
}

@MastersThesis{roald2013estimation,
  author   = {Roald, Nikolai Grov},
  title    = {Estimation of vital signs from ambient-light non-contact photoplethysmography},
  school   = {Norwegian University of Science and Technology},
  year     = {2013},
  abstract = {In this thesis we have investigated different aspects of non-contact photoplethysmography (PPG) using only ambient lighting. We have investigated how to develop a functional, automatic system based on this to detect heart rate. We have also investigated how to use the concept of non-contact PPG to acquire further relevant medical information from a human subject. We have investigated different color spaces and found that the Hue and Saturation channels from HSL and HSV color spaces are far superior to the Green channel of the RGB color space, which has previously been used. Especially under circumstances with much noise, are these channels superior and more robust against noise. The concept of independent component analysis (ICA) has been investigated as a method of improving results. It is found to improve some channels and color spaces, but the best ICA channel does not have better performance than the best non-ICA channel. The phase of, and difference between, PPG signals has been investigated as a means of acquiring medical information. The phase measurements are highly vulnerable to noise, but there are indications that occlusion can induce a phase difference between different limbs. This difference can be used to calculate change in blood pressure. We have synchronized ECG and PPG data, and found that there is a high correlation between the two. Pulse transit time (PTT) from the heart to the measurement site can be calculated using this synchronized information. Further have different motion compensation algorithms and signal processing techniques been investigated with the goal of improving the PPG signal and a programs ability to automatically detect heart rate.},
  file     = {:roald2013estimation - Estimation of vital signs from ambient-light non-contact photoplethysmography.pdf:PDF},
}

@Article{monkaresi2014machine,
  author    = {Hamed Monkaresi and Rafael A. Calvo and Hong Yan},
  title     = {A Machine Learning Approach to Improve Contactless Heart Rate Monitoring Using a Webcam},
  journal   = {{IEEE} Journal of Biomedical and Health Informatics},
  year      = {2014},
  volume    = {18},
  number    = {4},
  pages     = {1153--1160},
  month     = {jul},
  abstract  = {Unobtrusive, contactless recordings of physiological signals are very important for many health and human-computer interaction applications. Most current systems require sensors which intrusively touch the user’s skin. Recent advances in contactfree physiological signals open the door to many new types of applications. This technology promises to measure heart rate (HR) and respiration using video only. The effectiveness of this technology, its limitations, and ways of overcoming them deserves particular attention. In this paper, we evaluate this technique for measuring HR in a controlled situation, in a naturalistic computer interaction session, and in an exercise situation. For comparison, HR wasmeasured simultaneously using an electrocardiography device during all sessions. The results replicated the published results in controlled situations, but show that they cannot yet be considered as a valid measure of HR in naturalistic human–computer interaction. We propose a machine learning approach to improve the accuracy of HR detection in naturalistic measurements. The results demonstrate that the root mean squared error is reduced from 43.76 to 3.64 beats/min using the proposed method.},
  doi       = {10.1109/jbhi.2013.2291900},
  file      = {:monkaresi2014machine - A Machine Learning Approach to Improve Contactless Heart Rate Monitoring Using a Webcam.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@InProceedings{hsu2014learning,
  author       = {YungChien Hsu and Yen-Liang Lin and Winston Hsu},
  title        = {Learning-based heart rate detection from remote photoplethysmography features},
  booktitle    = {2014 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
  year         = {2014},
  pages        = {4433--4437},
  month        = {may},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {Remote photoplethysmography (rPPG) enables measuring heart rate from recorded skin color variations with consumer cameras. Recent research has aimed to improve the signal strength of color variations caused by heart beat by using independent component analysis (ICA) technique or analyzing chrominance-based model. In this paper, we argue for treating this emerging problem in a novel aspect - proposing a learning-based framework to accommodate multiple and temporal feature and yielding significant and robust improvement. Using support vector regression (SVR) on published chrominance-based feature improves the root mean square error (RMSE) from 22.7 to 7.31 as well as correlation coefficient (CC) from 0.30 to 0.77. With proposed novel multiple feature fusion and multiple segment fusion techniques, we achieved the best estimation result with RMSE 5.48 and CC 0.88. Meanwhile, the proposed framework can be extended to other promising features.},
  doi          = {10.1109/icassp.2014.6854440},
  file         = {:hsu2014learning - Learning-based heart rate detection from remote photoplethysmography features.pdf:PDF},
}

@Article{zhao2013remote,
  author    = {Fang Zhao and Meng Li and Yi Qian and Joe Z. Tsien},
  title     = {Remote Measurements of Heart and Respiration Rates for Telemedicine},
  journal   = {{PLoS} {ONE}},
  year      = {2013},
  volume    = {8},
  number    = {10},
  pages     = {e71384},
  month     = {oct},
  abstract  = {Non-contact and low-cost measurements of heart and respiration rates are highly desirable for telemedicine. Here, we describe a novel technique to extract blood volume pulse and respiratory wave from a single channel images captured by a video camera for both day and night conditions. The principle of our technique is to uncover the temporal dynamics of heart beat and breathing rate through delay-coordinate transformation and independent component analysis-based deconstruction of the single channel images. Our method further achieves robust elimination of false positives via applying ratio-variation probability distributions filtering approaches. Moreover, it enables a much needed low-cost means for preventing sudden infant death syndrome in new born infants and detecting stroke and heart attack in elderly population in home environments. This noncontact-based method can also be applied to a variety of animal model organisms for biomedical research.},
  doi       = {10.1371/journal.pone.0071384},
  editor    = {Ioannis P. Androulakis},
  file      = {:zhao2013remote - Remote Measurements of Heart and Respiration Rates for Telemedicine.pdf:PDF},
  publisher = {Public Library of Science ({PLoS})},
}

@InProceedings{tran2015robust,
  author       = {Duc Nhan Tran and Hyukzae Lee and Changick Kim},
  title        = {A robust real time system for remote heart rate measurement via camera},
  booktitle    = {2015 {IEEE} International Conference on Multimedia and Expo ({ICME})},
  year         = {2015},
  pages        = {1--6},
  month        = {jun},
  organization = {IEEE},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  abstract     = {Heart rate (HR) is an important indicator of human health status. Traditional heart rate measurement methods rely on contact-based sensors or electrodes, which are inconvenient and troublesome for users. Remote sensing of the photoplephysmography (PPG) signal using a video camera provides a promising means to monitor vital signs of people without the need of any physical contact. However, until recently, most of the literature papers approaching this problem have only reported results from off-line recording videos taken under well controlled environments. In this paper, we propose a method to improve HR measurement accuracy under challenging environments involving factors such as subjects movement, complicated facial models (i.e., hair, glass, beards, etc.), subjects distance to camera, and low illumination condition. We also build a framework for real-time measuring system and construct a stable model for recording and displaying results for long term heart rate monitoring. We tested our system on challenging dataset, and demonstrated that our method not only deals with real-time, on-line measurement tasks, but also outperforms others works.},
  doi          = {10.1109/icme.2015.7177484},
  file         = {:tran2015robust - A robust real time system for remote heart rate measurement via camera.pdf:PDF},
}

@Article{hyvarinen2000independent,
  author    = {Hyv{\"a}rinen, Aapo and Oja, Erkki},
  title     = {Independent component analysis: algorithms and applications},
  journal   = {Neural Networks},
  year      = {2000},
  volume    = {13},
  number    = {4},
  pages     = {411--430},
  month     = {jun},
  doi       = {10.1016/s0893-6080(00)00026-5},
  publisher = {Elsevier {BV}},
}

@InCollection{jolliffe2002principal,
  author    = {Ian Jolliffe},
  title     = {Principal Component Analysis},
  booktitle = {International Encyclopedia of Statistical Science},
  publisher = {Springer Nature},
  year      = {2011},
  pages     = {1094--1096},
  doi       = {10.1007/978-3-642-04898-2_455},
}

@Book{salen2004rules,
  title     = {Rules of play: Game design fundamentals},
  publisher = {MIT press},
  year      = {2004},
  author    = {Salen, Katie and Zimmerman, Eric},
}

@Article{chen2007flow,
  author    = {Jenova Chen},
  title     = {Flow in games (and everything else)},
  journal   = {Communications of the ACM},
  year      = {2007},
  volume    = {50},
  number    = {4},
  pages     = {31},
  month     = {apr},
  doi       = {10.1145/1232743.1232769},
  file      = {:chen2007flow - Flow in games (and everything else).pdf:PDF},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{cruz2017player,
  author    = {Christian Arzate Cruz and Jorge Adolfo Ramirez Uresti},
  title     = {Player-centered game {AI} from a flow perspective: Towards a better understanding of past trends and future directions},
  journal   = {Entertainment Computing},
  year      = {2017},
  volume    = {20},
  pages     = {11--24},
  month     = {may},
  doi       = {10.1016/j.entcom.2017.02.003},
  file      = {:cruz2017player - Player-centered game AI from a flow perspective - Towards a better understanding of past trends and future directions.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{sweetser2005gameflow,
  author    = {Penelope Sweetser and Peta Wyeth},
  title     = {{GameFlow}},
  journal   = {Computers in Entertainment (CIE)},
  year      = {2005},
  volume    = {3},
  number    = {3},
  pages     = {3--3},
  month     = {jul},
  abstract  = {Although player enjoyment is central to computer games, there is currently no accepted model of player enjoyment in games. There are many heuristics in the literature, based on elements such as the game interface, mechanics, gameplay, and narrative. However, there is a need to integrate these heuristics into a validated model that can be used to design, evaluate, and understand enjoyment in games. We have drawn together the various heuristics into a concise model of enjoyment in games that is structured by flow. Flow, a widely accepted model of enjoyment, includes eight elements that, we found, encompass the various heuristics from the literature. Our new model, GameFlow, consists of eight elements – concentration, challenge, skills, control, clear goals, feedback, immersion, and social interaction. Each element includes a set of criteria for achieving enjoyment in games. An initial investigation and validation of the GameFlow model was carried out by conducting expert reviews of two real-time strategy games, one high-rating and one low-rating, using the GameFlow criteria. The result was a deeper understanding of enjoyment in real-time strategy games and the identification of the strengths and weaknesses of the GameFlow model as an evaluation tool. The GameFlow criteria were able to successfully distinguish between the high-rated and low-rated games and identify why one succeeded and the other failed. We concluded that the GameFlow model can be used in its current form to review games; further work will provide tools for designing and evaluating enjoyment in games.},
  doi       = {10.1145/1077246.1077253},
  file      = {:sweetser2005gameflow - GameFlow.pdf:PDF},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{nogueira2015annotation,
  author    = {Pedro A. Nogueira and Vasco Torres and Rui Rodrigues and Eug{\'{e}}nio Oliveira},
  title     = {An annotation tool for automatically triangulating individuals' psychophysiological emotional reactions to digital media stimuli},
  journal   = {Entertainment Computing},
  year      = {2015},
  volume    = {9-10},
  pages     = {19--27},
  month     = {jun},
  abstract  = {Current affective user experience studies require both laborious and time-consuming data analysis, as well as dedicated affective classification algorithms. Moreover, the high technical complexity and lack of general guidelines for developing these affective classification algorithms further limits the comparability of the obtained results. In this paper we target this issue by presenting a tool capable of automatically annotating and triangulating players’ physiologically interpreted emotional reactions to in-game events. This tool was initially motivated by an experimental psychology study regarding the emotional habituation effects of audio-visual stimuli in digital games and we expect it to contribute in future similar studies by providing both a deeper and more objective analysis on the affective aspects of user experience. We also hope it will contribute towards the rapid implementation and accessibility of this type of studies by open-sourcing it. Throughout this paper we describe the development and benefits presented by our tool, which include: enabling researchers to conduct objective a posteriori analyses without disturbing the gameplay experience, automating the annotation and emotional response identification process, and formatted data exporting for further analysis in third-party statistical software applications.},
  doi       = {10.1016/j.entcom.2015.06.003},
  file      = {:nogueira2015annotation - An annotation tool for automatically triangulating individuals psychophysiological emotional reactions to digital media stimuli.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@InProceedings{mekler2014systematic,
  author       = {Elisa D. Mekler and Julia Ayumi Bopp and Alexandre N. Tuch and Klaus Opwis},
  title        = {A systematic review of quantitative studies on the enjoyment of digital entertainment games},
  booktitle    = {Proceedings of the 32nd annual {ACM} conference on Human factors in computing systems - {CHI} {\textquotesingle}14},
  year         = {2014},
  pages        = {927--936},
  organization = {ACM},
  publisher    = {Association for Computing Machinery ({ACM})},
  abstract     = {Enjoyment has been identified as a central component of the player experience (PX), but various, overlapping concepts within PX make it difficult to develop valid measures and a common understanding of game enjoyment. We conducted a systematic review of 87 quantitative studies, analyzing different operationalizations and measures of game enjoyment, its determinants, and how these were related to other components of PX, such as flow, presence and immersion. Results suggest that game enjoyment describes the positive cognitive and affective appraisal of the game experience, and may in part be associated with the support of player needs and values. Further, we outline that enjoyment is distinct from flow in that it may occur independently of challenge and cognitive involvement, and argue that enjoyment may be understood as the valence of the player experience. We conclude with a discussion of methodological challenges and point out opportunities for future research on game enjoyment.},
  doi          = {10.1145/2556288.2557078},
  file         = {:mekler2014systematic - A systematic review of quantitative studies on the enjoyment of digital entertainment games.pdf:PDF},
}

@InCollection{nakamura2014concept,
  author    = {Nakamura, Jeanne and Csikszentmihalyi, Mihaly},
  title     = {The concept of flow},
  booktitle = {Flow and the foundations of positive psychology},
  publisher = {Springer},
  year      = {2014},
  pages     = {239--263},
}

@Article{russell1978evidence,
  author    = {James A. Russell},
  title     = {Evidence of convergent validity on the dimensions of affect.},
  journal   = {Journal of Personality and Social Psychology},
  year      = {1978},
  volume    = {36},
  number    = {10},
  pages     = {1152--1168},
  doi       = {10.1037/0022-3514.36.10.1152},
  file      = {:russell1978evidence - Evidence of convergent validity on the dimensions of affect.pdf:PDF},
  publisher = {American Psychological Association ({APA})},
}

@Article{posner2005circumplex,
  author    = {Posner, Jonathan and Russell, James A and Peterson, Bradley S},
  title     = {The circumplex model of affect: An integrative approach to affective neuroscience, cognitive development, and psychopathology},
  journal   = {Development and Psychopathology},
  year      = {2005},
  volume    = {17},
  number    = {03},
  pages     = {715--734},
  month     = {sep},
  abstract  = {The circumplex model of affect proposes that all affective states arise from cognitive interpretations of core neural sensations that are the product of two independent neurophysiological systems. This model stands in contrast to theories of basic emotions, which posit that a discrete and independent neural system subserves every emotion. We propose that basic emotion theories no longer explain adequately the vast number of empirical observations from studies in affective neuroscience, and we suggest that a conceptual shift is needed in the empirical approaches taken to the study of emotion and affective psychopathologies. The circumplex model of affect is more consistent with many recent findings from behavioral, cognitive neuroscience, neuroimaging, and developmental studies of affect. Moreover, the model offers new theoretical and empirical approaches to studying the development of affective disorders as well as the genetic and cognitive underpinnings of affective processing within the central nervous system.},
  doi       = {10.1017/s0954579405050340},
  file      = {:posner2005circumplex - The circumplex model of affect - An integrative approach to affective neuroscience, cognitive development, and psychopathology.pdf:PDF},
  publisher = {Cambridge University Press ({CUP})},
}

@InCollection{akakin2010spatiotemporal,
  author       = {Hatice {\c{C}}{\i}nar Akak{\i}n and Bülent Sankur},
  title        = {Spatiotemporal-Boosted {DCT} Features for Head and Face Gesture Analysis},
  booktitle    = {Human Behavior Understanding},
  publisher    = {Springer Nature},
  year         = {2010},
  pages        = {64--74},
  abstract     = {Automatic analysis of head gestures and facial expressions is a challenging research area and it has significant applications in humancomputer interfaces. In this study, facial landmark points are detected and tracked over successive video frames using a robust method based on subspace regularization, Kalman prediction and refinement. The trajectories (time series) of facial landmark positions during the course of the head gesture or facial expression are organized in a spatiotemporal matrix and discriminative features are extracted from the trajectory matrix. Alternatively, appearance based features are extracted from DCT coefficients of several face patches. Finally Adaboost algorithm is performed to learn a set of discriminating spatiotemporal DCT features for face and head gesture (FHG) classification. We report the classification results obtained by using the Support Vector Machines (SVM) on the outputs of the features learned by Adaboost. We achieve 94.04\% subject independent classification performance over seven FHG.},
  doi          = {10.1007/978-3-642-14715-9_7},
  file         = {:akakin2010spatiotemporal - Spatiotemporal-Boosted DCT Features for Head and Face Gesture Analysis.pdf:PDF},
  organization = {Springer},
}

@InProceedings{joho2009exploiting,
  author       = {Hideo Joho and Joemon M. Jose and Roberto Valenti and Nicu Sebe},
  title        = {Exploiting facial expressions for affective video summarisation},
  booktitle    = {Proceeding of the {ACM} International Conference on Image and Video Retrieval - {CIVR} {\textquotesingle}09},
  year         = {2009},
  pages        = {31},
  organization = {ACM},
  publisher    = {Association for Computing Machinery ({ACM})},
  abstract     = {This paper presents an approach to affective video summarisation based on the facial expressions (FX) of viewers. A facial expression recognition system was deployed to capture a viewer’s face and his/her expressions. The user’s facial expressions were analysed to infer personalised affective scenes from videos. We proposed two models, pronounced level and expression’s change rate, to generate affective summaries using the FX data. Our result suggested that FX can be a promising source to exploit for affective video summaries that can be tailored to individual preferences.},
  doi          = {10.1145/1646396.1646435},
  file         = {:joho2009exploiting - Exploiting facial expressions for affective video summarisation.pdf:PDF},
}

@InProceedings{anttonen2005emotions,
  author       = {Jenni Anttonen and Veikko Surakka},
  title        = {Emotions and heart rate while sitting on a chair},
  booktitle    = {Proceedings of the {SIGCHI} conference on Human factors in computing systems - {CHI} {\textquotesingle}05},
  year         = {2005},
  pages        = {491--499},
  organization = {ACM},
  publisher    = {Association for Computing Machinery ({ACM})},
  abstract     = {New methods for unobtrusive monitoring of computer users’ emotion psychophysiology are very much needed in human-computer interaction research. The present aim was to study heart rate changes during emotionally provocative stimulation. Six-second long auditory, visual, and audiovisual emotionally negative, neutral, and positive stimuli were presented to 24 participants. Heart rate responses were measured with a regular office chair embedded with electromechanical film (the EMFi chair) and with traditional earlobe photoplethysmography (PPG). Ratings of the stimuli were also collected. The results showed that the two heart rate measurements were significantly correlated, r = 0.99. In line with other studies the results showed that, in general, heart rate decelerated in response to emotional stimulation and it decelerated the most in response to negative stimuli as compared with responses to positive and neutral stimuli. Especially, emotional stimulation caused significant changes in heart rate at the 6th second from the stimulus onset. We suggest that the EMFi chair could be used in human-computer interaction for unobtrusive measurement of the user’s emotional reactions.},
  doi          = {10.1145/1054972.1055040},
  file         = {:anttonen2005emotions - Emotions and heart rate while sitting on a chair.pdf:PDF},
}

@Article{witvliet2007play,
  author    = {Charlotte V. O. Witvliet and Scott R. Vrana},
  title     = {Play it again Sam: Repeated exposure to emotionally evocative music polarises liking and smiling responses, and influences other affective reports, facial {EMG}, and heart rate},
  journal   = {Cognition {\&} Emotion},
  year      = {2007},
  volume    = {21},
  number    = {1},
  pages     = {3--25},
  month     = {jan},
  doi       = {10.1080/02699930601000672},
  file      = {:witvliet2007play - Play it again Sam Repeated exposure to emotionally evocative music polarises liking and smiling responses, and influences other affective reports, facial EMG, and heart rate.pdf:PDF},
  publisher = {Taylor \& Francis},
}

@Article{ekman1971constants,
  author    = {Paul Ekman and Wallace V. Friesen},
  title     = {Constants across cultures in the face and emotion.},
  journal   = {Journal of Personality and Social Psychology},
  year      = {1971},
  volume    = {17},
  number    = {2},
  pages     = {124--129},
  doi       = {10.1037/h0030377},
  file      = {:ekman1971constants - Constants across cultures in the face and emotion.pdf:PDF},
  publisher = {American Psychological Association ({APA})},
}

@InProceedings{metaxas2004image,
  author       = {Dimitris Metaxas and Sundara Venkataraman and Christian Vogler},
  title        = {Image-Based Stress Recognition Using a Model-Based Dynamic Face Tracking System},
  booktitle    = {Computational Science - {ICCS} 2004},
  year         = {2004},
  pages        = {813--821},
  organization = {Springer},
  publisher    = {Springer Nature},
  abstract     = {Stress recognition from facial image sequences is a subject that has not received much attention although it is an important problem for a host of applications such as security and human-computer interaction. This class of problems and the related software are instances of Dynamic Data Driven Application Systems (DDDAS). This paper presents a method to detect stress from dynamic facial image sequences. The image sequences consist of people subjected to various psychological tests that induce high and low stress situations. We use a model-based tracking system to obtain the deformations of different parts of the face (eyebrows, lips, mouth) in a parameterized form. We train a Hidden Markov Model system using these parameters for stressed and unstressed situations and use this trained system to do recognition of high and low stress situations for an unlabelled video sequence. Hidden Markov Models (HMMs) are an effective tool to model the temporal dependence of the facial movements. The main contribution of this paper is a novel method of stress detection from image sequences of a person’s face.},
  doi          = {10.1007/978-3-540-24688-6_105},
  file         = {:metaxas2004image - Image-Based Stress Recognition Using a Model-Based Dynamic Face Tracking System.pdf:PDF},
}

@InProceedings{liao2005decision,
  author    = {Liao, Wenhui and Zhang, Weihong and Zhu, Zhiwei and Ji, Qiang},
  title     = {A Decision Theoretic Model for Stress Recognition and User Assistance},
  booktitle = {Proceedings of the 20th National Conference on Artificial Intelligence - Volume 2},
  year      = {2005},
  series    = {AAAI'05},
  pages     = {529--534},
  publisher = {AAAI Press},
  abstract  = {We present a general unified probabilistic decisiontheoretic model based on Influence Diagrams for simultaneously modeling both user stress recognition and user assistance. Stress recognition is achieved through dynamic probabilistic inference from the available sensory data from multiple-modality sources. User assistance is automatically achieved by balancing the benefits of improving user performance and the costs of performing user assistance. In addition, a non-invasive real-time system is built to validate the proposed framework. Utilizing the evidences from four modalities (physical appearance features, physiological measures, user performance and behavioral data), the system can successfully recognize human stress and provide timely and appropriate assistance in a task-specific environment.},
  acmid     = {1619418},
  file      = {:liao2005decision - A Decision Theoretic Model for Stress Recognition and User Assistance.pdf:PDF},
  isbn      = {1-57735-236-x},
  location  = {Pittsburgh, Pennsylvania},
  numpages  = {6},
  url       = {http://dl.acm.org/citation.cfm?id=1619410.1619418},
}

@Article{dinges2005optical,
  author    = {Dinges, David F and Rider, Robert L and Dorrian, Jillian and McGlinchey, Eleanor L and Rogers, Naomi L and Cizman, Ziga and Goldenstein, Siome K and Vogler, Christian and Venkataraman, Sundara and Metaxas, Dimitris N},
  title     = {Optical computer recognition of facial expressions associated with stress induced by performance demands},
  journal   = {Aviation, space, and environmental medicine},
  year      = {2005},
  volume    = {76},
  number    = {6},
  pages     = {B172--B182},
  abstract  = {Application of computer vision to track changes in human facial expressions during long-duration spaceflight may be a useful way to unobtrusively detect the presence of stress during critical operations. To develop such an approach, we applied optical computer recognition (OCR) algorithms for detecting facial changes during performance while people experienced both low- and high-stressor performance demands. Workload and social feedback were used to vary performance stress in 60 healthy adults (29 men, 31 women; mean age 30 yr). High-stressor scenarios involved more difficult performance tasks, negative social feedback, and greater time pressure relative to low workload scenarios. Stress reactions were tracked using self-report ratings, salivary cortisol, and heart rate. Subjects also completed personality, mood, and alexithymia questionnaires. To bootstrap development of the OCR algorithm, we had a human observer, blind to stressor condition, identify the expressive elements of the face of people undergoing high- vs. lowstressor performance. Different sets of videos of subjects’ faces during performance conditions were used for OCR algorithm training. Subjective ratings of stress, task difficulty, effort required, frustration, and negative mood were significantly increased during high-stressor performance bouts relative to low-stressor bouts (all p < 0.01). The OCR algorithm was refined to provide robust 3-d tracking of facial expressions during head movement. Movements of eyebrows and asymmetries in the mouth were extracted. These parameters are being used in a Hidden Markov model to identify high- and low-stressor conditions. Preliminary results suggest that an OCR algorithm using mouth and eyebrow regions has the potential to discriminate high- from lowstressor performance bouts in 75 - 88\% of subjects. The validity of the workload paradigm to induce differential levels of stress in facial expressions was established. The paradigm also provided the basic stressrelated facial expressions required to establish a prototypical OCR algorithm to detect such changes. Efforts are underway to further improve the OCR algorithm by adding facial touching and automating application of the deformable masks and OCR algorithms to video footage of the moving faces as a prelude to blind validation of the automated approach.},
  file      = {:dinges2005optical - Optical computer recognition of facial expressions associated with stress induced by performance demands.pdf:PDF},
  publisher = {Aerospace Medical Association},
}

@Article{staab2014influence,
  author    = {Jeffrey P. Staab},
  title     = {The influence of anxiety on ocular motor control and gaze},
  journal   = {Current Opinion in Neurology},
  year      = {2014},
  volume    = {27},
  number    = {1},
  pages     = {118--124},
  month     = {feb},
  abstract  = {The influence of anxiety on ocular motor control and gaze has received less research attention than its effects on postural control and locomotion. This review summarizes research on trait anxiety, state anxiety, anxiety disorders, ocular motor reflexes, and gaze. It applies these findings to clinical problems of visually induced unsteadiness and dizziness (VUD, also known as visual vertigo), fear of falling (FoF), and chronic subjective dizziness (CSD). Humans are inherently more sensitive to vertical heights than horizontal distances. Vertical height intolerance is reported by one-quarter to one-third of the general population. Humans also possess a gaze bias toward potentially threatening stimuli in the visual field, more prominent in individuals with higher versus lower trait anxiety and increased by state anxiety. This bias may drive hypervigilance-avoidance gaze patterns in patients with social anxiety disorder and specific phobias. Trait and state anxiety also appear to adversely affect gaze control, reducing gaze stability on visual targets. This may be one mechanism underlying persistent VUD and visual symptoms of CSD. Anxiety-related gaze diversion may increase gait instability in patients with FoF. Anxiety affects ocular motor reflexes and gaze control in ways that may contribute to clinically significant visual and visual-vestibular syndromes.},
  doi       = {10.1097/wco.0000000000000055},
  publisher = {Ovid Technologies (Wolters Kluwer Health)},
}

@Article{pan1985real,
  author    = {Jiapu Pan and Willis J. Tompkins},
  title     = {A Real-Time {QRS} Detection Algorithm},
  journal   = {{IEEE} Transactions on Biomedical Engineering},
  year      = {1985},
  volume    = {{BME}-32},
  number    = {3},
  pages     = {230--236},
  month     = {mar},
  doi       = {10.1109/tbme.1985.325532},
  file      = {:pan1985real - A Real-Time QRS Detection Algorithm.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Techreportcle{ahmed2010heart,
  author      = {Ahmed, Mobyen Uddin and Begum, Shahina and Islam, Mohd Siblee},
  title       = {Heart Rate and Inter-beat Interval Computation to Diagnose Stress Using ECG Sensor Signal},
  year        = {2010},
  file        = {:ahmed2010heart - Heart Rate and Inter-beat Interval Computation to Diagnose Stress Using ECG Sensor Signal.pdf:PDF},
  institution = {M\"alardalen University},
  journal     = {MRTC Report},
}

@TechReport{yanowitz2012introduction,
  author      = {Yanowitz, Frank G},
  title       = {Introduction to ECG interpretation},
  institution = {LDS Hospital \& Intermountain Medical Center},
  year        = {2012},
}

@Article{kim2004emotion,
  author    = {Kim, Kyung Hwan and Bang, Seok Won and Kim, Sang Ryong},
  title     = {Emotion recognition system using short-term monitoring of physiological signals},
  journal   = {Medical {\&} Biological Engineering {\&} Computing},
  year      = {2004},
  volume    = {42},
  number    = {3},
  pages     = {419--427},
  month     = {may},
  doi       = {10.1007/bf02344719},
  publisher = {Springer Nature},
}

@MastersThesis{chwyl2016statistical,
  author = {Chwyl, Brendan},
  title  = {A Statistical Framework for Non-Contact Heart Rate Estimation via Photoplethysmogram Imaging},
  school = {University of Waterloo},
  year   = {2016},
  file   = {:Chwyl_Brendan.pdf:PDF},
}

@Article{valentini2009variables,
  author    = {Mariaconsuelo Valentini and Gianfranco Parati},
  title     = {Variables Influencing Heart Rate},
  journal   = {Progress in Cardiovascular Diseases},
  year      = {2009},
  volume    = {52},
  number    = {1},
  pages     = {11--19},
  month     = {jul},
  abstract  = {In both physiologic and pathological conditions, instantaneous heart rate value is the result of a rather complex interplay. It constantly varies under the influence of a number of factors: nonmodifiable and modifiable ones. Pharmacologic blockade with B-adrenergic antagonists and/or with parasympathetic antagonists such as atropine have permitted the identification of the mechanisms of autonomic nervous regulation of heart rate in a variety of physiologic and pathological conditions. The analysis of heart rate and blood pressure variability has yielded additional information on the autonomic control of the circulation, which has proven to have diagnostic and prognostic implications in a number of clinically relevant conditions such as hypertension, acute myocardial infarction, heart failure, and predisposition to sudden cardiac death. This article will summarize, based on available epidemiologic and clinical studies, the key variables influencing heart rate and heart rate variability in view of the known association between heart rate and cardiovascular disease.},
  doi       = {10.1016/j.pcad.2009.05.004},
  file      = {:valentini2009variables - Variables Influencing Heart Rate.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Comment{jabref-meta: databaseType:bibtex;}
