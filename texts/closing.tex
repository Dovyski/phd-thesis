\chapter{Closing remarks}
\label{ch:closing}

Questionnaires and physiological measurements are the most common approach used to obtain data for emotion estimation in the field of HCI and games research. Both approaches interfere with the natural behavior of users, which affects any research procedure. Initiaties based on computer vision and remote extraction of user signals for emotion estimation exist, however they are limited. Experiments of such initiatives were performed under extremely controlled situations with few game-related stimuli. Users had a passive role with limited possibilities for interaction or emotional involvement, differently than game-based emotion stimuli, where users take an active role in the process, making decision and directly interacting with the media. Previous works also focus on predictive models based on a group perspective. As a consequece, a model is usually trained from data of several users, which in practice describes the average behavior of the group, excluding or diluting key individualities of each user. In that light, there is a lack of initiatives focusing on non-obtrusive, user-tailored emotion detection models, in particular regarding stress and boredom, within the context of games research that are based on emotion data generated from game stimuli.

This thesis presented a research that aims to fill that gap, providing the HCI and the games research community with tools to remotely study users emotions in a non-obtrusive way within the context of games. Current results of this research show that individualities can be detected regarding facial activity, e.g. increased number of facial actions during the stressful part of games. Regarding physiological signals, results indicate that the average HR mean for players during the last minute of gameplay is greater than the average HR mean during the second minute of gameplay. The findings are aligned with and reinforce previous research that indicate higher HR mean during stressful situations in a gaming context. The findings also suggest that changes in the HR during gaming sessions is a promising indicator of stress, which can be incorporated into a model aimed at emotion detection. As pointed out by previous work, a user-tailored model based on several signals, e.g. HR and facial activity, is more likely to detect emotional states of users.

The remote measurement of physiological signals via rPPG within the context of games research proved a feasible solution. On average, the estimation error of the rPPG technique is up to 10.31\% of the expected value calculated from ground truth. Investigations suggest factors connected to the type of the game being played and the unique behavior of each subject influenced the estimations. Among the causes of such influence are body movement, e.g. head tilt and rotation, and facial occlusion by subjects hand.

The literature reviews and the experiments conducted so far support the idea of using facial activity and body movement as source of information. It can be combined with remote HR estimations in a multifactorial analysis for the identification of stress and boredom in games. It will produce a user-tailored approach for emotion detection focused on the behavioral particularities of each user instead of the average group pattern.

\section{Future work}

The literature reviews conducted on emotion detection and computer vision techniques, along with the results from the first experiment, support the following course of action. As the theories presented in chapter \ref{ch:literature-physiological} suggest, techniques for remote extraction of physiological signals of users are significantly affected by natural behavior, e.g. head movement and facial activity. The results of the first experiment also support that, indicating that users indeed behave in a way that directly affect the accuracy of measurements. Preliminary analysis \parencite{bevilacqua2017accuracy} suggests that the accuracy of the rPPG technique is feasable under such circustances, however it is still not clear how the accuracy problems interfer with a predictive model. As a consequence, studies will be conducted to investigate how the selected rPPG technique can be improved to mitigate or elimitate those problems, which will allow a correct extraction of user signals, leading to a working emotion detection model. The data obtained from the first experiment is enough to conduct such investigation.

The techniques and works presented in chapter \ref{ch:literature-face}, which relate to face detection and emotion estimation, suggest that facial analysis is an important component of a multifactorial emotion detection model. Empirical analysis of the data from the first experiment also suggest that individualities regarding facial activities do exist and could be used to estimate emotional states on a user-tailored basis \parencite{bevilacqua2016variations}. As described in section \ref{ch:literature-face-emotion-prediction}, facial actions, head movement, lips/eye/mouth activity and distance measurements of detected facial landmarks are viable and proved sources of information for emotion detection. Additionally related works suggest that a combination of facial analysis and physiological signals is a more accurate approach regarding emotion detection, in particular the use of individually-based user data instead of group-based information. In that sense, studies will be conducted to investigate how such facial activity can be used for emotion detection along with the measurements performed by the rPPG technique.

After the rPPG technique has been improved and the facial analysis has been structured, a fourth study will be conducted on the data of the first experiment. It will guide the process of refining the remote detection of physiological signals along with facial analysis, which is the foundation for the predictive model proposed in this thesis. At the present moment, the software required to perform such study is almost finished and ready to be deployed. The results of this study should lead to another publication, which will describe the improvements applied to the rPPG technique and how they affect remote estimation of physiological signals.

At some point in the near future, an investigation will be conducted regarding the mathematical techniques to be used as the foundation for the model proposed in this thesis. As detailed in chapters \ref{ch:literature-face}, \ref{ch:literature-rppg} and \ref{ch:literature-multifactorial}, the most commonly employed method is machine learning. The investigation will probably test different machine learning techniques in the process of translating the extracted user signals into an indication of stress and boredom. It is likely that such investigation will be performed on the data collected with the first experiment. When the model is deemed mature enough, a new experiment will be conducted. It will validate both the improvents performed on the selected computer vision technique, the concept of calibration games and the model itself. As described in section \ref{sec:research-process}, the results of the experiment and their evaluation will guide future work on the model. The model itself will be re-valided, refined and improved with another experiment, following a cycle of experimental research.
