\chapter{Introduction}
\label{c:introduction}

In human-computer interaction (HCI) research, the study of the relation between users and systems is of interest. Within the context of games research in particular, the relation between the player and the game is an important topic. Such relation comprehends concepts as engagement and immersion \parencite{boyle2012engagement} and the investigation of the elements that influence those concepts.

To perform such investigations, researchers need to rely on methods that are able to capture the user's emotional state within the proposed context. The most commonly used techniques to obtain data regarding emotional states of players in a game are self-reports (questionnaires) and physiological measurements \parencite{mekler2014systematic}. Questionnaires are practical and ease to use tools, however they require a shift in attention, hence breaking or affecting the level of engagement/immersion of the user. Physiological signals, on the other hand, have been used to obtain information from users without causing interruptions \parencite{bousefsaf2013remote,yun2009game,rani2006empirical,tijs2008dynamic}. Sensors, despite avoiding interruptions, are usually perceived as uncomfortable and intrusive, since they require the proper setup in the person's body. Additionally sensors might restrict player's motion abilities, e.g. a sensor attached to a finger prevents the use of that finger. Sensors also increase user's awareness of being monitored \parencite{yamakoshi2007preliminary,yamaguchi2006evaluation,healey2005detecting}, which disturbs the results of an investigation.

%Questionnaires, however, require the user to stop the game activity in order to share his/her current state. The frequency that such questionnaires are issued is also a concern. If performed too often, more information might be collected, but the data might contain noise caused by the frequent interruptions, e.g. player is more stressed/bored by the questionnaire interruptions than by the game itself. If performed too sparse, not enough information will be gathered from the player.

Despite the mentioned problems, sensors continue to be used because there is a significant amount of information that can be read from the human body, such as heart rate (HR), respiratory rate (RR), facial expressions, among others. The information provenient from the human body can be seen as input signals for emotion estimation. A number of studies \parencite{kukolja2014comparative} suggest that the analysis of a combination of different input signals, known as multimodal analysis, is more likely to produce accurate results when mapping emotional states. Physiological signals, e.g. HR, are considered reliable sources since they are hard to fake (because of their link to the central nervous system), differently from facial expressions \parencite{Landowska}, for instance. When combined in the same analysis, however, those signals can complement each other and provide more information about emotional states. The process of mapping such signals to an emotional state, however, is a significant task. It involves testing/defining what are the possible emotional states a person can experience \parencite{mandryk2006continuous}, as well as comparing which signals are better predictors of such states \parencite{jerritta2011physiological}. A common approach to perform the mapping between input signals and emotional states is the use of machine learning models.

The use of a machine learning model commonly starts by exposing a group of users to some emotion elicitation material, e.g. images and videos with known emotional labels as stressful and boring. The signals from those users, e.g. HR and facial expressions, are measured during the interaction and used to train the machine learning model according to the labeled elicitation material. Ideally the trained model can be generalized and used to detect the emotional state of different users based on the analysis of their signals. This approach, however, fails to learn individual nuances since it assumes all users behave similarly. In practice, this approach is limited to detecting the average behavior of the training group. The great variability between individuals regarding physiological signals and emotional states does influece the process. Studies have shown that the correlaction between facial analysis and emotional states of the training population significantly differs from the expected correlation described in the literature for other populations \parencite{grafsgaard2013automatically}. Additionally there are indications that a machine learning model presents higher prediction rates for users with the highest self-reported emotional levels during the training phase, as well as the lowest prediction rates for participants with the lowest self-reported emotional levels during the training phase \parencite{mcduffcogcam}. It emphasizes the individualities of each user and the need of a user-tailored approach that preserves such characteristics.

Investigations have been conducted towards a user-tailored approach. It has been proved that a model created from a group of users is less effective at detecting emotions then a model created from a single person which is used to analyse that same person in the future \parencite{bailenson2008real}. This user-tailored approach is more likely to learn individual characteristics, not the average features of the training population. Additionally initiaties show a migration from physicial, obstrusive approaches for signal acquisition of users in favor of remote-based approaches instead. Advances in areas as Computer Vision allow the remote acquisition of input signals, including HR information, based on the analysis of videos of users. The remote detection of HR, for instance, proved a promising approach to infer boredom/stress levels \parencite{kukolja2014comparative} or cognitive stress \parencite{mcduff2014remote} of a person. Such remote and non-obtrusive approach, combined with a user-tailored machine learning model, allows the development of new tools for emotion detection.

This thesis presents an approach built on the previously mentined studies applied to the context of games. The main contribution is the detection of the emotional state of users during gaming sessions using remote acquisition of signals via computer vision, a user-tailored model and emotion elicitation based on a novel game-based calibration phase. The approach is automated and deployed as a software without the need of specialized equipment, e.g. sensors, only a regular video camera. Within that configuration, the following scenarios illustrate the overall goal of this research. In the first scenario, a games researcher wants to investigate the stress level of a user during a training session with a serious game. The researcher points an ordinary camera at the user face and asks him/her to play a few games for 15 minutes for calibration purposes. After that, the reseacher records a video of the user face while he/she plays the serious game to be investigated. The user experience is not disturbed by inconvinient sensors attached to his/her body, nor the user is constantly interrupted during the game play to answer questionnaires. After the user finishes playing, a software shows a report informing the researcher about the stress levels througout the session. In another ocasion, the researcher asks the same user to play a different serious game being investigated. This time the reseacher skips the calibration phase because the profile of that user is already known (no re-calibration phase is needed). Again the reseacher points a camera at the user's face, films the gaming session and at the end a software shows a report regarding stress levels. In another scenario, a small game developer company wants to check if a new title to be released is well balanced, i.e. it is not too difficult nor too easy to play. The small company has several hours of video recordings of users play-testing the game, however they have no budget nor time to manually inspect the material to find useful information. A representative of the company then invites the users involved in the play-testing sessions to visit the company again. A new video of each player is recored while he/she plays a few calibration games for about 15 minutes. After that, the company representative feeds a computer software with the newly created user videos and the already existing videos with hours of gameplay. In minutes, all material is analyzed and a software indicates the points in time where the stress level of users was higher than their usual behavior. The company then inspects the problems and adjusts the games accordingly, increasing its chances of success.

%Research in different areas, such as affective computing and computer vision, aim to improve the workflow of emotion investigation with non-obtrusive approaches involving the aforementioned signals. By using computer vision and a video stream captured by a camera, one can obtain different information from a subject, such as facial expressions and physiological signals, without the use of physical sensors.

The following sections present how the previously described scenarios can be achieved, showing the problem specification, the research aim and its contributions.

\section{Problem specification}

As previosly described, questionnaires and physiological measurements are the most common approach used to obtain data for emotion estimation. Both approaches interfere with the natural behavior of users, which affects any research procedure. Improvements to such approaches have been proposed in the literature, including the use of computer vision for remote extraction of user signals and a user-tailored machine learning model to map those signals into emotional states. The material used for emotion elicitation is also an important component of the process to accurately capture the singularities of each user.

One of the problems with previous work is directly connected to the emotion elicitation material used in the process. In the majority of the existing studies, subjects had limited interaction with the content being presented: they performed tasks mentally (e.g. counting), watched videos/images or performed gamified cognitive tests for a short period of time. Those are artificial situations that are unlikely to happen in a context involving games. The models trained from those emotion elicitation sources are less likely to cover the range of emotional activity featured by users during gaming sessions, especially those with a challenging game lasting for several minutes. There is a lack of investigation regarding the use of games as emotion elicitation sources, which is a media of interest to the games research community. The process of detecting emotions of users while they play games is more likely to succeeed with a model trained from game-based emotion elicitation materials instead of images and videos. With game-based emotion stimuli, users take an active role in the process, making decision and directly interacting with the content, which results in more genuine emotional manifestations. When images, videos or gamified tests are employed, users take a passive role with limited possibilities for interaction or emotional involvement, resulting in less significant emotional manifestations.

Regarding the initiaties based on computer vision and emotion estimation, the remote detection of HR, for instance, proved a promising approach to infer boredom/stress levels \parencite{kukolja2014comparative} or cognitive stress \parencite{mcduff2014remote} of a person. The application of such techniques, however, has not been proposed in a contex involving games and natural behavior of users. Experiments regarding the use of computer vision and signal extraction were performed under extremely controlled situations with few game-related stimuli. A significant limitation of such approaches was that subjects were asked to remain still during the experiment. This is an uncommon user behavior during the interaction with emotional estimulators that hinders the real efficiency of such remote detection techniques. In particular, when game-based emotion elicitation is used, users are likely to behave in a more natural way, e.g. featuring facial expressions and moving the body \parencite{bevilacqua2016variations}, which directly affect the remote measurements of physiological signals. The use of such computer vision techniques within the context of games and natural behavior must have its reliability confirmed. Additionally the techniques must be adapted to overcome the challenges associated with its usage in the context where users behave natually while playing games instead of being oriented to remain still.

Finally previous works focus on predictive models based on a collective perspective. As a consequece, a model is usually trained from data of several users, which in practice describes the average behavior of the group, excluding key individualities of each user. As previously mentioned, users behave differently and they present unique characteristics. It has been proved that a user-tailored approach is more likely to produce better emotional estimations, however no previous work has focused on game-based emotion elicitation combined with a user-tailored model. The lack of such investigation reduces the applicability of existing approaches within the context of games research, since they are based on emotion elicitation materials that are not games.

In summary, a significant part of those studies focus on models trained from data of a population instead of a user-tailored approach. It dilutes the peculiarities of each user and tends to predict the average behavior of a group. When a user-tailored model is used, it is trained with emotion elicitation materials based on images, videos and gamified cognitive tests. The use of games as emotion elicitation sources is not fully explored. The acquisition of user signals, e.g. HR and facial expression, is performed remotely via computer vision, however its applicability in a context involving games and natural behavior lacks further investigation. In that light, there is a lack of initiatives focusing on non-obtrusive, user-tailored emotion detection models, in particular regarding stress and boredom, within the context of games research that are based on emotion data generated from game stimuli. This thesis presents a research that aims to fill that gap, providing the games research community with a tool to remotely detect the emotional state of users in a non-obtrusive way, based on a model trained from a novel game-based calibration phase, which directly relates to the context of games research.

\section{Research aim}
\label{sec:research-aim}

This research presents an approach for remotely detecting the changes in stress and boredom levels of a player during the interaction with a game. The process, whose general structure is illustrated in Figure \ref{fig:research-aim-general}, is composed of two main phases: a calibration and an emotion estimation phase. In the calibration phase, the user plays a set of carefully designed games, named calibration games, that act as emotion elicitation sources. During this phase, the user signals elicitated from the interaction with the games, e.g. HR and facial expressions, are remotely acquired and used to train a user-tailored model. This model is the foundation to detect the stress and boredom levels of that particular user in any other game. In the emotion estimation phase, the user interacts with any ordinary game, e.g. a serious game, while his/her signals are remotely acquired and fed into the previously trained user-tailored model. The model outputs the current levels of stress and boredom for that user in that game.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{figures/research-aim-general.png}
    \caption{General structure proposed for remote detection of stress and boredom levels of players during interaction with games.}
    \label{fig:research-aim-general}
\end{figure}

The process is based on a non-contact, multifactorial analysis of user signals obtained from a video stream via computer vision. The principal of the emotion detection phase is based on a user-tailored machine learning model, which is trained with information obtained from the user while he/she played a set of games in the calibration phase. The user-tailored machine learning model is trained according to the process presented in Figure \ref{fig:user-tailored-calibration}. Each user plays a set of calibration games while being recorded by a camera. Computer vision is used to process the video feed and remotely extract signals from the user, such as HR and facial actions. Those signals are used as input to train the machine learning model for that particular user (user-tailored model).

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/user-tailored-calibration.png}
    \caption{Calibration phase composed of emotion elicitation games (calibration games) and remote acquisition of signals from the user. The result of this phase is a user-tailored model used to detect emotions.}
    \label{fig:user-tailored-calibration}
\end{figure}

The games used in the calibration phase act as emotion elicitation sources. Each of those games are casual-themed and carefully designed to trigger two distinct emotions, i.e. boredom and stress, featuring a progressive transition between them as illustrated by Figure \ref{fig:calibration-game-linear}. At the begining of the game, the difficulty level (green line) is significantly low and the user is required to perform few or no actions. The games are designed in a way that the user is not able to increase the pace of the gameplay nor make it faster based on personal skills. As a consequence the user is forced to play a low-paced gameplay, which leads to an emotional state of boredom (blue curve). As times progresses, the pace of the gameplay and its difficulty level increase lineraly. The increase happens at fixed time intervals, e.g. every 60 seconds. At some point in time, which is different for each user depending on gaming skills and personal preferences, the pace of the gameplay and the difficulty level will be overwhelming, leading the user to an emotional state of stress (red curve). As the difficulty level continues to increase, the stress level of the user will also increase. Finally the difficulty level will increase until the point where the user is unable to couple with the game, which will lead to consecutive mistakes in the game that will eventually terminate it, e.g. heathbar of the main character reaches zero.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/calibration-game-linear.png}
    \caption{Progression of the level of difficulty of a calibration game over time along with the corresponding variations of the emotional states of stress and boredom experienced by the user.}
    \label{fig:calibration-game-linear}
\end{figure}

The mentioned calibration games are designed to trigger specific emotions and vary them over time, so the remotely collected information from the user during the calibration phase contains a detailed variation profile of the person being analyzed, including changes of each signal and the theoretically known emotional state of the user at that moment. If a person has a better response to a certain physiological signal instead of another, e.g. HR over facial expressions, then the variation of that signal accounts more weight in the training of the model. Since the training process is completely based on the signals of a single user, nuances and individual behavior are likely to be registered and learned. The calibration phase needs to be performed once per person.

After the calibration phase, the person can play any other ordinary game and be monitored in an emotion estimation phase, as illustrated by Figure \ref{fig:user-tailored-use}. As the user plays the game, signals are remotely acquired via computer vision. Those signals are used as input to the trained user-tailored model of that particular person, which produces as a result an estimation of the emotional state regarding stress and boredom for that person in that game. The process relies on the same remotely aquired signals with the addition of the predictions of the model according to the training performed during the calibration phase.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/user-tailored-use.png}
    \caption{Emotion estimation phase. Remotely acquired signals from the user are fed into a user-tailored model that ouputs the stress/boredom levels of the user during the interaction with an ordinary game.}
    \label{fig:user-tailored-use}
\end{figure}

Stated the user has a trained user-tailored model, the emotion estimation phase can be performed for any game as many times as desired. The model uses the remotely obtained signals from the user in conjunction with the calibration data to detect the player's changes regarding stress and boredom levels in any other game.

%According to previous research, the use of games as a emotional triggering mechanism is a feasible approach. Additionally an user-tailored model is a more efficient approach than a group-tailored model for the detection of emotional changes in users.

\section{Expected knowledge contributions}
\label{sec:contributions}

This research is expected to produce a method that is able to interpret remotely acquired signals from a person and detect his/her current emotional state regarding stress and boredom according to data obtained in a game-based calibration phase. The model will be implemented in a software that uses a video feed to detect the person's emotional state.

The following research objectives (O) have being identified to support the overall aim and knowledge contributions of this thesis:

\textbf{O1}: identification of the main concepts, theories and signals associated with the psychophysiological profile of users and their emotions within the field of HCI, particularly regarding games research. The result of this objective is a formal definition of stress and boredom within the context of this research, as well as the identification of which physiological and non-physiological signals are commonly applied to emotion detection.

\textbf{O2}: identification of the ideal existing computer vision techniques that can be employed to remotely extract the identified physiological and non-physiological signals of users via analysis of videos. The investigation includes the analysis of how existing techniques are being applied to emotion detection. The set of signals to be remotely extracted is based on the results of objective \textbf{O1}.

\textbf{O3}: investigation of the feasibility, accuracy and challenges of applying the identified computer vision techniques regarding the extraction of the signals within the context of computer games. This objective also comprehends the analysis of the behavior of players during gaming sessions and how it affects the technique.

\textbf{O4}: investigation and validation of the concept of a game-based calibration phase as an emotional elicitation source able to provide data to fit a user-tailored predictive model. The result of this objective is to design and validate a set of calibration games that can trigger the emotional responses required for the analysis of the remotely obtained signals and detection of boredom/stress levels by the model.

\textbf{O5}: Proposal of a user-tailored, multifactorial model that uses the identified physiological and non-physiological signals, the computer vision technique and the calibration data to detect the current stress/boredom levels of a person while he/she plays any video game.

\textbf{O6}: Validation of the proposed model by deploying it to a software that can be used by researchers as a tool to detect the level of boredom/stress of users during the interaction with games.

The result of this research adds to the body of knowledge of HCI and games research. As previously described, information regarding concepts, models and theories involing games, emotions and computer vision will be identified, evalutated and orchestrated to work in combination. A novel game-based, multifactorial, user-tailored calibration phase is proposed and evalutated, which contributes to the research of emotions within the context of games and HCI.

A purely remote-based approach, as the one proposed by this research, enhances the tooling available regarding investigation methods of stress and boredom. The approach, which is based on novel user-tailored, game-based calibration phase, maps a set of variations of signals into two specific emotional states (stress/boredom). This information can be used by other researchers to identify important moments during the interaction of players with games, such as when the recognized pattern is closer to stress. In game design research, for instance, that instrumentation can be used as another way of obtaining information from a user during a game session. The use of questionnaires, which shift the player's focus away from the game, can be enhanced and/or replaced by the use of the proposed method, making the process less obtrusive. By remotely reading information regarding stress and boredom, a researcher can use such information to better understand concepts as engagement, frustration, immersion and flow in games, for instance. Additionally it can be used in any activity that relies on stress/boredom as an important measurement, such as usability tests in software and games, for instance. Another contribution is a better understanding of how the selected signals are related to stress/boredom. Other researchers might use that information in contexts outside the games area, such as the measurement of costumers satisfaction or interest in stores.

%The proposed method will be based on the analysis of the variation of signals of a person according to a reference (calibration data). This approach is significantly different from the already existing methods, which focus on training a model to detect pre-defined states (e.g. stress, boredom, rest) based on the current value of the acquired signals. The foundation of the approach proposed in this research is the use of variations, which by nature account for differences between the current state and any other known state (the calibration profile, for instance). This configuration allows the method to be expanded or further investigated to produce a scale regarding the measurement of stress and boredom. Different from a direct mapping of signals to a state, a scaled measurement might inform the researcher of how much stress or boredom the player is experiencing, as opposed to just informing he/she is stressed or bored. This might be possible to be achieved with a machine learning model, for instance, but it will require a complex training setup. which will inevitably result in frequent interruptions of the player for collecting self-reported stress/boredom levels. This will disturb immersion/engagement with the game, probably resulting in noise in the mapping.

%A researcher is be able to increase the internal validity of his/her workflow by ensuring the player keeps the focus on the game without interruptions and by minimizing the side effects (and inconveniences) of physical monitoring. This research can also be deployed as a solution for game developer studios to automatically analyze hours of recorded gameplay and highlight the moments when boredom/stress levels changed significantly. As a complement the solution is based on a single, ordinary camera and a software implementation, which eliminates the use of complex setups of physical sensors. It eases the investigation process and reduces costs.

\section{Thesis overview and structure}
